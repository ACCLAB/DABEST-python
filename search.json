[
  {
    "objectID": "02-about.html",
    "href": "02-about.html",
    "title": "About",
    "section": "",
    "text": "DABEST is written in Python by Joses W. Ho, with design and input from Adam Claridge-Chang and other lab members.\nFeatures in v2025.10.20 were added by Jonathan Anns, Zinan Lu, Yishan Mai, and Sangyu Xu.\nFeatures in v2025.03.27 were added by Jonathan Anns, Zinan Lu, Kah Seng Lian, Yishan Mai, Sangyu Xu, and Lucas Wang Zhuoyu.\nFeatures in v2024.03.29 were added by Zinan Lu, Kah Seng Lian, Ana Rosa Castillo.\nFeatures in v2023.02.14 were added by Yixuan Li, Zinan Lu and Rou Zhang.\nTo find out more about the authors‚Äô research, please visit the Claridge-Chang lab webpage.",
    "crumbs": [
      "Get Started",
      "About"
    ]
  },
  {
    "objectID": "02-about.html#authors",
    "href": "02-about.html#authors",
    "title": "About",
    "section": "",
    "text": "DABEST is written in Python by Joses W. Ho, with design and input from Adam Claridge-Chang and other lab members.\nFeatures in v2025.10.20 were added by Jonathan Anns, Zinan Lu, Yishan Mai, and Sangyu Xu.\nFeatures in v2025.03.27 were added by Jonathan Anns, Zinan Lu, Kah Seng Lian, Yishan Mai, Sangyu Xu, and Lucas Wang Zhuoyu.\nFeatures in v2024.03.29 were added by Zinan Lu, Kah Seng Lian, Ana Rosa Castillo.\nFeatures in v2023.02.14 were added by Yixuan Li, Zinan Lu and Rou Zhang.\nTo find out more about the authors‚Äô research, please visit the Claridge-Chang lab webpage.",
    "crumbs": [
      "Get Started",
      "About"
    ]
  },
  {
    "objectID": "02-about.html#contributors",
    "href": "02-about.html#contributors",
    "title": "About",
    "section": "Contributors",
    "text": "Contributors\n\nStatistics supervision by Hyungwon Choi\nAlpha testers from the Claridge-Chang lab: Sangyu Xu, Xianyuan Zhang, Farhan Mohammad, Jurga Mituzaitƒó, Stanislav Ott, Tayfun Tumkaya, Jonathan Anns, Nicole Lee and Yishan Mai.\nDizietAsahi (DizietAsahi) with PR #86: Fix bugs in slopegraph and reference line keyword parsing.\nAdam Li (@adam2392) with PR #85: Implement Lq-Likelihood-Ratio-Type Test in statistical output.\nMason Malone (@MasonM) with PR #30: Fix plot error when effect size is 0.\nMatthew Edwards (@mje-nz) with PR #71: Specify dependencies correctly in setup.py.\nAdam Nekimken (@anekimken) with PR #73: Implement inset axes so estimation plots can be plotted on a pre-determined :py:mod:matplotlib :py:class:Axes object.\nMarin Manuel (@MarinManuel) with PR #109: Fixed bug preventing non-string columns from being used.\nMike Lotinga (@mlotinga): Helped with addition of jitter and the adjusted p-value calculation, both of which are included in the v2025.03.27 release.",
    "crumbs": [
      "Get Started",
      "About"
    ]
  },
  {
    "objectID": "02-about.html#typography",
    "href": "02-about.html#typography",
    "title": "About",
    "section": "Typography",
    "text": "Typography\nThis documentation uses Spectral for the body text, Merriweather Sans for the side bar and titles, and IBM Plex Mono for the monospace code font.",
    "crumbs": [
      "Get Started",
      "About"
    ]
  },
  {
    "objectID": "02-about.html#license",
    "href": "02-about.html#license",
    "title": "About",
    "section": "License",
    "text": "License\nThe DABEST package in Python is licenced under the BSD 3-clause Clear License.\nCopyright (c) 2016-2023, Joses W. Ho All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted (subject to the limitations in the disclaimer below) provided that the following conditions are met:\n * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\n * Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nNO EXPRESS OR IMPLIED LICENSES TO ANY PARTY‚ÄôS PATENT RIGHTS ARE GRANTED BY THIS LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ‚ÄúAS IS‚Äù AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
    "crumbs": [
      "Get Started",
      "About"
    ]
  },
  {
    "objectID": "read_me.html#recent-version-update",
    "href": "read_me.html#recent-version-update",
    "title": "DABEST-Python",
    "section": "Recent Version Update",
    "text": "Recent Version Update\n‚ú® DABEST ‚ÄúBingka‚Äù v2025.10.20 for Python is now released! ‚ú®\nDear DABEST users, The latest version of the DABEST Python library brings new visualizations, refined plots, and improved accuracy.\n\nWhorlmap üåÄ: Compact visualization for multi-dimensional effects\nIntroducing Whorlmap, a new way to visualize effect sizes from multiple comparisons in a compact, grid-based format.\nWhorlmaps condense information from the full bootstrap distributions of many contrast objects into a 2D heatmap-style grid of ‚Äúwhorled‚Äù cells. This provides an overview of the entire dataset while preserving the underlying distributional detail.\nThey are especially useful for large-scale or multi-condition experiments, serving as a space-efficient alternative to stacked forest plots.\nYou can generate a Whorlmap directly from multi-dimensional DABEST objects using the .whorlmap() method. See the Whorlmap tutorial for more details.\nSlopegraphs üìà: Enhanced summaries for paired data\nSlopegraphs for paired continuous data now display group summary statistics.\n\nBy default, a thick trend line connects group means, with vertical bars showing standard deviation.\nChoose the summary type via the group_summaries argument in .plot() ‚Äî options include 'mean_sd', 'median_quartiles', or None.\nCustomize appearance with group_summaries_kwargs.\n\nSee the Group Summaries section in the Plot Aesthetics tutorial for more details.\nMini-meta Weighted Delta Fix üßÆ\nThe weighted delta calculation in mini-meta plots has been updated for greater accuracy and consistency.\nExpanded custom_palette functionality üé®\n\nBarplots (unpaired, proportional): custom_palette can now take 1 and 0 as dictionary keys to color the filled and unfilled portions of the plot.\nSlopegraphs (paired, non-proportional): custom_palette can now color contrast bars and effect-size curves.\n\n\nSee the Custom Palette section in the Plot Aesthetics tutorial for examples.\nThank you for your continued support!\nThe DABEST Development Team"
  },
  {
    "objectID": "read_me.html#contents",
    "href": "read_me.html#contents",
    "title": "DABEST-Python",
    "section": "Contents",
    "text": "Contents\n\n\nAbout\nInstallation\nUsage\nHow to cite\nBugs\nContributing\nAcknowledgements\nTesting\nDABEST in other languages"
  },
  {
    "objectID": "read_me.html#about",
    "href": "read_me.html#about",
    "title": "DABEST-Python",
    "section": "About",
    "text": "About\nDABEST is a package for Data Analysis using Bootstrap-Coupled ESTimation.\nEstimation statistics are a simple framework that avoids the pitfalls of significance testing. It employs familiar statistical concepts such as means, mean differences, and error bars. More importantly, it focuses on the effect size of one‚Äôs experiment or intervention, rather than succumbing to a false dichotomy engendered by P values.\nAn estimation plot comprises two key features.\n\nIt presents all data points as a swarm plot, ordering each point to display the underlying distribution.\nIt illustrates the effect size as a bootstrap 95% confidence interval on a separate but aligned axis.\n\n\n\n\nThe five kinds of estimation plots\n\n\nDABEST powers estimationstats.com, allowing everyone access to high-quality estimation plots."
  },
  {
    "objectID": "read_me.html#installation",
    "href": "read_me.html#installation",
    "title": "DABEST-Python",
    "section": "Installation",
    "text": "Installation\nThis package is tested on Python 3.11 and onwards. It is highly recommended to download the Anaconda distribution of Python in order to obtain the dependencies easily.\nYou can install this package via pip.\nTo install, at the command line run\npip install dabest\nYou can also clone this repo locally.\nThen, navigate to the cloned repo in the command line and run\npip install ."
  },
  {
    "objectID": "read_me.html#usage",
    "href": "read_me.html#usage",
    "title": "DABEST-Python",
    "section": "Usage",
    "text": "Usage\nimport pandas as pd\nimport dabest\n\n# Load the iris dataset. This step requires internet access.\niris = pd.read_csv(\"https://github.com/mwaskom/seaborn-data/raw/master/iris.csv\")\n\n# Load the above data into `dabest`.\niris_dabest = dabest.load(data=iris, x=\"species\", y=\"petal_width\",\n                          idx=(\"setosa\", \"versicolor\", \"virginica\"))\n\n# Produce a Cumming estimation plot.\niris_dabest.mean_diff.plot();\n\n\n\nA Cumming estimation plot of petal width from the iris dataset\n\n\nPlease refer to the official tutorial for more useful code snippets."
  },
  {
    "objectID": "read_me.html#how-to-cite",
    "href": "read_me.html#how-to-cite",
    "title": "DABEST-Python",
    "section": "How to cite",
    "text": "How to cite\nMoving beyond P values: Everyday data analysis with estimation plots\nJoses Ho, Tayfun Tumkaya, Sameer Aryal, Hyungwon Choi, Adam Claridge-Chang\nNature Methods 2019, 1548-7105. 10.1038/s41592-019-0470-3\nPaywalled publisher site; Free-to-view PDF"
  },
  {
    "objectID": "read_me.html#bugs",
    "href": "read_me.html#bugs",
    "title": "DABEST-Python",
    "section": "Bugs",
    "text": "Bugs\nPlease report any bugs on the issue page."
  },
  {
    "objectID": "read_me.html#contributing",
    "href": "read_me.html#contributing",
    "title": "DABEST-Python",
    "section": "Contributing",
    "text": "Contributing\nAll contributions are welcome; please read the Guidelines for contributing first.\nWe also have a Code of Conduct to foster an inclusive and productive space.\n\nA wish list for new features\nIf you have any specific comments and ideas for new features that you would like to share with us, please read the Guidelines for contributing, create a new issue using Feature request template or create a new post in our Google Group."
  },
  {
    "objectID": "read_me.html#acknowledgements",
    "href": "read_me.html#acknowledgements",
    "title": "DABEST-Python",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank alpha testers from the Claridge-Chang lab: Sangyu Xu, Xianyuan Zhang, Farhan Mohammad, Jurga Mituzaitƒó, and Stanislav Ott."
  },
  {
    "objectID": "read_me.html#testing",
    "href": "read_me.html#testing",
    "title": "DABEST-Python",
    "section": "Testing",
    "text": "Testing\nTo test DABEST, you need to install pytest and nbdev.\n\nRun pytest in the root directory of the source distribution. This runs the test suite in the folder dabest/tests/mpl_image_tests.\nRun nbdev_test in the root directory of the source distribution. This runs the value assertion tests in the folder dabest/tests\n\nThe test suite ensures that the bootstrapping functions and the plotting functions perform as expected.\nFor detailed information, please refer to the test folder"
  },
  {
    "objectID": "read_me.html#dabest-in-other-languages",
    "href": "read_me.html#dabest-in-other-languages",
    "title": "DABEST-Python",
    "section": "DABEST in other languages",
    "text": "DABEST in other languages\nDABEST is also available in R (dabestr) and Matlab (DABEST-Matlab)."
  },
  {
    "objectID": "API/effsize_objects.html",
    "href": "API/effsize_objects.html",
    "title": "Effectsize objects",
    "section": "",
    "text": "TwoGroupsEffectSize\n\n TwoGroupsEffectSize (control, test, effect_size, proportional=False,\n                      is_paired=None, ci=95, resamples=5000,\n                      permutation_count=5000, random_seed=12345,\n                      ps_adjust=False)\n\n*A class to compute and store the results of bootstrapped mean differences between two groups.\nCompute the effect size between two groups.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncontrol\narray-like\n\n\n\n\ntest\narray-like\n\nThese should be numerical iterables.\n\n\neffect_size\nstring.\n\nAny one of the following are accepted inputs:‚Äòmean_diff‚Äô, ‚Äòmedian_diff‚Äô, ‚Äòcohens_d‚Äô, ‚Äòhedges_g‚Äô, or ‚Äòcliffs_delta‚Äô\n\n\nproportional\nbool\nFalse\n\n\n\nis_paired\nNoneType\nNone\n\n\n\nci\nint\n95\nThe confidence interval width. The default of 95 produces 95%confidence intervals.\n\n\nresamples\nint\n5000\nThe number of bootstrap resamples to be taken for the calculationof the confidence interval limits.\n\n\npermutation_count\nint\n5000\nThe number of permutations (reshuffles) to perform for thecomputation of the permutation p-value\n\n\nrandom_seed\nint\n12345\nrandom_seed is used to seed the random number generator duringbootstrap resampling. This ensures that the confidence intervalsreported are replicable.\n\n\nps_adjust\nbool\nFalse\nIf True, adjust calculated p-value according to Phipson & Smyth (2010)# https://doi.org/10.2202/1544-6115.1585\n\n\nReturns\npy:class:TwoGroupEffectSize object:\n\ndifference : float The effect size of the difference between the control and the test.effect_size : string The type of effect size reported.is_paired : string The type of repeated-measures experiment.ci : float Returns the width of the confidence interval, in percent.alpha : float Returns the significance level of the statistical test as a float between 0 and 1.resamples : int The number of resamples performed during the bootstrap procedure.bootstraps : numpy ndarray The generated bootstraps of the effect size.random_seed : int The number used to initialise the numpy random seed generator, ie.seed_value from numpy.random.seed(seed_value) is returned.bca_low, bca_high : float The bias-corrected and accelerated confidence interval lower limit and upper limits, respectively.pct_low, pct_high : float The percentile confidence interval lower limit and upper limits, respectively.\n\n\n\n\nExample\n\nrandom.seed(12345)\ncontrol = norm.rvs(loc=0, size=30)\ntest = norm.rvs(loc=0.5, size=30)\neffsize = dabest.TwoGroupsEffectSize(control, test, \"mean_diff\")\neffsize\n\nThe unpaired mean difference is -0.253 [95%CI -0.782, 0.241].\nThe p-value of the two-sided permutation t-test is 0.348, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\n\n\neffsize.to_dict()\n\n{'alpha': 0.05,\n 'bca_high': 0.2413346581369784,\n 'bca_interval_idx': (109, 4858),\n 'bca_low': -0.7818088458343655,\n 'bec_bca_high': 0.5352403905584314,\n 'bec_bca_interval_idx': (130, 4880),\n 'bec_bca_low': -0.4982839949134528,\n 'bec_bootstraps': array([-0.48953946, -0.18565285, -0.23896785, ..., -0.55130928,\n         0.16037238, -0.07364879]),\n 'bec_difference': 0.0,\n 'bec_pct_high': 0.5280564736117328,\n 'bec_pct_interval_idx': (125, 4875),\n 'bec_pct_low': -0.5041777340626885,\n 'bootstraps': array([-0.23923425, -0.66013733, -0.42672232, ..., -0.33191074,\n        -0.16543251, -0.34179536]),\n 'ci': 95,\n 'difference': -0.25315417702752846,\n 'effect_size': 'mean difference',\n 'is_paired': None,\n 'is_proportional': False,\n 'pct_high': 0.25135646125431527,\n 'pct_interval_idx': (125, 4875),\n 'pct_low': -0.763588353717278,\n 'permutation_count': 5000,\n 'permutations': array([ 0.17221029,  0.03112419, -0.13911387, ..., -0.38007941,\n         0.30261507, -0.09073054]),\n 'permutations_var': array([0.07201642, 0.07251104, 0.07219407, ..., 0.07003705, 0.07094885,\n        0.07238581]),\n 'proportional_difference': nan,\n 'pvalue_brunner_munzel': nan,\n 'pvalue_kruskal': nan,\n 'pvalue_mann_whitney': 0.5201446121616038,\n 'pvalue_mcnemar': nan,\n 'pvalue_paired_students_t': nan,\n 'pvalue_permutation': 0.3484,\n 'pvalue_students_t': 0.34743913903372836,\n 'pvalue_welch': 0.3474493875548964,\n 'pvalue_wilcoxon': nan,\n 'random_seed': 12345,\n 'resamples': 5000,\n 'statistic_brunner_munzel': nan,\n 'statistic_kruskal': nan,\n 'statistic_mann_whitney': 494.0,\n 'statistic_mcnemar': nan,\n 'statistic_paired_students_t': nan,\n 'statistic_students_t': 0.9472545159069105,\n 'statistic_welch': 0.9472545159069105,\n 'statistic_wilcoxon': nan}\n\n\n\n\n\n\nEffectSizeDataFrame\n\n EffectSizeDataFrame (dabest, effect_size, is_paired, ci=95,\n                      proportional=False, resamples=5000,\n                      permutation_count=5000, random_seed=12345,\n                      x1_level=None, x2=None, delta2=False,\n                      experiment_label=None, mini_meta=False,\n                      ps_adjust=False)\n\nA class that generates and stores the results of bootstrapped effect sizes for several comparisons.\n\nExample: plot\nCreate a Gardner-Altman estimation plot for the mean difference.\n\nrandom.seed(9999) # Fix the seed so the results are replicable.\n# pop_size = 10000 # Size of each population.\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = repeat('Female', Ns/2).tolist()\nmales = repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                 'Control 2' : c2,     'Test 2' : t2,\n                 'Control 3' : c3,     'Test 3' : t3,\n                 'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                 'Gender'    : gender, 'ID'  : id_col\n                })\nmy_data = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\n\n\nfig1 = my_data.mean_diff.plot();\n\n\n\n\n\n\n\n\nCreate a Gardner-Altman plot for the Hedges‚Äô g effect size.\n\nfig2 = my_data.hedges_g.plot();\n\n\n\n\n\n\n\n\nCreate a Cumming estimation plot for the mean difference.\n\nfig3 = my_data.mean_diff.plot(float_contrast=True);\n\n\n\n\n\n\n\n\nCreate a paired Gardner-Altman plot.\n\nmy_data_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"),\n                       id_col = \"ID\", paired='baseline')\nfig4 = my_data_paired.mean_diff.plot();\n\n\n\n\n\n\n\n\nCreate a multi-group Cumming plot.\n\nmy_multi_groups = dabest.load(df, id_col = \"ID\", \n                             idx=((\"Control 1\", \"Test 1\"),\n                                 (\"Control 2\", \"Test 2\")))\nfig5 = my_multi_groups.mean_diff.plot();\n\n/Users/jonathananns/GitHub/DABEST-python/dabest/plot_tools.py:2778: UserWarning: 5.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\n/Users/jonathananns/GitHub/DABEST-python/dabest/plot_tools.py:2778: UserWarning: 10.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\n\n\n\n\n\n\n\n\n\nCreate a shared control Cumming plot.\n\nmy_shared_control = dabest.load(df, id_col = \"ID\",\n                                 idx=(\"Control 1\", \"Test 1\",\n                                          \"Test 2\", \"Test 3\"))\nfig6 = my_shared_control.mean_diff.plot();\n\n/Users/jonathananns/GitHub/DABEST-python/dabest/plot_tools.py:2778: UserWarning: 10.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\n\n\n\n\n\n\n\n\n\nCreate a repeated meausures (against baseline) Slopeplot.\n\nmy_rm_baseline = dabest.load(df, id_col = \"ID\", paired = \"baseline\",\n                                 idx=(\"Control 1\", \"Test 1\",\n                                          \"Test 2\", \"Test 3\"))\nfig7 = my_rm_baseline.mean_diff.plot();\n\n\n\n\n\n\n\n\nCreate a repeated meausures (sequential) Slopeplot.\n\nmy_rm_sequential = dabest.load(df, id_col = \"ID\", paired = \"sequential\",\n                                 idx=(\"Control 1\", \"Test 1\",\n                                          \"Test 2\", \"Test 3\"))\nfig8 = my_rm_sequential.mean_diff.plot();\n\n\n\n\n\n\n\n\n\n\n\n\nPermutationTest\n\n PermutationTest (control:&lt;built-infunctionarray&gt;, test:&lt;built-\n                  infunctionarray&gt;, effect_size:str, is_paired:str=None,\n                  permutation_count:int=5000, random_seed:int=12345,\n                  ps_adjust:bool=False, **kwargs)\n\nA class to compute and report permutation tests.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncontrol\narray\n\n\n\n\ntest\narray\n\nThese should be numerical iterables.\n\n\neffect_size\nstr\n\nAny one of the following are accepted inputs: ‚Äòmean_diff‚Äô, ‚Äòmedian_diff‚Äô, ‚Äòcohens_d‚Äô, ‚Äòhedges_g‚Äô, or ‚Äòcliffs_delta‚Äô\n\n\nis_paired\nstr\nNone\n\n\n\npermutation_count\nint\n5000\nThe number of permutations (reshuffles) to perform.\n\n\nrandom_seed\nint\n12345\nrandom_seed is used to seed the random number generator during bootstrap resampling. This ensures that the generated permutations are replicable.\n\n\nps_adjust\nbool\nFalse\nIf True, the p-value is adjusted according to Phipson & Smyth (2010).# https://doi.org/10.2202/1544-6115.1585\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\nReturns\npy:class:PermutationTest object:\n\ndifference:float The effect size of the difference between the control and the test.effect_size:string The type of effect size reported.\n\n\n\nNotes:\nThe basic concept of permutation tests is the same as that behind bootstrapping. In an ‚Äúexact‚Äù permutation test, all possible resuffles of the control and test labels are performed, and the proportion of effect sizes that equal or exceed the observed effect size is computed. This is the probability, under the null hypothesis of zero difference between test and control groups, of observing the effect size: the p-value of the Student‚Äôs t-test.\nExact permutation tests are impractical: computing the effect sizes for all reshuffles quickly exceeds trivial computational loads. A control group and a test group both with 10 observations each would have a total of \\(20!\\) or \\(2.43 \\times {10}^{18}\\) reshuffles. Therefore, in practice, ‚Äúapproximate‚Äù permutation tests are performed, where a sufficient number of reshuffles are performed (5,000 or 10,000), from which the p-value is computed.\nMore information can be found here.\n\nExample: permutation test\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest = norm.rvs(loc=0.5, size=30, random_state=12345)\nperm_test = dabest.PermutationTest(control, test, \n                                   effect_size=\"mean_diff\", \n                                   is_paired=None)\nperm_test\n\n5000 permutations were taken. The p-value is 0.0758.",
    "crumbs": [
      "Get Started",
      "API",
      "Effectsize objects"
    ]
  },
  {
    "objectID": "API/index.html",
    "href": "API/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of dabest‚Äôs python submodules. This reference documentation is mainly useful for people looking to customise or build on top of dabest, or wanting detailed information about how dabest works.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\nLoading Data\n\n\nLoading data and relevant groups\n\n\n\n\n\n\nDabest object\n\n\nMain class for estimating statistics and generating plots.\n\n\n\n\n\n\nBootstrap\n\n\n\n\n\n\n\n\n\nForest plot\n\n\nCreating forest plots from contrast objects.\n\n\n\n\n\n\nPlot\n\n\nCreating estimation plots.\n\n\n\n\n\n\nplot_tools\n\n\nA set of convenience functions used for producing plots in dabest.\n\n\n\n\n\n\neffsize\n\n\nA range of functions to compute various effect sizes.\n\n\n\n\n\n\nconfint_1group\n\n\nA range of functions to compute bootstraps for a single sample.\n\n\n\n\n\n\nconfint_2group_diff\n\n\nA range of functions to compute bootstraps for the mean difference\n\n\n\n\n\n\nDelta objects\n\n\nAuxiliary delta classes for estimating statistics and generating plots.\n\n\n\n\n\n\nmisc_tools\n\n\nConvenience functions that don‚Äôt directly deal with plotting or bootstrap computations are placed here.\n\n\n\n\n\n\nEffectsize objects\n\n\nThe auxiliary classes involved in the computations of bootstrapped effect sizes.\n\n\n\n\n\n\nprecompile\n\n\nA tool to pre-compile Numba functions for speeding up DABEST bootstrapping\n\n\n\n\n\n\nmulti\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "API"
    ]
  },
  {
    "objectID": "API/plot_tools.html",
    "href": "API/plot_tools.html",
    "title": "plot_tools",
    "section": "",
    "text": "source\n\nadd_counts_to_prop_plots\n\n add_counts_to_prop_plots (plot_data:pandas.core.frame.DataFrame,\n                           xvar:str, yvar:str,\n                           rawdata_axes:matplotlib.axes._axes.Axes,\n                           horizontal:bool, is_paired:bool,\n                           prop_sample_counts_kwargs:dict)\n\nAdd counts to the proportion plots.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplot_data\nDataFrame\nDataframe of the plot data.\n\n\nxvar\nstr\nColumn name of the x variable.\n\n\nyvar\nstr\nColumn name of the y variable.\n\n\nrawdata_axes\nAxes\nMatplotlib axis object to plot on.\n\n\nhorizontal\nbool\nIf the plot is horizontal.\n\n\nis_paired\nbool\nWhether the data is paired.\n\n\nprop_sample_counts_kwargs\ndict\nKeyword arguments for the sample counts.\n\n\n\n\nsource\n\n\ntable_for_horizontal_plots\n\n table_for_horizontal_plots (effectsize_df:object,\n                             ax:matplotlib.axes._axes.Axes,\n                             contrast_axes:matplotlib.axes._axes.Axes,\n                             ticks_to_plot:list, show_mini_meta:bool,\n                             show_delta2:bool, table_kwargs:dict,\n                             ticks_to_skip:list)\n\nAdd table axes for showing the deltas for horizontal plots.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neffectsize_df\nobject\nEffect size DABEST object.\n\n\nax\nAxes\nMatplotlib axis object to plot the table axes.\n\n\ncontrast_axes\nAxes\nMatplotlib axis object to plot the contrast axes.\n\n\nticks_to_plot\nlist\nList of indices of the contrast objects.\n\n\nshow_mini_meta\nbool\nWhether to show the mini meta-analysis.\n\n\nshow_delta2\nbool\nWhether to show the delta-delta.\n\n\ntable_kwargs\ndict\nKeyword arguments for the table.\n\n\nticks_to_skip\nlist\n\n\n\n\n\nsource\n\n\nbarplotter\n\n barplotter (xvar:str, yvar:str, all_plot_groups:list,\n             rawdata_axes:matplotlib.axes._axes.Axes,\n             plot_data:pandas.core.frame.DataFrame, raw_colors:str,\n             plot_palette_raw:dict, color_col:str, barplot_kwargs:dict,\n             horizontal:bool)\n\nAdd bars to the raw data plot.\n\n\n\n\nType\nDetails\n\n\n\n\nxvar\nstr\nColumn name of the x variable.\n\n\nyvar\nstr\nColumn name of the y variable.\n\n\nall_plot_groups\nlist\nList of all plot groups.\n\n\nrawdata_axes\nAxes\nMatplotlib axis object to plot on.\n\n\nplot_data\nDataFrame\nDataframe of the plot data.\n\n\nraw_colors\nstr\nColor of the bar.\n\n\nplot_palette_raw\ndict\nDictionary of colors used in the bar plot.\n\n\ncolor_col\nstr\nColumn name of the color column.\n\n\nbarplot_kwargs\ndict\nKeyword arguments for the barplot.\n\n\nhorizontal\nbool\nIf the plot is horizontal.\n\n\n\n\nsource\n\n\ngridkey_plotter\n\n gridkey_plotter (is_paired:bool, idx:list, all_plot_groups:list,\n                  gridkey:list, rawdata_axes:matplotlib.axes._axes.Axes,\n                  contrast_axes:matplotlib.axes._axes.Axes,\n                  plot_data:pandas.core.frame.DataFrame, xvar:str,\n                  yvar:str, results:pandas.core.frame.DataFrame,\n                  show_delta2:bool, show_mini_meta:bool, x1_level:list,\n                  experiment_label:list, float_contrast:bool,\n                  horizontal:bool, delta_delta:object, mini_meta:object,\n                  effect_size:str, gridkey_kwargs:dict)\n\nAdd gridkey to the contrast plot.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nis_paired\nbool\nWhether the data is paired.\n\n\nidx\nlist\nList of indices of the contrast objects.\n\n\nall_plot_groups\nlist\nList of all plot groups.\n\n\ngridkey\nlist\nList of gridkey rows.\n\n\nrawdata_axes\nAxes\nMatplotlib axis object for the raw data.\n\n\ncontrast_axes\nAxes\nMatplotlib axis object for the contrast data.\n\n\nplot_data\nDataFrame\nDataframe of the plot data.\n\n\nxvar\nstr\nColumn name of the x variable.\n\n\nyvar\nstr\nColumn name of the y variable.\n\n\nresults\nDataFrame\nDataframe of contrast object comparisons.\n\n\nshow_delta2\nbool\nWhether to show the delta-delta.\n\n\nshow_mini_meta\nbool\nWhether to show the mini meta-analysis.\n\n\nx1_level\nlist\nList of x1 levels.\n\n\nexperiment_label\nlist\nList of experiment labels.\n\n\nfloat_contrast\nbool\nWhether the DABEST plot uses Gardner-Altman or Cummings\n\n\nhorizontal\nbool\nIf the plot is horizontal.\n\n\ndelta_delta\nobject\ndelta-delta object.\n\n\nmini_meta\nobject\nMini meta-analysis object.\n\n\neffect_size\nstr\nType of effect size to plot\n\n\ngridkey_kwargs\ndict\nKeyword arguments for the gridkey.\n\n\n\n\nsource\n\n\neffect_size_curve_plotter\n\n effect_size_curve_plotter (ticks_to_plot:list,\n                            ticks_for_baseline_ec:list,\n                            results:pandas.core.frame.DataFrame,\n                            ci_type:str,\n                            contrast_axes:matplotlib.axes._axes.Axes,\n                            contrast_kwargs:dict,\n                            bootstraps_color_by_group:bool,\n                            plot_palette_contrast:dict, horizontal:bool,\n                            contrast_marker_kwargs:dict,\n                            contrast_errorbar_kwargs:dict, idx:list,\n                            is_paired:bool, contrast_paired_lines:bool,\n                            contrast_paired_lines_kwargs:dict,\n                            show_baseline_ec:bool=False)\n\nAdd effect size curves to the contrast plot.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nticks_to_plot\nlist\n\nList of indices of the contrast objects.\n\n\nticks_for_baseline_ec\nlist\n\nList of indices of the baseline effect curve objects.\n\n\nresults\nDataFrame\n\nDataframe of contrast object comparisons.\n\n\nci_type\nstr\n\nType of confidence interval to plot.\n\n\ncontrast_axes\nAxes\n\nMatplotlib axis object to plot on.\n\n\ncontrast_kwargs\ndict\n\nKeyword arguments for the violinplot.\n\n\nbootstraps_color_by_group\nbool\n\nWhether to color the bootstraps by group.\n\n\nplot_palette_contrast\ndict\n\nDictionary of colors used in the contrast plot.\n\n\nhorizontal\nbool\n\nIf the plot is horizontal.\n\n\ncontrast_marker_kwargs\ndict\n\n\n\n\ncontrast_errorbar_kwargs\ndict\n\n\n\n\nidx\nlist\n\nList of indices of the raw groups.\n\n\nis_paired\nbool\n\nWhether the data is paired.\n\n\ncontrast_paired_lines\nbool\n\nWhether to add lines for repeated measures data.\n\n\ncontrast_paired_lines_kwargs\ndict\n\nKeyword arguments for the repeated measures lines.\n\n\nshow_baseline_ec\nbool\nFalse\nWhether to show the baseline effect curve.\n\n\n\n\nsource\n\n\nplot_minimeta_or_deltadelta_violins\n\n plot_minimeta_or_deltadelta_violins (dabest_obj:object, type:str,\n                                      ci_type:str, rawdata_axes:matplotlib\n                                      .axes._axes.Axes, contrast_axes:matp\n                                      lotlib.axes._axes.Axes,\n                                      contrast_kwargs:dict,\n                                      contrast_xtick_labels:list,\n                                      effect_size:str, plot_kwargs:dict,\n                                      horizontal:bool, show_pairs:bool,\n                                      contrast_marker_kwargs:dict,\n                                      contrast_errorbar_kwargs:dict)\n\nAdd mini meta-analysis or delta-delta violin plots to the contrast plot.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndabest_obj\nobject\nDABEST Effectsize object delta-delta or mini_meta\n\n\ntype\nstr\n\n\n\nci_type\nstr\nType of confidence interval to plot.\n\n\nrawdata_axes\nAxes\nMatplotlib axis object to plot on.\n\n\ncontrast_axes\nAxes\nMatplotlib axis object to plot on.\n\n\ncontrast_kwargs\ndict\nKeyword arguments for the violinplot.\n\n\ncontrast_xtick_labels\nlist\nList of xtick labels for the contrast plot.\n\n\neffect_size\nstr\nType of effect size to plot.\n\n\nplot_kwargs\ndict\nKeyword arguments for the plot.\n\n\nhorizontal\nbool\nIf the plot is horizontal.\n\n\nshow_pairs\nbool\nWhether the data is paired and shown in pairs.\n\n\ncontrast_marker_kwargs\ndict\n\n\n\ncontrast_errorbar_kwargs\ndict\n\n\n\n\n\nsource\n\n\nslopegraph_plotter\n\n slopegraph_plotter (dabest_obj:object,\n                     plot_data:pandas.core.frame.DataFrame, xvar:str,\n                     yvar:str, color_col:str, plot_palette_raw:dict,\n                     slopegraph_kwargs:dict,\n                     rawdata_axes:matplotlib.axes._axes.Axes,\n                     ytick_color:str, temp_idx:list, horizontal:bool,\n                     temp_all_plot_groups:list, plot_kwargs:dict,\n                     group_summaries_kwargs:dict)\n\nAdd slopegraph to the rawdata axes.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndabest_obj\nobject\nDABEST object.\n\n\nplot_data\nDataFrame\nDataframe of the plot data.\n\n\nxvar\nstr\nColumn name of the x variable.\n\n\nyvar\nstr\nColumn name of the y variable.\n\n\ncolor_col\nstr\nColumn name of the color column.\n\n\nplot_palette_raw\ndict\nDictionary of colors used in the plot.\n\n\nslopegraph_kwargs\ndict\nKeyword arguments for the slopegraph.\n\n\nrawdata_axes\nAxes\nMatplotlib axis object to plot on.\n\n\nytick_color\nstr\nColor of the yticks.\n\n\ntemp_idx\nlist\nList of indices of the contrast objects.\n\n\nhorizontal\nbool\nIf the plotting will be in horizontal format.\n\n\ntemp_all_plot_groups\nlist\nList of all plot groups.\n\n\nplot_kwargs\ndict\nKeyword arguments for the plot.\n\n\ngroup_summaries_kwargs\ndict\nKeyword arguments for group summaries, if applicable.\n\n\n\n\nsource\n\n\ndelta_dots_plotter\n\n delta_dots_plotter (plot_data:pandas.core.frame.DataFrame,\n                     contrast_axes:matplotlib.axes._axes.Axes,\n                     delta_id_col:str, idx:list, xvar:str, yvar:str,\n                     is_paired:bool, color_col:str, float_contrast:bool,\n                     plot_palette_raw:dict, delta_dot_kwargs:dict,\n                     horizontal:bool)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplot_data\nDataFrame\nDataframe of the plot data.\n\n\ncontrast_axes\nAxes\nMatplotlib axis object to plot on.\n\n\ndelta_id_col\nstr\nColumn name of the delta id column.\n\n\nidx\nlist\nList of indices of the contrast objects.\n\n\nxvar\nstr\nColumn name of the x variable.\n\n\nyvar\nstr\nColumn name of the y variable.\n\n\nis_paired\nbool\nWhether the data is paired.\n\n\ncolor_col\nstr\nColumn name of the color column.\n\n\nfloat_contrast\nbool\nWhether the DABEST plot uses Gardner-Altman or Cummings\n\n\nplot_palette_raw\ndict\nDictionary of colors used in the plot.\n\n\ndelta_dot_kwargs\ndict\nKeyword arguments for the delta dots.\n\n\nhorizontal\nbool\nIf the rawplot is horizontal.\n\n\n\n\nsource\n\n\ndelta_text_plotter\n\n delta_text_plotter (results:pandas.core.frame.DataFrame,\n                     ax_to_plot:object, ticks_to_plot:list,\n                     delta_text_kwargs:dict, color_col:str,\n                     plot_palette_raw:dict, show_pairs:bool,\n                     float_contrast:bool, extra_delta:float,\n                     bootstraps_color_by_group:bool=False)\n\nAdd delta text to the contrast plot.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nresults\nDataFrame\n\nDataframe of contrast object comparisons.\n\n\nax_to_plot\nobject\n\nMatplotlib axis object to plot on.\n\n\nticks_to_plot\nlist\n\nList of indices of the contrast objects.\n\n\ndelta_text_kwargs\ndict\n\nKeyword arguments for the delta text.\n\n\ncolor_col\nstr\n\nColumn name of the color column.\n\n\nplot_palette_raw\ndict\n\nDictionary of colors used in the plot.\n\n\nshow_pairs\nbool\n\nWhether the data is paired and show pairs.\n\n\nfloat_contrast\nbool\n\nWhether the DABEST plot uses Gardner-Altman or Cummings.\n\n\nextra_delta\nfloat\n\nThe extra mini-meta or delta-delta value if applicable.\n\n\nbootstraps_color_by_group\nbool\nFalse\nWhether to color the bootstraps by group. Default is False.\n\n\n\n\nsource\n\n\nadd_bars_to_plot\n\n add_bars_to_plot (bar_dict:dict, ax:matplotlib.axes._axes.Axes,\n                   bar_kwargs:dict)\n\nAdd bars to the relevant axes.\n\n\n\n\nType\nDetails\n\n\n\n\nbar_dict\ndict\nDictionary of bar values.\n\n\nax\nAxes\nMatplotlib axis object to plot on.\n\n\nbar_kwargs\ndict\nKeyword arguments for the bars.\n\n\n\n\nsource\n\n\nsankeydiag\n\n sankeydiag (data:pandas.core.frame.DataFrame, xvar:str, yvar:str,\n             temp_all_plot_groups:list, idx:list, temp_idx:list,\n             left_labels:list=None, right_labels:list=None,\n             palette:str|dict=None, ax=None, flow:bool=True,\n             sankey:bool=True, one_sankey:bool=False, width:float=0.4,\n             right_color:bool=False, align:str='center', alpha:float=0.65,\n             horizontal:bool=False, **kwargs)\n\nRead in melted pd.DataFrame, and draw multiple sankey diagram on a single axes using the value in column yvar according to the value in column xvar left_idx in the column xvar is on the left side of each sankey diagram right_idx in the column xvar is on the right side of each sankey diagram\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nDataFrame\n\n\n\n\nxvar\nstr\n\nx column to be plotted.\n\n\nyvar\nstr\n\ny column to be plotted.\n\n\ntemp_all_plot_groups\nlist\n\n\n\n\nidx\nlist\n\n\n\n\ntemp_idx\nlist\n\n\n\n\nleft_labels\nlist\nNone\nlabels for the left side of the diagram. The diagram will be sorted by these labels.\n\n\nright_labels\nlist\nNone\nlabels for the right side of the diagram. The diagram will be sorted by these labels.\n\n\npalette\nstr | dict\nNone\n\n\n\nax\nNoneType\nNone\nmatplotlib axes to be drawn on\n\n\nflow\nbool\nTrue\nif True, draw the sankey in a flow, else draw 1 vs 1 Sankey diagram for each group comparison\n\n\nsankey\nbool\nTrue\nif True, draw the sankey diagram, else draw barplot\n\n\none_sankey\nbool\nFalse\ndetermined by the driver function on plotter.py, if True, draw the sankey diagram across the whole raw data axes\n\n\nwidth\nfloat\n0.4\nthe width of each sankey diagram\n\n\nright_color\nbool\nFalse\nif True, each strip of the diagram will be colored according to the corresponding left labels\n\n\nalign\nstr\ncenter\nthe alignment of each sankey diagram, can be ‚Äòcenter‚Äô or ‚Äòleft‚Äô\n\n\nalpha\nfloat\n0.65\nthe transparency of each strip\n\n\nhorizontal\nbool\nFalse\nif True, the horizontal format for the sankey diagram will be used\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\n\n\nsource\n\n\nsingle_sankey\n\n single_sankey (left:&lt;built-infunctionarray&gt;, right:&lt;built-\n                infunctionarray&gt;, xpos:float=0, left_weight:&lt;built-\n                infunctionarray&gt;=None, right_weight:&lt;built-\n                infunctionarray&gt;=None, colorDict:dict=None,\n                left_labels:list=None, right_labels:list=None, ax=None,\n                flow:bool=True, sankey:bool=True, width=0.5, alpha=0.65,\n                bar_width=0.2, error_bar_on:bool=True, strip_on:bool=True,\n                one_sankey:bool=False, right_color:bool=False,\n                align:str='center', horizontal:bool=False)\n\n*Make a single Sankey diagram showing proportion flow from left to right\nOriginal code from: https://github.com/anazalea/pySankey\nChanges are added to normalize each diagram‚Äôs height to be 1*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nleft\narray\n\ndata on the left of the diagram\n\n\nright\narray\n\ndata on the right of the diagram, len(left) == len(right)\n\n\nxpos\nfloat\n0\nthe starting point on the x-axis\n\n\nleft_weight\narray\nNone\nweights for the left labels, if None, all weights are 1\n\n\nright_weight\narray\nNone\nweights for the right labels, if None, all weights are corresponding left_weight\n\n\ncolorDict\ndict\nNone\ninput format: {‚Äòlabel‚Äô: ‚Äòcolor‚Äô}\n\n\nleft_labels\nlist\nNone\nlabels for the left side of the diagram. The diagram will be sorted by these labels.\n\n\nright_labels\nlist\nNone\nlabels for the right side of the diagram. The diagram will be sorted by these labels.\n\n\nax\nNoneType\nNone\nmatplotlib axes to be drawn on\n\n\nflow\nbool\nTrue\nif True, draw the sankey in a flow, else draw 1 vs 1 Sankey diagram for each group comparison\n\n\nsankey\nbool\nTrue\nif True, draw the sankey diagram, else draw barplot\n\n\nwidth\nfloat\n0.5\n\n\n\nalpha\nfloat\n0.65\n\n\n\nbar_width\nfloat\n0.2\n\n\n\nerror_bar_on\nbool\nTrue\nif True, draw error bar for each group comparison\n\n\nstrip_on\nbool\nTrue\nif True, draw strip for each group comparison\n\n\none_sankey\nbool\nFalse\nif True, only draw one sankey diagram\n\n\nright_color\nbool\nFalse\nif True, each strip of the diagram will be colored according to the corresponding left labels\n\n\nalign\nstr\ncenter\nif ‚Äòcenter‚Äô, the diagram will be centered on each xtick, if ‚Äòedge‚Äô, the diagram will be aligned with the left edge of each xtick\n\n\nhorizontal\nbool\nFalse\nif True, the horizontal format for the sankey diagram will be used\n\n\n\n\nsource\n\n\nwidth_determine\n\n width_determine (labels, data, pos='left')\n\n*Calculates normalized width positions for a set of labels based on their associated data.\nThis function is designed to determine width positions for plotting or graphical representation. It takes into account the cumulative weight of each label in the data and adjusts their positions accordingly. The function allows for adjusting the position of labels to either the ‚Äòleft‚Äô or ‚Äòright‚Äô.\nParameters: labels (list): A list of labels whose width positions are to be calculated. data (DataFrame): A pandas DataFrame containing the data used for calculating width positions. The DataFrame should have columns corresponding to the ‚Äòpos‚Äô and ‚ÄòposWeight‚Äô. pos (str, optional): The position of labels. It can be either ‚Äòleft‚Äô or ‚Äòright‚Äô. Defaults to ‚Äòleft‚Äô.\nReturns: defaultdict: A dictionary where each key is a label and the value is another dictionary with keys ‚Äòbottom‚Äô, ‚Äòtop‚Äô, and ‚Äòpos‚Äô, representing the calculated width positions.\nNote: The function assumes that the data DataFrame contains columns named after the value of ‚Äòpos‚Äô and an additional column named ‚ÄòposWeight‚Äô which represents the weight of each label.*\n\nsource\n\n\nnormalize_dict\n\n normalize_dict (nested_dict, target)\n\n*Normalizes the values in a nested dictionary based on a target dictionary.\nThis function iterates through a nested dictionary, calculates the sum of values for each key across all sub-dictionaries, and then normalizes these values according to a target dictionary. The normalization is performed such that the values in each sub-dictionary are proportionally scaled to match the corresponding ‚Äòright‚Äô values in the target dictionary.\nParameters: nested_dict (dict of dict): A nested dictionary where each key maps to another dictionary. The values in these inner dictionaries are subject to normalization. target (dict): A dictionary with the target values for normalization. Each key in nested_dict should have a corresponding key in target, and each target[key] should be a dictionary with a ‚Äòright‚Äô key containing the target normalization value.\nReturns: dict: The normalized nested dictionary. The original nested_dict is modified in place.\nNote: - If the sum of values for a particular key in nested_dict is zero, the normalized value is set to 0. - If a key in a sub-dictionary of nested_dict does not exist in the target dictionary, the corresponding ‚Äòright‚Äô value from the target dictionary is directly assigned. - The function modifies the input nested_dict in place and also returns it.*\n\nsource\n\n\ncheck_data_matches_labels\n\n check_data_matches_labels (labels, data, side:str)\n\nFunction to check that the labels and data match in the sankey diagram. And enforce labels and data to be lists. Raises an exception if the labels and data do not match.\n\n\n\n\nType\nDetails\n\n\n\n\nlabels\n\nlist of input labels\n\n\ndata\n\nPandas Series of input data\n\n\nside\nstr\n‚Äòleft‚Äô or ‚Äòright‚Äô on the sankey diagram\n\n\n\n\nsource\n\n\nerror_bar\n\n error_bar (data:pandas.core.frame.DataFrame, x:str, y:str,\n            type:str='mean_sd', offset:float=0.2, ax=None,\n            line_color='black', gap_width_percent=1, pos:list=[0, 1],\n            method:str='gapped_lines', horizontal:bool=False,\n            **kwargs:dict)\n\n*Function to plot the standard deviations as vertical errorbars. The mean is a gap defined by negative space.\nThis function combines the functionality of gapped_lines(), proportional_error_bar(), and sankey_error_bar().*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nDataFrame\n\nThis DataFrame should be in ‚Äòlong‚Äô format.\n\n\nx\nstr\n\nx column to be plotted.\n\n\ny\nstr\n\ny column to be plotted.\n\n\ntype\nstr\nmean_sd\nChoose from [‚Äòmean_sd‚Äô, ‚Äòmedian_quartiles‚Äô]. Plots the summary statistics for each group. If ‚Äòmean_sd‚Äô, then the mean and standard deviation of each group is plotted as a gapped line. If ‚Äòmedian_quantiles‚Äô, then the median and 25th and 75th percentiles of each group is plotted instead.\n\n\noffset\nfloat\n0.2\nGive a single float (that will be used as the x-offset of all gapped lines), or an iterable containing the list of x-offsets.\n\n\nax\nNoneType\nNone\nIf a matplotlib Axes object is specified, the gapped lines will be plotted in order on this axes. If None, the current axes (plt.gca()) is used.\n\n\nline_color\nstr\nblack\nThe color of the gapped lines.\n\n\ngap_width_percent\nint\n1\nThe width of the gap in the gapped lines, as a percentage of the y-axis span.\n\n\npos\nlist\n[0, 1]\n\n\n\nmethod\nstr\ngapped_lines\nThe method to use for drawing the error bars. Options are: ‚Äògapped_lines‚Äô, ‚Äòproportional_error_bar‚Äô, and ‚Äòsankey_error_bar‚Äô.\n\n\nhorizontal\nbool\nFalse\nIf True, the error bars will be horizontal. If False, the error bars will be vertical.\n\n\nkwargs\ndict\n\n\n\n\n\n\nsource\n\n\nget_swarm_spans\n\n get_swarm_spans (coll)\n\nGiven a matplotlib Collection, will obtain the x and y spans for the collection. Will return None if this fails.\n\nsource\n\n\nhalfviolin\n\n halfviolin (v, half='right', fill_color='k', alpha=1, line_color='k',\n             line_width=0)\n\n\nsource\n\n\nSwarmPlot\n\n SwarmPlot (data:pandas.core.frame.DataFrame, x:str, y:str,\n            ax:matplotlib.axes._axes.Axes, order:List=None, hue:str=None,\n            palette:Union[Iterable,str]='black', zorder:float=1,\n            size:float=5, side:str='center', jitter:float=1,\n            horizontal:bool=False)\n\nInitialize a SwarmPlot instance.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nDataFrame\n\nThe input data as a pandas DataFrame.\n\n\nx\nstr\n\nThe column in the DataFrame to be used as the x-axis.\n\n\ny\nstr\n\nThe column in the DataFrame to be used as the y-axis.\n\n\nax\nAxes\n\nMatplotlib axes.Axes object for which the plot would be drawn on.\n\n\norder\nList\nNone\nThe order in which x-axis categories should be displayed. Default is None.\n\n\nhue\nstr\nNone\nThe column in the DataFrame that determines the grouping for color.If None (by default), it assumes that it is being grouped by x.\n\n\npalette\nUnion\nblack\nThe color palette to be used for plotting. Default is ‚Äúblack‚Äù.\n\n\nzorder\nfloat\n1\nThe z-order for drawing the swarm plot wrt other matplotlib drawings. Default is 1.\n\n\nsize\nfloat\n5\n\n\n\nside\nstr\ncenter\nThe side on which points are swarmed (‚Äúcenter‚Äù, ‚Äúleft‚Äù, or ‚Äúright‚Äù). Default is ‚Äúcenter‚Äù.\n\n\njitter\nfloat\n1\nDetermines the distance between points. Default is 1.\n\n\nhorizontal\nbool\nFalse\nIf True, the swarm plot is drawn horizontally. Default is False.\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nswarmplot\n\n swarmplot (data:pandas.core.frame.DataFrame, x:str, y:str,\n            ax:matplotlib.axes._axes.Axes, order:List=None, hue:str=None,\n            palette:Union[Iterable,str]='black', zorder:float=1,\n            size:float=5, side:str='center', jitter:float=1,\n            filled:Union[bool,List,Tuple]=True, is_drop_gutter:bool=True,\n            gutter_limit:float=0.5, horizontal:bool=False, **kwargs)\n\nAPI to plot a swarm plot.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nDataFrame\n\nThe input data as a pandas DataFrame.\n\n\nx\nstr\n\nThe column in the DataFrame to be used as the x-axis.\n\n\ny\nstr\n\nThe column in the DataFrame to be used as the y-axis.\n\n\nax\nAxes\n\nMatplotlib axes.Axes object for which the plot would be drawn on. Default is None.\n\n\norder\nList\nNone\nThe order in which x-axis categories should be displayed. Default is None.\n\n\nhue\nstr\nNone\nThe column in the DataFrame that determines the grouping for color.If None (by default), it assumes that it is being grouped by x.\n\n\npalette\nUnion\nblack\nThe color palette to be used for plotting. Default is ‚Äúblack‚Äù.\n\n\nzorder\nfloat\n1\nThe z-order for drawing the swarm plot wrt other matplotlib drawings. Default is 1.\n\n\nsize\nfloat\n5\n\n\n\nside\nstr\ncenter\nThe side on which points are swarmed (‚Äúcenter‚Äù, ‚Äúleft‚Äù, or ‚Äúright‚Äù). Default is ‚Äúcenter‚Äù.\n\n\njitter\nfloat\n1\nDetermines the distance between points. Default is 1.\n\n\nfilled\nUnion\nTrue\nDetermines whether the dots in the swarmplot are filled or not. If set to False,dots are not filled. If provided as a List or Tuple, it should contain boolean values,each corresponding to a swarm group in order, indicating whether the dot should befilled or not.\n\n\nis_drop_gutter\nbool\nTrue\nIf True, drop points that hit the gutters; otherwise, readjust them.\n\n\ngutter_limit\nfloat\n0.5\nThe limit for points hitting the gutters.\n\n\nhorizontal\nbool\nFalse\nIf True, the swarm plot is drawn horizontally. Default is False.\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\nReturns\naxes.Axes\n\nMatplotlib axes.Axes object for which the swarm plot has been drawn on.",
    "crumbs": [
      "Get Started",
      "API",
      "plot_tools"
    ]
  },
  {
    "objectID": "API/forest_plot.html",
    "href": "API/forest_plot.html",
    "title": "Forest plot",
    "section": "",
    "text": "source\n\nforest_plot\n\n forest_plot (data:list, idx:Optional[list[int]]=None,\n              ax:Optional[matplotlib.axes._axes.Axes]=None,\n              fig_size:tuple[int,int]=None, effect_size:str='mean_diff',\n              ci_type='bca', horizontal:bool=False, marker_size:int=10,\n              custom_palette:Union[dict,list,str,NoneType]=None,\n              contrast_alpha:float=0.8, contrast_desat:float=1,\n              labels:list[str]=None, labels_rotation:int=None,\n              labels_fontsize:int=10, title:str=None,\n              title_fontsize:int=16, ylabel:str=None,\n              ylabel_fontsize:int=12,\n              ylim:Optional[list[float,float]]=None,\n              yticks:Optional[list[float]]=None,\n              yticklabels:Optional[list[str]]=None,\n              remove_spines:bool=True, delta_text:bool=True,\n              delta_text_kwargs:dict=None, contrast_bars:bool=True,\n              contrast_bars_kwargs:dict=None,\n              reference_band:list|tuple=None,\n              reference_band_kwargs:dict=None,\n              violin_kwargs:Optional[dict]=None,\n              zeroline_kwargs:Optional[dict]=None,\n              marker_kwargs:Optional[dict]=None,\n              errorbar_kwargs:Optional[dict]=None)\n\nCustom function that generates a forest plot from given contrast objects, suitable for a range of data analysis types, including those from packages like DABEST-python.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nlist\n\nList of contrast objects.\n\n\nidx\nOptional\nNone\nList of indices to select from the contrast objects if delta-delta experiment. If None, only the delta-delta objects are plotted.\n\n\nax\nOptional\nNone\nMatplotlib Axes object for the plot; creates new if None.additional_plotting_kwargs : Optional[dict], default=NoneFurther customization arguments for the plot.\n\n\nfig_size\ntuple\nNone\nFigure size for the plot.\n\n\neffect_size\nstr\nmean_diff\nType of effect size to plot (e.g., ‚Äòmean_diff‚Äô, hedges_g or ‚Äòdelta_g‚Äô).\n\n\nci_type\nstr\nbca\nType of confidence interval to plot (bca‚Äô or ‚Äòpct‚Äô)\n\n\nhorizontal\nbool\nFalse\nIf True, the plot will be horizontal.\n\n\nmarker_size\nint\n10\nMarker size for plotting effect size dots.\n\n\ncustom_palette\nUnion\nNone\nCustom color palette for the plot.\n\n\ncontrast_alpha\nfloat\n0.8\nTransparency level for violin plots.\n\n\ncontrast_desat\nfloat\n1\nSaturation level for violin plots.\n\n\nlabels\nlist\nNone\nLabels for each contrast. If None, defaults to ‚ÄòContrast 1‚Äô, ‚ÄòContrast 2‚Äô, etc.\n\n\nlabels_rotation\nint\nNone\nRotation angle for contrast labels.\n\n\nlabels_fontsize\nint\n10\nFont size for contrast labels.\n\n\ntitle\nstr\nNone\nPlot title, summarizing the visualized data.\n\n\ntitle_fontsize\nint\n16\nFont size for the plot title.\n\n\nylabel\nstr\nNone\nLabel for the y-axis, describing the plotted data or effect size.\n\n\nylabel_fontsize\nint\n12\nFont size for the y-axis label.\n\n\nylim\nOptional\nNone\nLimits for the y-axis.\n\n\nyticks\nOptional\nNone\nCustom y-ticks for the plot.\n\n\nyticklabels\nOptional\nNone\nCustom y-tick labels for the plot.\n\n\nremove_spines\nbool\nTrue\nIf True, removes plot spines (except the relevant dependent variable spine).\n\n\ndelta_text\nbool\nTrue\nIf True, it adds text next to each curve representing the effect size value.\n\n\ndelta_text_kwargs\ndict\nNone\nAdditional keyword arguments for the delta_text.\n\n\ncontrast_bars\nbool\nTrue\nIf True, it adds bars from the zeroline to the effect size curve.\n\n\ncontrast_bars_kwargs\ndict\nNone\nAdditional keyword arguments for the contrast_bars.\n\n\nreference_band\nlist | tuple\nNone\n\n\n\nreference_band_kwargs\ndict\nNone\nAdditional keyword arguments for the reference_band.\n\n\nviolin_kwargs\nOptional\nNone\nAdditional arguments for violin plot customization.\n\n\nzeroline_kwargs\nOptional\nNone\nAdditional arguments for the zero line customization.\n\n\nmarker_kwargs\nOptional\nNone\nAdditional arguments for the effect size marker customization.\n\n\nerrorbar_kwargs\nOptional\nNone\nAdditional arguments for the effect size error bar customization.\n\n\nReturns\nFigure\n\nThe matplotlib figure object with the generated forest plot.\n\n\n\n\nsource\n\n\ncolor_palette\n\n color_palette (custom_palette, labels, number_of_curves_to_plot,\n                contrast_desat)\n\n\nsource\n\n\nget_kwargs\n\n get_kwargs (violin_kwargs, zeroline_kwargs, horizontal, marker_kwargs,\n             errorbar_kwargs, delta_text_kwargs, contrast_bars_kwargs,\n             reference_band_kwargs, marker_size)\n\n\nsource\n\n\ncheck_for_errors\n\n check_for_errors (**kwargs)\n\n\nsource\n\n\nload_plot_data\n\n load_plot_data (data:List, effect_size:str='mean_diff',\n                 contrast_type:str=None, ci_type:str='bca',\n                 idx:Optional[List[int]]=None)\n\nLoads plot data based on specified effect size and contrast type.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nList\n\n\n\n\neffect_size\nstr\nmean_diff\n\n\n\ncontrast_type\nstr\nNone\n\n\n\nci_type\nstr\nbca\n\n\n\nidx\nOptional\nNone\n\n\n\nReturns\nList",
    "crumbs": [
      "Get Started",
      "API",
      "Forest plot"
    ]
  },
  {
    "objectID": "API/precompile.html",
    "href": "API/precompile.html",
    "title": "precompile",
    "section": "",
    "text": "source\n\nprecompile_all\n\n precompile_all ()\n\nPre-compile all numba functions with dummy data",
    "crumbs": [
      "Get Started",
      "API",
      "precompile"
    ]
  },
  {
    "objectID": "API/misc_tools.html",
    "href": "API/misc_tools.html",
    "title": "misc_tools",
    "section": "",
    "text": "source\n\nprepare_bars_for_plot\n\n prepare_bars_for_plot (bar_type, bar_kwargs, horizontal,\n                        plot_palette_raw, color_col, show_pairs,\n                        bootstraps_color_by_group, plot_data=None,\n                        xvar=None, yvar=None, results=None,\n                        ticks_to_plot=None, extra_delta=None,\n                        reference_band=None, summary_axes=None,\n                        ci_type=None)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbar_type\n\n\n\n\n\nbar_kwargs\n\n\n\n\n\nhorizontal\n\n\n\n\n\nplot_palette_raw\n\n\n\n\n\ncolor_col\n\n\n\n\n\nshow_pairs\n\n\n\n\n\nbootstraps_color_by_group\n\n\n\n\n\nplot_data\nNoneType\nNone\n\n\n\nxvar\nNoneType\nNone\n\n\n\nyvar\nNoneType\nNone\nRaw data\n\n\nresults\nNoneType\nNone\n\n\n\nticks_to_plot\nNoneType\nNone\n\n\n\nextra_delta\nNoneType\nNone\nContrast data\n\n\nreference_band\nNoneType\nNone\n\n\n\nsummary_axes\nNoneType\nNone\n\n\n\nci_type\nNoneType\nNone\nSummary data\n\n\n\n\nsource\n\n\ncolor_picker\n\n color_picker (color_type:str, kwargs:dict, elements:list, color_col:str,\n               show_pairs:bool, color_palette:dict,\n               bootstraps_color_by_group:bool)\n\n\nsource\n\n\nextract_group_summaries\n\n extract_group_summaries (proportional:bool,\n                          rawdata_axes:matplotlib.axes._axes.Axes,\n                          asymmetric_side:str, horizontal:bool,\n                          bootstraps_color_by_group:bool,\n                          plot_palette_raw:list, all_plot_groups:list,\n                          n_groups:int, color_col, ytick_color,\n                          group_summaries_kwargs:dict)\n\nExtract the group summaries for the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nproportional\nbool\nA boolean flag to determine if the plot is for proportional data.\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\nasymmetric_side\nstr\nThe side of the asymmetric error bars.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\nbootstraps_color_by_group\nbool\nA boolean flag to determine if the bootstraps are colored by group.\n\n\nplot_palette_raw\nlist\nA list of the plot palette colors.\n\n\nall_plot_groups\nlist\nA list of all the plot groups.\n\n\nn_groups\nint\nThe number of groups.\n\n\ncolor_col\nstr\nThe name of the color column.\n\n\nytick_color\nstr\nThe color of the y-ticks.\n\n\ngroup_summaries_kwargs\ndict\nKwargs passed to the group summaries.\n\n\n\n\nsource\n\n\nredraw_dependent_spines\n\n redraw_dependent_spines (rawdata_axes:matplotlib.axes._axes.Axes,\n                          contrast_axes:matplotlib.axes._axes.Axes,\n                          redraw_axes_kwargs:dict, float_contrast:bool,\n                          horizontal:bool, show_delta2:bool,\n                          delta2_axes:matplotlib.axes._axes.Axes)\n\nDraw the dependent axis spine lines.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\ncontrast_axes\nAxes\nThe contrast axes.\n\n\nredraw_axes_kwargs\ndict\nKwargs passed to the redraw axes.\n\n\nfloat_contrast\nbool\nA boolean flag to determine if the plot is GA or Cum\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\nshow_delta2\nbool\nA boolean flag to determine if the plot will have a delta-delta effect size.\n\n\ndelta2_axes\nAxes\nThe delta2 axes.\n\n\n\n\nsource\n\n\nredraw_independent_spines\n\n redraw_independent_spines (rawdata_axes:matplotlib.axes._axes.Axes,\n                            contrast_axes:matplotlib.axes._axes.Axes,\n                            horizontal:bool, two_col_sankey:bool,\n                            ticks_to_start_twocol_sankey:list, idx:list,\n                            is_paired:str, show_pairs:bool,\n                            proportional:bool, ticks_to_skip:list,\n                            temp_idx:list, ticks_to_skip_contrast:list,\n                            redraw_axes_kwargs:dict)\n\nDraw the independent axis spine lines.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\ncontrast_axes\nAxes\nThe contrast axes.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\ntwo_col_sankey\nbool\nA boolean flag to determine if the plot is for two-col sankey.\n\n\nticks_to_start_twocol_sankey\nlist\nA list of ticks to start for sankey plot.\n\n\nidx\nlist\nA list of indices.\n\n\nis_paired\nstr\nA boolean flag to determine if the data is paired.\n\n\nshow_pairs\nbool\nA boolean flag to determine if pairs should be shown.\n\n\nproportional\nbool\nA boolean flag to determine if the plot is proportional/binary.\n\n\nticks_to_skip\nlist\nA list of ticks to be skipped in the raw data axes.\n\n\ntemp_idx\nlist\nA temporary list of indices to be used for skipping ticks in the raw data axes.\n\n\nticks_to_skip_contrast\nlist\nA list of ticks to be skipped in the contrast axes.\n\n\nredraw_axes_kwargs\ndict\nKwargs passed to the redraw axes.\n\n\n\n\nsource\n\n\ndraw_zeroline\n\n draw_zeroline (ax:matplotlib.axes._axes.Axes, horizontal:bool,\n                reflines_kwargs:dict, extra_delta:bool)\n\nDraw the independent axis spine lines.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nax\nAxes\nThe contrast data axes.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\nreflines_kwargs\ndict\nAdditional keyword arguments to be passed to the zeroline.\n\n\nextra_delta\nbool\nA boolean flag to determine if the plot includes an extra delta (delta-delta or mini-meta).\n\n\n\n\nsource\n\n\ngardner_altman_adjustments\n\n gardner_altman_adjustments (effect_size_type:str,\n                             plot_data:pandas.core.frame.DataFrame,\n                             xvar:str, yvar:str, current_control:str,\n                             current_group:str,\n                             rawdata_axes:matplotlib.axes._axes.Axes,\n                             contrast_axes:matplotlib.axes._axes.Axes,\n                             results:pandas.core.frame.DataFrame,\n                             current_effsize:float, is_paired:bool,\n                             one_sankey:bool, reflines_kwargs:dict,\n                             redraw_axes_kwargs:dict)\n\nAesthetic adjustments specific to Gardner-Altman plots (float_contrast=True).\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neffect_size_type\nstr\nThe type of effect size.\n\n\nplot_data\nDataFrame\nA dataframe of plot data.\n\n\nxvar\nstr\nThe name of the x-axis variable.\n\n\nyvar\nstr\nThe name of the y-axis variable.\n\n\ncurrent_control\nstr\nThe name of the current control group.\n\n\ncurrent_group\nstr\nThe name of the current test group.\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\ncontrast_axes\nAxes\nThe contrast axes.\n\n\nresults\nDataFrame\nA dataframe of the results.\n\n\ncurrent_effsize\nfloat\nThe current effect size.\n\n\nis_paired\nbool\nA boolean flag to determine if the plot is for paired data.\n\n\none_sankey\nbool\nA boolean flag to determine if the plot is for a single sankey diagram.\n\n\nreflines_kwargs\ndict\nKwargs passed to the reference lines.\n\n\nredraw_axes_kwargs\ndict\nKwargs passed to the redraw axes.\n\n\n\n\nsource\n\n\nshow_legend\n\n show_legend (legend_labels:list, legend_handles:list,\n              rawdata_axes:matplotlib.axes._axes.Axes,\n              contrast_axes:matplotlib.axes._axes.Axes,\n              table_axes:matplotlib.axes._axes.Axes, float_contrast:bool,\n              show_pairs:bool, horizontal:bool, legend_kwargs:dict,\n              table_kwargs:dict)\n\nShow the legend for the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nlegend_labels\nlist\nA list of legend labels.\n\n\nlegend_handles\nlist\nA list of legend handles.\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\ncontrast_axes\nAxes\nThe contrast axes.\n\n\ntable_axes\nAxes\nThe table axes.\n\n\nfloat_contrast\nbool\nA boolean flag to determine if the plot is GA or Cumming format.\n\n\nshow_pairs\nbool\nA boolean flag to determine if the plot will show the paired data.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\nlegend_kwargs\ndict\nKwargs passed to the legend function.\n\n\ntable_kwargs\ndict\n\n\n\n\n\nsource\n\n\nset_xaxis_ticks_and_lims\n\n set_xaxis_ticks_and_lims (show_delta2:bool, show_mini_meta:bool,\n                           rawdata_axes:matplotlib.axes._axes.Axes,\n                           contrast_axes:matplotlib.axes._axes.Axes,\n                           show_pairs:bool, float_contrast:bool,\n                           ticks_to_skip:list, contrast_xtick_labels:list,\n                           plot_kwargs:dict, proportional:bool,\n                           horizontal:bool)\n\nSet the x-axis/yaxis ticks and limits for the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nshow_delta2\nbool\nA boolean flag to determine if the plot will have a delta-delta effect size.\n\n\nshow_mini_meta\nbool\nA boolean flag to determine if the plot will have a mini-meta effect size.\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\ncontrast_axes\nAxes\nThe contrast axes.\n\n\nshow_pairs\nbool\nA boolean flag to determine if the plot will show the paired data.\n\n\nfloat_contrast\nbool\nA boolean flag to determine if the plot is a GA or Cumming design.\n\n\nticks_to_skip\nlist\nA list of ticks to skip.\n\n\ncontrast_xtick_labels\nlist\nA list of contrast xtick labels.\n\n\nplot_kwargs\ndict\nKwargs passed to the plot function.\n\n\nproportional\nbool\n\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\n\n\nsource\n\n\nextract_contrast_plotting_ticks\n\n extract_contrast_plotting_ticks (is_paired:bool, show_pairs:bool,\n                                  two_col_sankey:bool, plot_groups:list,\n                                  idx:list, sankey_control_group:list)\n\nExtract the contrast plotting ticks from the idx object for use in the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nis_paired\nbool\nA boolean flag to determine if the plot is for paired data.\n\n\nshow_pairs\nbool\nA boolean flag to determine if the plot will show the paired data.\n\n\ntwo_col_sankey\nbool\nA boolean flag to determine if the plot will show a two-column sankey diagram.\n\n\nplot_groups\nlist\nA list of the plot groups.\n\n\nidx\nlist\nA list of tuples containing the group names.\n\n\nsankey_control_group\nlist\nA list of the control group names.\n\n\n\n\nsource\n\n\nadd_counts_to_ticks\n\n add_counts_to_ticks (plot_data:pandas.core.frame.DataFrame, xvar:str,\n                      yvar:str, rawdata_axes:matplotlib.axes._axes.Axes,\n                      plot_kwargs:dict, flow:bool, horizontal:bool)\n\nAdd the counts to the raw data axes labels.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplot_data\nDataFrame\nA dataframe of plot data.\n\n\nxvar\nstr\nThe name of the x-axis variable.\n\n\nyvar\nstr\nThe name of the y-axis variable.\n\n\nrawdata_axes\nAxes\nThe raw data axes.\n\n\nplot_kwargs\ndict\nKwargs passed to the plot function.\n\n\nflow\nbool\nWhether sankey flow is enabled or not.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\n\n\nsource\n\n\nget_plot_groups\n\n get_plot_groups (is_paired:bool, idx:list, proportional:bool,\n                  all_plot_groups:list)\n\nExtract the plot groups from the idx object for use in the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nis_paired\nbool\nA boolean flag to determine if the plot is for paired data.\n\n\nidx\nlist\nA list of tuples containing the group names.\n\n\nproportional\nbool\nA boolean flag to determine if the plot is for proportional data.\n\n\nall_plot_groups\nlist\nA list of all the group names.\n\n\n\n\nsource\n\n\ninitialize_fig\n\n initialize_fig (plot_kwargs:dict, dabest_obj:object, show_delta2:bool,\n                 show_mini_meta:bool, is_paired:bool, show_pairs:bool,\n                 proportional:bool, float_contrast:bool,\n                 effect_size_type:str, yvar:str, horizontal:bool,\n                 show_table:bool, color_col:str)\n\nInitialize the figure and axes for the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplot_kwargs\ndict\nKwargs passed to the plot function.\n\n\ndabest_obj\nobject\nA dabest EffectSizeDataFrame object.\n\n\nshow_delta2\nbool\nA boolean flag to determine if the plot will have a delta-delta effect size.\n\n\nshow_mini_meta\nbool\nA boolean flag to determine if the plot will have a mini-meta effect size.\n\n\nis_paired\nbool\nA boolean flag to determine if the plot is for paired data.\n\n\nshow_pairs\nbool\nA boolean flag to determine if the plot will show the paired data.\n\n\nproportional\nbool\nA boolean flag to determine if the plot is for proportional data.\n\n\nfloat_contrast\nbool\nA boolean flag to determine if the plot is for floating contrast data.\n\n\neffect_size_type\nstr\nThe type of effect size to be plotted.\n\n\nyvar\nstr\nThe name of the y-axis variable.\n\n\nhorizontal\nbool\nA boolean flag to determine if the plot is for horizontal plotting.\n\n\nshow_table\nbool\nA boolean flag to determine if the table will be shown in horizontal plot.\n\n\ncolor_col\nstr\nThe column name for coloring the data points.\n\n\n\n\nsource\n\n\nget_color_palette\n\n get_color_palette (plot_kwargs:dict,\n                    plot_data:pandas.core.frame.DataFrame, xvar:str,\n                    show_pairs:bool, idx:list, all_plot_groups:list,\n                    delta2:bool, proportional:bool)\n\nCreate the color palette to be used in the plotter function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplot_kwargs\ndict\nKwargs passed to the plot function.\n\n\nplot_data\nDataFrame\nA dataframe of plot data.\n\n\nxvar\nstr\nThe name of the x-axis variable.\n\n\nshow_pairs\nbool\nA boolean flag to determine if the plot is for paired data.\n\n\nidx\nlist\nA list of tuples containing the group names.\n\n\nall_plot_groups\nlist\nA list of all the group names.\n\n\ndelta2\nbool\nA boolean flag to determine if the plot will have a delta-delta effect size.\n\n\nproportional\nbool\nA boolean flag to determine if the plot is for a proportional plot.\n\n\n\n\nsource\n\n\nget_kwargs\n\n get_kwargs (plot_kwargs:dict, ytick_color, is_paired:bool=False)\n\nExtracts the kwargs from the plot_kwargs object for use in the plotter function.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nplot_kwargs\ndict\n\nKwargs passed to the plot function.\n\n\nytick_color\nstr or color list\n\nColor of the yticks.\n\n\nis_paired\nbool\nFalse\nA boolean flag to determine if the plot is for paired data. Default is False.\n\n\n\n\nsource\n\n\nget_params\n\n get_params (effectsize_df:object, plot_kwargs:dict, sankey_kwargs:dict,\n             barplot_kwargs:dict)\n\nExtracts parameters from the effectsize_df and plot_kwargs objects for use in the plotter function.\n\n\n\n\nType\nDetails\n\n\n\n\neffectsize_df\nobject\nA dabest EffectSizeDataFrame object.\n\n\nplot_kwargs\ndict\nKwargs passed to the plot function.\n\n\nsankey_kwargs\ndict\n\n\n\nbarplot_kwargs\ndict\nKwargs relating to the barplot\n\n\n\n\nsource\n\n\nget_unique_categories\n\n get_unique_categories (names)\n\nExtract unique categories from various input types.\n\nsource\n\n\nget_varname\n\n get_varname (obj)\n\n\nsource\n\n\nprint_greeting\n\n print_greeting ()\n\n*Generates a greeting message based on the current time, along with the version information of DABEST.\nThis function dynamically generates a greeting (‚ÄòGood morning‚Äô, ‚ÄòGood afternoon‚Äô, ‚ÄòGood evening‚Äô) based on the current system time. It also retrieves and displays the version of DABEST (Data Analysis using Bootstrap-Coupled ESTimation). The message includes a header with the DABEST version and the current time formatted in a user-friendly manner.\nReturns: str: A formatted string containing the greeting message, DABEST version, and current time.*\n\nsource\n\n\nunpack_and_add\n\n unpack_and_add (l, c)\n\nConvenience function to allow me to add to an existing list without altering that list.\n\nsource\n\n\nmerge_two_dicts\n\n merge_two_dicts (x:dict, y:dict)\n\n*Given two dicts, merge them into a new dict as a shallow copy. Any overlapping keys in y will override the values in x.\nTaken from here*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nx\ndict\n\n\n\ny\ndict\n\n\n\nReturns\ndict\nA dictionary containing a union of all keys in both original dicts.",
    "crumbs": [
      "Get Started",
      "API",
      "misc_tools"
    ]
  },
  {
    "objectID": "API/load.html#example",
    "href": "API/load.html#example",
    "title": "Loading Data",
    "section": "Example",
    "text": "Example\n\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport dabest\n\nCreate dummy data for demonstration.\n\nnp.random.seed(88888)\nN = 10\nc1 = sp.stats.norm.rvs(loc=100, scale=5, size=N)\nt1 = sp.stats.norm.rvs(loc=115, scale=5, size=N)\ndf = pd.DataFrame({\"Control 1\": c1, \"Test 1\": t1})\n\nLoad the data.\n\nmy_data = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\nmy_data\n\nDABEST v2024.03.29\n==================\n                  \nGood afternoon!\nThe current time is Tue Mar 19 15:34:58 2024.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\nFor proportion plot.\n\nnp.random.seed(88888)\nN = 10\nc1 = np.random.binomial(1, 0.2, size=N)\nt1 = np.random.binomial(1, 0.5, size=N)\ndf = pd.DataFrame({\"Control 1\": c1, \"Test 1\": t1})\nmy_data = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), proportional=True)",
    "crumbs": [
      "Get Started",
      "API",
      "Loading Data"
    ]
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "DABEST Blog",
    "section": "",
    "text": "Robust and Beautiful Statistical Visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBootstrap Confidence Intervals\n\n\nExplanation of the bootstrap method and its application in hypothesis testing using DABEST.\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/robust-beautiful/robust-beautiful.html",
    "href": "blog/posts/robust-beautiful/robust-beautiful.html",
    "title": "Robust and Beautiful Statistical Visualization",
    "section": "",
    "text": "What is data visualization? Battle-Baptiste and Rusert (2018) give a cogent and compelling definition:\nData visualization[1] is the rendering of information in a visual format to help communicate data while also generating new patterns and knowledge through the act of visualization itself.\nSadly, too many figures and visualizations in modern academic publications seemingly fail to ‚Äúgenerate new patterns and knowledge through the act of visualization itself‚Äù. Here, we propose a solution: the estimation plot.\n\n\nBy only displaying the mean and standard deviation, barplots do not accurately represent the underlying distribution of the data.\n\nIn the above figure, four different samples with wildly different distributions‚Äìas seen in the swarmplot on the left panel‚Äìlook exactly the same when visualized with a barplot on the right panel. (You can download the dataset to see for yourself.)\nWe‚Äôre not the first ones (see these articles: article 1, article 2, or article 3) to point out the barplot‚Äôs fatal flaws. Indeed, it is both sobering and fascinating to realise that the barplot is a 17th century invention initially used to compare single values, not to compare summarized and aggregated data.\n\n\n\nBoxplots are another widely used visualization tool. They arguably do include more information for each sample (medians, quartiles, maxima, minima, and outliers), but they do not convey to the viewer the size of each sample.\n\nThe figure above visualizes the same four samples as a swarmplot (left panel) and as a boxplot. If we did not label the x-axis with the sample size, it would be impossible to definitively distinguish the sample with 5 observations from the sample with 50.\nEven if the world gets rid of barplots and boxplots, the problems plaguing statistical practices will remain unsolved. Null-hypothesis significance testing‚Äìthe dominant statistical paradigm in basic research‚Äìdoes not indicate the effect size, or its confidence interval."
  },
  {
    "objectID": "blog/posts/robust-beautiful/robust-beautiful.html#current-plots-do-not-work",
    "href": "blog/posts/robust-beautiful/robust-beautiful.html#current-plots-do-not-work",
    "title": "Robust and Beautiful Statistical Visualization",
    "section": "",
    "text": "What is data visualization? Battle-Baptiste and Rusert (2018) give a cogent and compelling definition:\nData visualization[1] is the rendering of information in a visual format to help communicate data while also generating new patterns and knowledge through the act of visualization itself.\nSadly, too many figures and visualizations in modern academic publications seemingly fail to ‚Äúgenerate new patterns and knowledge through the act of visualization itself‚Äù. Here, we propose a solution: the estimation plot.\n\n\nBy only displaying the mean and standard deviation, barplots do not accurately represent the underlying distribution of the data.\n\nIn the above figure, four different samples with wildly different distributions‚Äìas seen in the swarmplot on the left panel‚Äìlook exactly the same when visualized with a barplot on the right panel. (You can download the dataset to see for yourself.)\nWe‚Äôre not the first ones (see these articles: article 1, article 2, or article 3) to point out the barplot‚Äôs fatal flaws. Indeed, it is both sobering and fascinating to realise that the barplot is a 17th century invention initially used to compare single values, not to compare summarized and aggregated data.\n\n\n\nBoxplots are another widely used visualization tool. They arguably do include more information for each sample (medians, quartiles, maxima, minima, and outliers), but they do not convey to the viewer the size of each sample.\n\nThe figure above visualizes the same four samples as a swarmplot (left panel) and as a boxplot. If we did not label the x-axis with the sample size, it would be impossible to definitively distinguish the sample with 5 observations from the sample with 50.\nEven if the world gets rid of barplots and boxplots, the problems plaguing statistical practices will remain unsolved. Null-hypothesis significance testing‚Äìthe dominant statistical paradigm in basic research‚Äìdoes not indicate the effect size, or its confidence interval."
  },
  {
    "objectID": "blog/posts/robust-beautiful/robust-beautiful.html#introducing-the-estimation-plot",
    "href": "blog/posts/robust-beautiful/robust-beautiful.html#introducing-the-estimation-plot",
    "title": "Robust and Beautiful Statistical Visualization",
    "section": "Introducing the Estimation Plot",
    "text": "Introducing the Estimation Plot\n\nThis is a Gardner-Altman estimation plot. The plot draws its name from Martin J. Gardner and Douglas Altman, who are credited with creating the design in 1986.\nThis plot has two key features:\n\nIt presents all data points as a swarmplot, ordering each point to display the underlying distribution.\nIt presents the effect size as a bootstrap 95% confidence interval (95% CI) on a separate but aligned axis. The effect size is displayed to the right of the raw data, and the mean of the test group is aligned with the effect size.‚Äù\n\n\nThus, estimation plots are robust, beautiful, and convey important statistical information elegantly and efficiently.\n\nAn estimation plot obtains and displays the 95% CI through nonparametric bootstrap resampling. This enables visualization of the confidence interval as a graded sampling distribution.\nThis is one important difference between estimation plots created by DABEST, and the original Gardner-Altman design. Here, the 95% CI is computed through parametric methods, and displayed as a vertical error bar.\nRead more about this technique at bootstraps.\n\nIntroducing Estimation Statistics\nEstimation plots emerge from estimation statistics, a simple framework that avoids the pitfalls of significance testing. It focuses on the effect sizes of one‚Äôs experiment/interventions, and uses familiar statistical concepts: means, mean differences, and error bars.\nSignificance testing calculates the probability (the P value) that the experimental data would be observed, if the intervention did not produce a change in the metric measured (i.e.¬†the null hypothesis). This leads analysts to apply a false dichotomy on the experimental intervention.\nEstimation statistics, on the other hand, focuses on the magnitude of the effect (the effect size) and its precision. This encourages analysts to gain a deeper understanding of the metrics used, and how they relate to the natural processes being studied."
  },
  {
    "objectID": "blog/posts/robust-beautiful/robust-beautiful.html#an-estimation-plot-for-every-experimental-design",
    "href": "blog/posts/robust-beautiful/robust-beautiful.html#an-estimation-plot-for-every-experimental-design",
    "title": "Robust and Beautiful Statistical Visualization",
    "section": "An Estimation Plot For Every Experimental Design",
    "text": "An Estimation Plot For Every Experimental Design\nFor each of the most routine significance tests, there is an estimation replacement:\n\nUnpaired Student‚Äôs t-test ‚Äì&gt; Two-group estimation plot\n\n\n\nPaired Student‚Äôs t-test ‚Äì&gt; Paired estimation plot\nThe Gardner-Altman estimation plot can also display effect sizes for repeated measures (aka a paired experimental design) using a Tufte slopegraph instead of a swarmplot.\n\n\n\nOne-way ANOVA + multiple comparisons ‚Äì&gt; Multi two-group estimation plot\nFor comparisons between three or more groups that typically employ analysis of variance (ANOVA) methods, one can use the Cumming estimation plot, named after Geoff Cumming, and draws its design heavily from his 2012 textbook ‚ÄúUnderstanding the New Statistics‚Äù. This estimation plot design can be considered a variant of the Gardner-Altman plot.\n\nThe effect size and 95% CIs are still plotted on a separate axis, but unlike the Gardner-Altman plot, this axis is positioned beneath the raw data.\nSuch a design frees up visual space in the upper panel, allowing the display of summary measurements (mean ¬± standard deviation) for each group. These are shown as gapped lines to the right of each group. The mean of each group is indicated as a gap in the line, adhering to Edward Tufte‚Äôs dictum to keep the data-ink ratio low.\n\n\nRepeated measures ANOVA ‚Äì&gt; Multi paired estimation plot\n\n\n\nOrdered groups ANOVA ‚Äì&gt; Shared-control estimation plot\n\n\n\nEstimation Plots: The Way Forward\nIn summary, estimation plots offer five key benefits relative to conventional plots:\n\n\n\n\n\n\n\n\n\n\nBarplot\nBoxplot\nEstimation Plot\n\n\n\n\nDisplays all observed values\nNO\nNO\nYes\n\n\nAvoids false dichotomy\nNO\nNO\nYes\n\n\nFocusses on effect size\nNO\nNO\nYes\n\n\nVisualizes effect size precision\nNO\nNO\nYes\n\n\nShows mean difference distribution\nNO\nNO\nYes\n\n\n\nYou can create estimation plots using the DABEST (Data Analysis with Bootstrap Estimation) packages, which are available in Matlab, Python, and R.\n [1]:W. E. B. Du Bois‚Äôs Data Portraits: Visualizing Black America. Edited by Whitney Battle-Baptiste and Britt Rusert, Princeton Architectural Press, 2018"
  },
  {
    "objectID": "01-getting_started.html",
    "href": "01-getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "DABEST is a package for Data Analysis with Bootstrapped ESTimation\nEstimation statistics is a simple framework that avoids the pitfalls of significance testing. It uses familiar statistical concepts: means, mean differences, and error bars. More importantly, it focuses on the effect size of one‚Äôs experiment/intervention, as opposed to a false dichotomy engendered by P values.\nAn estimation plot has two key features.\n\nIt presents all datapoints as a swarmplot, which orders each point to display the underlying distribution.\nIt presents the effect size as a bootstrap 95% confidence interval on a separate but aligned axes.\n\nDABEST powers estimationstats.com, allowing everyone access to high-quality estimation plots.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#introduction",
    "href": "01-getting_started.html#introduction",
    "title": "Getting Started",
    "section": "",
    "text": "DABEST is a package for Data Analysis with Bootstrapped ESTimation\nEstimation statistics is a simple framework that avoids the pitfalls of significance testing. It uses familiar statistical concepts: means, mean differences, and error bars. More importantly, it focuses on the effect size of one‚Äôs experiment/intervention, as opposed to a false dichotomy engendered by P values.\nAn estimation plot has two key features.\n\nIt presents all datapoints as a swarmplot, which orders each point to display the underlying distribution.\nIt presents the effect size as a bootstrap 95% confidence interval on a separate but aligned axes.\n\nDABEST powers estimationstats.com, allowing everyone access to high-quality estimation plots.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#requirements",
    "href": "01-getting_started.html#requirements",
    "title": "Getting Started",
    "section": "Requirements",
    "text": "Requirements\nPython 3.11 is recommended. DABEST has also been tested with Python 3.10 and onwards.\nIn addition, the following packages are also required (listed with their minimal versions):\n\nnumpy 2.1.3\nscipy 1.15.2\nmatplotlib 3.10.0\npandas 2.2.3\nseaborn 0.13.2\nnumba 0.61.0\nlqrt 0.3.3\n\nTo obtain these package dependencies easily, it is highly recommended to download the Anaconda distribution of Python.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#installation",
    "href": "01-getting_started.html#installation",
    "title": "Getting Started",
    "section": "Installation",
    "text": "Installation\n\nUsing pip\n\nAt the command line, run\n$ pip install dabest\n\nUsing Github\n\nClone the DABEST-python repo locally (see instructions here).\nThen, navigate to the cloned repo in the command line and run\n$ pip install .",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#testing",
    "href": "01-getting_started.html#testing",
    "title": "Getting Started",
    "section": "Testing",
    "text": "Testing\nTo test DABEST, you will need to install pytest and nbdev.\nRun nbdev_export && nbdev_test in the root directory of the source distribution. This runs the value assertion tests in dabest/tests folder\nRun pytest in the root directory of the source distribution. This runs the image-based tests in dabest/tests/mpl_image_tests sub folder.\nThe test suite will ensure that the bootstrapping functions and the plotting functions perform as expected.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#bugs",
    "href": "01-getting_started.html#bugs",
    "title": "Getting Started",
    "section": "Bugs",
    "text": "Bugs\nPlease report any bugs on the Github issue tracker for DABEST-python.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "01-getting_started.html#contributing",
    "href": "01-getting_started.html#contributing",
    "title": "Getting Started",
    "section": "Contributing",
    "text": "Contributing\nAll contributions are welcome. Please fork the Github repo and open a pull request.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "tests/test_06_delta-delta_effsize_pvals.html",
    "href": "tests/test_06_delta-delta_effsize_pvals.html",
    "title": "dabest",
    "section": "",
    "text": "import pytest\nimport numpy as np\nfrom math import gamma\n\n\n\nfrom dabest import Dabest, PermutationTest\nfrom data.mocked_data_test_06 import df_test, df_test_control, df_test_treatment1, dabest_default_kwargs\n\n\n# example of unpaired delta-delta calculation\nunpaired = Dabest(data = df_test, x = [\"Time\", \"Drug\"], y = \"Heart Rate\", \n                  delta2 = True, experiment = \"Experiment\",\n                  experiment_label=None, x1_level=None, paired=None, id_col=None,\n                  **dabest_default_kwargs)\n\n\n# example of paired delta-delta calculation\npaired = Dabest(data = df_test, x = [\"Time\", \"Drug\"], y = \"Heart Rate\", \n                  delta2 = True, experiment = \"Experiment\", paired=\"sequential\", id_col=\"ID\",\n                  experiment_label=None, x1_level=None,\n                  **dabest_default_kwargs)\n\n\n# example of paired data with specified experiment/x1 level\npaired_specified_level = Dabest(data = df_test, x = [\"Time\", \"Drug\"], y = \"Heart Rate\", \n                  delta2 = True, experiment = \"Experiment\", paired=\"sequential\", id_col=\"ID\",\n                  experiment_label=[\"Control\", \"Treatment1\"], x1_level=[\"T2\", \"T1\"],\n                  **dabest_default_kwargs)\n\ntest_mean_diff_delta_unpaired\n\nmean_diff_results = unpaired.mean_diff.results\nall_mean_diff = mean_diff_results['difference'].to_list()\ndiff1 = np.mean(df_test_treatment1[\"T2\"])-np.mean(df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"])-np.mean(df_test_control[\"T1\"])\nnp_result = [diff1, diff2]\nassert all_mean_diff == pytest.approx(np_result)\n\ntest_mean_diff_delta_paired\n\nmean_diff_results = paired.mean_diff.results\nall_mean_diff = mean_diff_results['difference'].to_list()\ndiff1 = np.mean(df_test_treatment1[\"T2\"]-df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"]-df_test_control[\"T1\"])\nnp_result = [diff1, diff2]\nassert all_mean_diff == pytest.approx(np_result)\n\ntest_mean_diff_delta_paired_specified_level\n\nmean_diff_results = paired_specified_level.mean_diff.results\nall_mean_diff = mean_diff_results['difference'].to_list()\ndiff1 = np.mean(df_test_control[\"T1\"]-df_test_control[\"T2\"])\ndiff2 = np.mean(df_test_treatment1[\"T1\"]-df_test_treatment1[\"T2\"])\nnp_result = [diff1, diff2]\nassert all_mean_diff == pytest.approx(np_result)\n\ntest_median_diff_unpaired\n\nall_median_diff = unpaired.median_diff.results\nmedian_diff = all_median_diff['difference'].to_list()\ndiff1 = np.median(df_test_treatment1[\"T2\"])-np.median(df_test_treatment1[\"T1\"])\ndiff2 = np.median(df_test_control[\"T2\"])-np.median(df_test_control[\"T1\"])\nnp_result = [diff1, diff2]\nassert median_diff == pytest.approx(np_result)\n\ntest_median_diff_paired\n\nall_median_diff = paired.median_diff.results\nmedian_diff = all_median_diff['difference'].to_list()\ndiff1 = np.median(df_test_treatment1[\"T2\"]-df_test_treatment1[\"T1\"])\ndiff2 = np.median(df_test_control[\"T2\"]-df_test_control[\"T1\"])\nnp_result = [diff1, diff2]\nassert median_diff == pytest.approx(np_result)\n\ntest_median_diff_paired_specified_level\n\nall_median_diff = paired_specified_level.median_diff.results\nmedian_diff = all_median_diff['difference'].to_list()\ndiff1 = np.median(df_test_control[\"T1\"]-df_test_control[\"T2\"])\ndiff2 = np.median(df_test_treatment1[\"T1\"]-df_test_treatment1[\"T2\"])\nnp_result = [diff1, diff2]\nassert median_diff == pytest.approx(np_result)\n\ntest_cohens_d_unpaired\n\nall_cohens_d = unpaired.cohens_d.results\ncohens_d = all_cohens_d['difference'].to_list()\ndiff1 = np.mean(df_test_treatment1[\"T2\"])-np.mean(df_test_treatment1[\"T1\"])\ndiff1 = diff1/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2) \ndiff2 = np.mean(df_test_control[\"T2\"])-np.mean(df_test_control[\"T1\"])\ndiff2 = diff2/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2) \nnp_result = [diff1, diff2]          \nassert cohens_d == pytest.approx(np_result)\n\ntest_cohens_d_paired\n\nall_cohens_d = paired.cohens_d.results\ncohens_d = all_cohens_d['difference'].to_list()\ndiff1 = np.mean(df_test_treatment1[\"T2\"]-df_test_treatment1[\"T1\"])\ndiff1 = diff1/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2) \ndiff2 = np.mean(df_test_control[\"T2\"]-df_test_control[\"T1\"])\ndiff2 = diff2/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2) \nnp_result = [diff1, diff2]          \nassert cohens_d == pytest.approx(np_result)\n\ntest_cohens_d_paired_specified_level\n\nall_cohens_d = paired_specified_level.cohens_d.results\ncohens_d = all_cohens_d['difference'].to_list()\ndiff1 = np.mean(df_test_control[\"T1\"])-np.mean(df_test_control[\"T2\"])\ndiff1 = diff1/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2)\ndiff2 = np.mean(df_test_treatment1[\"T1\"])-np.mean(df_test_treatment1[\"T2\"])\ndiff2 = diff2/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2)  \nnp_result = [diff1, diff2]     \nassert cohens_d == pytest.approx(np_result)\n\ntest_hedges_g_unpaired\n\nhedges_g = unpaired.hedges_g.results['difference'].to_list()\na = 8*2-2\nfac = gamma(a/2)/(np.sqrt(a/2)*gamma((a-1)/2))\ndiff1 = (np.mean(df_test_treatment1[\"T2\"])-np.mean(df_test_treatment1[\"T1\"]))*fac\ndiff1 = diff1/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2) \ndiff2 = (np.mean(df_test_control[\"T2\"])-np.mean(df_test_control[\"T1\"]))*fac\ndiff2 = diff2/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2) \nnp_result=[diff1, diff2]\nassert hedges_g == pytest.approx(np_result)\n\ntest_hedges_g_paired\n\nhedges_g = paired.hedges_g.results['difference'].to_list()\na = 8*2-2\nfac = gamma(a/2)/(np.sqrt(a/2)*gamma((a-1)/2))\ndiff1 = (np.mean(df_test_treatment1[\"T2\"]-df_test_treatment1[\"T1\"]))*fac\ndiff1 = diff1/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2) \ndiff2 = (np.mean(df_test_control[\"T2\"]-df_test_control[\"T1\"]))*fac\ndiff2 = diff2/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2) \nnp_result=[diff1, diff2]\nassert hedges_g == pytest.approx(np_result)\n\ntest_hedges_g_paired_specified_level\n\nhedges_g = paired_specified_level.hedges_g.results['difference'].to_list()\na = 8*2-2\nfac = gamma(a/2)/(np.sqrt(a/2)*gamma((a-1)/2))\ndiff1 = (np.mean(df_test_control[\"T1\"]-df_test_control[\"T2\"]))*fac\ndiff1 = diff1/np.sqrt((np.var(df_test_control[\"T2\"], ddof=1)+np.var(df_test_control[\"T1\"], ddof=1))/2) \ndiff2 = (np.mean(df_test_treatment1[\"T1\"]-df_test_treatment1[\"T2\"]))*fac\ndiff2 = diff2/np.sqrt((np.var(df_test_treatment1[\"T2\"], ddof=1)+np.var(df_test_treatment1[\"T1\"], ddof=1))/2) \nnp_result=[diff1, diff2]\nassert hedges_g == pytest.approx(np_result)\n\ntest_unpaired_delta_delta\n\ndelta_delta = unpaired.mean_diff.delta_delta.difference\n\ndiff1 = np.mean(df_test_treatment1[\"T2\"])-np.mean(df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"])-np.mean(df_test_control[\"T1\"])\nnp_result = diff2-diff1\n\nassert delta_delta == pytest.approx(np_result)\n\ntest_paired_delta_delta\n\ndelta_delta = paired.mean_diff.delta_delta.difference\n\ndiff1 = np.mean(df_test_treatment1[\"T2\"] - df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"] - df_test_control[\"T1\"])\nnp_result = diff2-diff1\n\nassert delta_delta == pytest.approx(np_result)\n\ntest_paired_specified_level_delta_delta\n\ndelta_delta = paired_specified_level.mean_diff.delta_delta.difference\n\ndiff1 = np.mean(df_test_control[\"T1\"] - df_test_control[\"T2\"])\ndiff2 = np.mean(df_test_treatment1[\"T1\"] - df_test_treatment1[\"T2\"])\nnp_result = diff2-diff1\n\nassert delta_delta == pytest.approx(np_result)\n\ntest_unpaired_permutation_test\n\ndelta_delta              = unpaired.mean_diff.delta_delta\npvalue                   = delta_delta.pvalue_permutation\npermutations_delta_delta = delta_delta.permutations_delta_delta\n\nperm_test_1 = PermutationTest(df_test_treatment1[\"T1\"], \n                              df_test_treatment1[\"T2\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=False)\nperm_test_2 = PermutationTest(df_test_control[\"T1\"], \n                              df_test_control[\"T2\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=False)\npermutations_1 = perm_test_1.permutations\npermutations_2 = perm_test_2.permutations\n\ndelta_deltas = permutations_2-permutations_1\nassert permutations_delta_delta == pytest.approx(delta_deltas)\n\ndiff1 = np.mean(df_test_treatment1[\"T2\"])-np.mean(df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"])-np.mean(df_test_control[\"T1\"])\nnp_diff = diff2-diff1\n\nnp_pvalues = len(list(filter(lambda x: np.abs(x)&gt;np.abs(np_diff), \n                            delta_deltas)))/len(delta_deltas)\n\nassert pvalue == pytest.approx(np_pvalues)\n\ntest_paired_permutation_test\n\ndelta_delta              = paired.mean_diff.delta_delta\npvalue                   = delta_delta.pvalue_permutation\npermutations_delta_delta = delta_delta.permutations_delta_delta\n\nperm_test_1 = PermutationTest(df_test_treatment1[\"T1\"], \n                              df_test_treatment1[\"T2\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=\"sequential\")\nperm_test_2 = PermutationTest(df_test_control[\"T1\"], \n                              df_test_control[\"T2\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=\"sequential\")\npermutations_1 = perm_test_1.permutations\npermutations_2 = perm_test_2.permutations\n\ndelta_deltas = permutations_2-permutations_1\nassert permutations_delta_delta == pytest.approx(delta_deltas)\n\ndiff1 = np.mean(df_test_treatment1[\"T2\"]-df_test_treatment1[\"T1\"])\ndiff2 = np.mean(df_test_control[\"T2\"]-df_test_control[\"T1\"])\nnp_diff = diff2-diff1\n\nnp_pvalues = len(list(filter(lambda x: np.abs(x)&gt;np.abs(np_diff), \n                            delta_deltas)))/len(delta_deltas)\n\nassert pvalue == pytest.approx(np_pvalues)\n\ntest_paired_specified_level_permutation_test\n\ndelta_delta              = paired_specified_level.mean_diff.delta_delta\npvalue                   = delta_delta.pvalue_permutation\npermutations_delta_delta = delta_delta.permutations_delta_delta\n\nperm_test_1 = PermutationTest(df_test_control[\"T2\"], \n                              df_test_control[\"T1\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=\"sequential\")\nperm_test_2 = PermutationTest(df_test_treatment1[\"T2\"], \n                              df_test_treatment1[\"T1\"], \n                              effect_size=\"mean_diff\", \n                              is_paired=\"sequential\")\npermutations_1 = perm_test_1.permutations\npermutations_2 = perm_test_2.permutations\n\ndelta_deltas = permutations_2-permutations_1\nassert permutations_delta_delta == pytest.approx(delta_deltas)\n\ndiff1 = np.mean(df_test_control[\"T1\"]-df_test_control[\"T2\"])\ndiff2 = np.mean(df_test_treatment1[\"T1\"]-df_test_treatment1[\"T2\"])\nnp_diff = diff2-diff1\n\nnp_pvalues = len(list(filter(lambda x: np.abs(x)&gt;np.abs(np_diff), \n                            delta_deltas)))/len(delta_deltas)\n\nassert pvalue == pytest.approx(np_pvalues)"
  },
  {
    "objectID": "tests/test_02_edge_cases.html",
    "href": "tests/test_02_edge_cases.html",
    "title": "dabest",
    "section": "",
    "text": "import numpy as np\nfrom numpy.random import PCG64, RandomState\nimport scipy as sp\nimport pytest\nimport pandas as pd\n\n\n\nfrom dabest._api import load\n\n\ntest_unrelated_columns\nTest to see if 'unrelated' columns jam up the analysis.\nSee Github Issue 43.\nhttps://github.com/ACCLAB/DABEST-python/issues/44.\n\nAdded in v0.2.5.\n\nN=60\nrandom_seed=12345\n\n# rng = RandomState(MT19937(random_seed))\nrng = RandomState(PCG64(random_seed))\n# rng = np.random.default_rng(seed=random_seed)\n\ndf = pd.DataFrame(\n    {'groups': rng.choice(['Group 1', 'Group 2', 'Group 3'], size=(N,)),\n     'color' : rng.choice(['green', 'red', 'purple'], size=(N,)),\n     'value':  rng.random(size=(N,))})\n\ndf['unrelated'] = np.nan\n\ntest = load(data=df, x='groups', y='value', \n            idx=['Group 1', 'Group 2'])\n\nmd = test.mean_diff.results\nassert md.difference[0] == pytest.approx(-0.0322, abs=1e-4)\nassert md.bca_low[0]    == pytest.approx(-0.2268, abs=1e-4)\nassert md.bca_high[0]   == pytest.approx(0.1524, abs=1e-4)"
  },
  {
    "objectID": "tests/test_01_effsizes_pvals.html",
    "href": "tests/test_01_effsizes_pvals.html",
    "title": "dabest",
    "section": "",
    "text": "import pytest\nimport lqrt\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\n\n\nfrom dabest._stats_tools import effsize\nfrom dabest import Dabest, TwoGroupsEffectSize, PermutationTest\n\n\nfrom data.mocked_data_test_01 import wellbeing, paired_wellbeing, smoke, likert_control, likert_treatment, a_scores, b_scores, dabest_default_kwargs\n\ntest_mean_diff_unpaired\n\nmean_diff = effsize.func_difference(wellbeing.control, wellbeing.expt,\n                                    np.mean, is_paired=False)\nassert mean_diff == pytest.approx(5.4)\n\ntest_median_diff_unpaired\n\nmedian_diff = effsize.func_difference(wellbeing.control, wellbeing.expt,\n                                    np.median, is_paired=False)\nassert median_diff == pytest.approx(3.5)\n\ntest_mean_diff_paired\n\nmean_diff = effsize.func_difference(paired_wellbeing.pre,\n                                    paired_wellbeing.post,\n                                    np.mean, is_paired=\"baseline\")\nassert mean_diff == pytest.approx(4.10)\n\ntest_median_diff_paired\n\nmedian_diff = effsize.func_difference(paired_wellbeing.pre,\n                                      paired_wellbeing.post,\n                                      np.median, is_paired=\"baseline\")\nassert median_diff == pytest.approx(4.5)\n\ntest_cohens_d_unpaired\n\ncohens_d = effsize.cohens_d(np.array(wellbeing.control), np.array(wellbeing.expt),\n                            is_paired=False)\nassert np.round(cohens_d, 2) == pytest.approx(0.47)\n\ntest_hedges_g_unpaired\n\nhedges_g = effsize.hedges_g(np.array(wellbeing.control), np.array(wellbeing.expt),\n                                is_paired=False)\nassert np.round(hedges_g, 2) == pytest.approx(0.45)\n\ntest_cohens_d_paired\n\ncohens_d = effsize.cohens_d(np.array(paired_wellbeing.pre), np.array(paired_wellbeing.post),\n                                is_paired=\"baseline\")\nassert np.round(cohens_d, 2) == pytest.approx(0.34)\n\ntest_hedges_g_paired\n\nhedges_g = effsize.hedges_g(np.array(paired_wellbeing.pre), np.array(paired_wellbeing.post),\n                            is_paired=\"baseline\")\nassert np.round(hedges_g, 2) == pytest.approx(0.33)\n\ntest_cohens_h\n\ncohens_h = effsize.cohens_h(np.array(smoke.low), np.array(smoke.high))\nassert np.round(cohens_h, 2) == pytest.approx(0.17)\n\ntest_cliffs_delta\n\nlikert_delta = effsize.cliffs_delta(np.array(likert_treatment), np.array(likert_control))\nassert likert_delta == pytest.approx(-0.25)\n\nscores_delta = effsize.cliffs_delta(np.array(b_scores), np.array(a_scores))\nassert scores_delta == pytest.approx(0.65)\n\ntest_unpaired_stats\n\nc = wellbeing.control\nt = wellbeing.expt\n\nunpaired_es = TwoGroupsEffectSize(c, t, \"mean_diff\", is_paired=False, proportional=False)\n\np1 = sp.stats.mannwhitneyu(c, t, alternative=\"two-sided\").pvalue\nassert unpaired_es.pvalue_mann_whitney == pytest.approx(p1)\n\np2 = sp.stats.ttest_ind(c, t, nan_policy='omit').pvalue\nassert unpaired_es.pvalue_students_t == pytest.approx(p2)\n\np3 = sp.stats.ttest_ind(c, t, equal_var=False, nan_policy='omit').pvalue\nassert unpaired_es.pvalue_welch == pytest.approx(p3)\n\ntest_paired_stats\n\nbefore = paired_wellbeing.pre\nafter = paired_wellbeing.post\n\npaired_es = TwoGroupsEffectSize(before, after, \"mean_diff\", is_paired=\"baseline\", proportional=False)\n\np1 = sp.stats.ttest_rel(before, after, nan_policy='omit').pvalue\nassert paired_es.pvalue_paired_students_t == pytest.approx(p1)\n\np2 = sp.stats.wilcoxon(before, after).pvalue\nassert paired_es.pvalue_wilcoxon == pytest.approx(p2)\n\ntest_median_diff_stats\n\nc = wellbeing.control\nt = wellbeing.expt\n\nes = TwoGroupsEffectSize(c, t, \"median_diff\", is_paired=False, proportional=False)\n\np1 = sp.stats.kruskal(c, t, nan_policy='omit').pvalue\nassert es.pvalue_kruskal == pytest.approx(p1)\n\ntest_ordinal_dominance\n\nes = TwoGroupsEffectSize(likert_control, likert_treatment, \n                             \"cliffs_delta\", is_paired=False, proportional=False)\n                             \np1 = sp.stats.brunnermunzel(likert_control, likert_treatment).pvalue\nassert es.pvalue_brunner_munzel == pytest.approx(p1)\n\ntest_unpaired_permutation_test\n\nperm_test = PermutationTest(wellbeing.control, wellbeing.expt, \n                                effect_size=\"mean_diff\", \n                                is_paired=False)\nassert perm_test.pvalue == pytest.approx(0.2976)\n\ntest_paired_permutation_test\n\nperm_test = PermutationTest(paired_wellbeing.pre, \n                                paired_wellbeing.post, \n                                effect_size=\"mean_diff\", \n                                is_paired=\"baseline\")\nassert perm_test.pvalue == pytest.approx(0.0124)\n\ntest_lqrt_unpaired\n\nunpaired_dabest = Dabest(wellbeing, idx=(\"control\", \"expt\"), \n                             paired=None, id_col=None, \n                             **dabest_default_kwargs)\nlqrt_result = unpaired_dabest.mean_diff.lqrt\n\np1 = lqrt.lqrtest_ind(wellbeing.control, wellbeing.expt,\n                      equal_var=True,\n                      random_state=12345)\n\np2 = lqrt.lqrtest_ind(wellbeing.control, wellbeing.expt,\n                      equal_var=False,\n                      random_state=12345)\n\nassert lqrt_result.pvalue_lqrt_equal_var[0] == pytest.approx(p1.pvalue)\nassert lqrt_result.pvalue_lqrt_unequal_var[0] == pytest.approx(p2.pvalue)\n\ntest_lqrt_paired\n\npaired_dabest = Dabest(paired_wellbeing, idx=(\"pre\", \"post\"),\n                           paired=\"baseline\", id_col=\"ID\",\n                           **dabest_default_kwargs)\nlqrt_result = paired_dabest.mean_diff.lqrt\n\np1 = lqrt.lqrtest_rel(paired_wellbeing.pre, paired_wellbeing.post, \n             random_state=12345)\n\nassert lqrt_result.pvalue_paired_lqrt[0] == pytest.approx(p1.pvalue)"
  },
  {
    "objectID": "tutorials/10-whorlmap.html",
    "href": "tutorials/10-whorlmap.html",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "",
    "text": "In DABEST v2025.10.20, we introduce a new and more compact way of visualizing bootstrap distributions: - whorlmap",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#load-libraries",
    "href": "tutorials/10-whorlmap.html#load-libraries",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport dabest\nfrom dabest.multi import combine, whorlmap\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 37.69it/s]\n\n\nNumba compilation complete!",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#create-a-simulated-dataset-and-generate-a-list-of-corresponding-dabest-objects",
    "href": "tutorials/10-whorlmap.html#create-a-simulated-dataset-and-generate-a-list-of-corresponding-dabest-objects",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "Create a simulated dataset and generate a list of corresponding dabest objects",
    "text": "Create a simulated dataset and generate a list of corresponding dabest objects\n\ndef create_delta_dataset(N=50, \n                        seed=9999, \n                        second_quarter_adjustment=3, \n                        third_quarter_adjustment= -0.5,\n                        fourth_quarter_adjustment= -3, \n                        scale4=1, initial_loc = 10):\n    \"\"\"Create a sample dataset for delta-delta analysis.\"\"\"\n    np.random.seed(seed)\n\n    # Create samples\n    y = norm.rvs(loc=initial_loc, scale=0.4, size=N*4)\n    y[N:2*N] = norm.rvs(loc=initial_loc + second_quarter_adjustment, scale= 1, size=N) \n    y[2*N:3*N] = norm.rvs(loc=initial_loc + third_quarter_adjustment, scale=0.4, size=N)\n    y[3*N:4*N] = norm.rvs(loc=initial_loc + fourth_quarter_adjustment, scale=scale4, size=N)\n\n    # Treatment, Rep, Genotype, and ID columns\n    treatment = np.repeat(['Placebo', 'Drug'], N*2).tolist()\n    genotype = np.repeat(['W', 'M', 'W', 'M'], N).tolist()\n    id_col = list(range(0, N*2)) * 2\n\n    # Combine all columns into a DataFrame\n    df = pd.DataFrame({\n        'ID': id_col,\n        'Genotype': genotype,\n        'Treatment': treatment,\n        'Transcript Level': y\n    })\n    return df",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#working-with-many-many-dabest-objects",
    "href": "tutorials/10-whorlmap.html#working-with-many-many-dabest-objects",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "Working with many many Dabest objects",
    "text": "Working with many many Dabest objects\nLet‚Äôs say you have a transcriptomics experiment where you investigate the effects of administering 6 different drugs on oncogene transcripts 1 to 10. You want to find the drug that reduces all the transcripts the most effectively. In a 2x2 experiment, drug is compared to its placebo, so we will be tabulating delta-delta effect sizes. You may simulate the data as follows:\n\ndabest_objects_2d = [[None for _ in range(8)] for _ in range(6)]\nlabels_2d = [\"Transcript 1\", \"Transcript 2\", \"Transcript 3\", \"Transcript 4\", \"Transcript 5\", \"Transcript 6\", \"Transcript 7\", \"Transcript 8\"]\nrow_labels_2d = [\"Drug A\", \"Drug B\", \"Drug C\", \"Drug D\", \"Drug E\", \"Drug F\"]\ndrug_effect_2d = [[.9, 2, 2, .5, 1.2, 1, 3,2, 3, 4], \n             [0.1, -.3, .1, -0.3, -2, 1.2, 1,.1,-4, 2],\n             [4, 4, 1, 5, 1, 3, 6.5,.5, -1.2, .4],\n             [6, 2, 2, 4, 1.4, -0.5, -.5,1.1, 3, .4],\n             [0.1, -.3, .1, -0.3, -2, 1.2, 1,.1,-4, 2],\n             [-.3, -1, 2, 7, 1, -0.5, 4,1, 2.3, -.4],\n                                ]\ndrug_effect_scale_2d = [[5, 10, 1, 5, 1, 2, 1,1, .1, 2], \n             [7, .2, 8, 3, 1, 4, 7,1, 5, 2],\n             [15, 3, 1, 2, 1, 1, 11,1, 7, 2],\n             [8, .1, 1, 5, 1, 6,1,1, 3, .4],\n             [9, 10, 7, 12, 4, 2,14,10, 9, 20],\n             [4, 3, 1, 4, 1, 4,4,1, 3, 4],\n             ]\nseeds = [1, 1000, 20, 9999, 1000, 5320]\n\nfor i in range(len(row_labels_2d)):\n    for j in range(len(labels_2d)):\n        df = create_delta_dataset(seed=seeds[i], \n                                  fourth_quarter_adjustment=drug_effect_2d[i][j],\n                                  scale4=drug_effect_scale_2d[i][j],\n                                 initial_loc = 20)\n        dabest_objects_2d[i][j] = dabest.load(data=df, \n                       x=[\"Genotype\", \"Genotype\"], \n                       y=\"Transcript Level\", \n                       delta2=True, \n                       experiment=\"Treatment\")\n\nWe are going to create a new object called MultiContrast which will contain the array of contrast objects and information about them.\n\nmulti_2d_mean_diff = combine(dabest_objects_2d, labels_2d, row_labels=row_labels_2d, effect_size=\"mean_diff\")\nprint(\"multi_2d_mean_diff is a \" + str(multi_2d_mean_diff))\n\nmulti_2d_mean_diff is a MultiContrast(2D: 6x8, effect_size='mean_diff', contrast_type='delta2')\n\n\nAs we have seen in the previous tutorial, we can visualize these effect sizes with forest plot as follows:\n\nmulti_2d_mean_diff.forest_plot(forest_plot_title = \"2D Forest Plot of Mean Difference\", forest_plot_kwargs = { 'marker_size': 6});\n\n\n\n\n\n\n\n\nThis data would require a stack of forest plots to visualize. So instead, we plot a whorlmap for a concise representation and use color to represent the dimension of effect size. For each effect size, the full bootstrap distribution is binned by quantiles and ranked by value, and then each bin is represented by a pixel. All the pixels correponding to the bins of effects are arranged in a spiral in a cell. The redness and the blueness of the cells represent the magnitude of the effects in the positive and negative direction.\n\nmulti_2d_mean_diff.whorlmap(\n    title=\"Mean Difference Gene Expression Whorlmap\",\n    cmap=\"vlag\",\n    chop_tail=2.5,  # Remove 5% extreme values\n    fig_size = (10, 4)\n);\n\n\n\n\n\n\n\n\nThe resulting graphic is easy to interpret. Drug B and E induces the most broad spectrum reduction. However the data for Drug E seems a little less precise, mixing blue and red colored pixels. We can say Drug B is a surer bet.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#plotting-whorlmaps-with-standardized-effect-sizes",
    "href": "tutorials/10-whorlmap.html#plotting-whorlmaps-with-standardized-effect-sizes",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "Plotting whorlmaps with standardized effect sizes",
    "text": "Plotting whorlmaps with standardized effect sizes\nWe can also visualize the same array of effects in terms of standardized effect delta g. Let‚Äôs plot them together in the same figure by specifying the axes to plot in:\n\nfigure, axes = plt.subplots(1, 2, figsize = (9, 2))\nmulti_2d_mean_diff.whorlmap(\n    cmap=\"vlag\",\n    chop_tail=2.5,  # Remove 5% extreme values\n    title=\"Mean Difference\", ax = axes[0]\n);\n\nmulti_2d_delta_g = combine(dabest_objects_2d, labels_2d, row_labels=row_labels_2d, effect_size=\"delta_g\")\nprint(\"multi_2d_delta_g is a \" + str(multi_2d_delta_g))\n\nmulti_2d_delta_g.whorlmap(\n    cmap=\"vlag\",\n    chop_tail=2.5,  # Remove 5% extreme values\n    title=\"Delta g\", ax = axes[1]\n);\n\nmulti_2d_delta_g is a MultiContrast(2D: 6x8, effect_size='delta_g', contrast_type='delta2')",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#multicontrast-object-can-also-handle-1-d-dabest-object-arrays",
    "href": "tutorials/10-whorlmap.html#multicontrast-object-can-also-handle-1-d-dabest-object-arrays",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "MultiContrast object can also handle 1-D dabest object arrays",
    "text": "MultiContrast object can also handle 1-D dabest object arrays\n\nmulti_1d = combine(dabest_objects_2d[0], labels_2d, row_labels=\"Drug A\", effect_size=\"mean_diff\")\n\nYou can plot a forest plot from this MultiContrast object\n\nfig_forest = multi_1d.forest_plot(forest_plot_kwargs = {\"title\":\"Forest Plot from Multi Contrast (1D)\", \"marker_size\": 6})",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#d-whorlmap-also-works",
    "href": "tutorials/10-whorlmap.html#d-whorlmap-also-works",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "1-D whorlmap also works",
    "text": "1-D whorlmap also works\n\nmulti_1d.whorlmap(\n    n=21,  # Larger spiral size\n    chop_tail=2.5  # Remove 5% extreme values\n)\n# plt.title(\"Customized whorlmap\")\nplt.show()\n\n\n\n\n\n\n\n\n\ndabest_objects_2d_2group_delta = [[None for _ in range(8)] for _ in range(6)]\nfor i in range(len(row_labels_2d)):\n    for j in range(len(labels_2d)):\n        df = create_delta_dataset(seed=seeds[i], \n                                  fourth_quarter_adjustment=drug_effect_2d[i][j],\n                                  scale4=drug_effect_scale_2d[i][j],\n                                 initial_loc = 20)\n        dabest_objects_2d_2group_delta[i][j] = dabest.load(data=df, \n                       x=\"Treatment\", \n                       y=\"Transcript Level\", \n                       idx = (\"Placebo\", \"Drug\"))\nmulti_2d_2group_delta_mean_diff = combine(dabest_objects_2d_2group_delta, labels_2d, row_labels=row_labels_2d, effect_size=\"mean_diff\")\nprint(\"multi_2d_mean_diff is a \" + str(multi_2d_2group_delta_mean_diff))\n\nmulti_2d_mean_diff is a MultiContrast(2D: 6x8, effect_size='mean_diff', contrast_type='delta')\n\n\n\nmulti_2d_2group_delta_mean_diff.whorlmap(\n    title=\"Mean Difference Treatment Whorlmap\",\n    cmap=\"vlag\",\n    chop_tail=2.5,  # Remove 5% extreme values\n    fig_size = (10, 4)\n);\n\n\n\n\n\n\n\n\n\nmulti_2d_2group_delta_mean_diff.whorlmap(\n    title=\"Mean Difference Treatment Whorlmap\",\n    cmap=\"vlag\",\n    chop_tail=2.5,  # Remove 5% extreme values\n    fig_size = (10, 4),\n    heatmap_kwargs={'cbar_kws':{'pad':0.17}}\n);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/10-whorlmap.html#heatmap-and-plot-kwargs",
    "href": "tutorials/10-whorlmap.html#heatmap-and-plot-kwargs",
    "title": "Whorlmaps: Visualizing Even More Contrasts",
    "section": "Heatmap and plot kwargs",
    "text": "Heatmap and plot kwargs\nYou can customize the whorlmap further by passing in heatmap_kwargs and plot_kwargs.\n\nmulti_2d_2group_delta_mean_diff.whorlmap(\n    heatmap_kwargs={'cbar_kws':{'pad':0.10}, \"cmap\":'viridis', \"vmax\":4, \"vmin\":-4},\n    plot_kwargs={'xlabel':\"Genes\", 'ylabel':\"Drugs\", \n                 \"xticklabels\":['test1', 'test2', 'test3', 'test4', 'test5', 'test6', 'test7', 'test8'],\n                 \"xticklabels_rotation\": 90, \"xticklabels_ha\": 'center',\n                 \"yticklabels\": ['Drug1', 'Drug2', 'Drug3', 'Drug4', 'Drug5', 'Drug6'],\n                 \"yticklabels_rotation\": 45, 'yticklabels_ha': \"right\", 'title': 'My Title!'}\n);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Whorlmaps: Visualizing Even More Contrasts"
    ]
  },
  {
    "objectID": "tutorials/02-two_group.html",
    "href": "tutorials/02-two_group.html",
    "title": "Two-Group Experiments",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 41.28it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Two-Group Experiments"
    ]
  },
  {
    "objectID": "tutorials/02-two_group.html#load-libraries",
    "href": "tutorials/02-two_group.html#load-libraries",
    "title": "Two-Group Experiments",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 41.28it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Two-Group Experiments"
    ]
  },
  {
    "objectID": "tutorials/02-two_group.html#creating-a-demo-dataset",
    "href": "tutorials/02-two_group.html#creating-a-demo-dataset",
    "title": "Two-Group Experiments",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\nHere, we create a dataset to illustrate how to perform Two-Group analyses using dabest.\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                 'Control 2' : c2,     'Test 2' : t2,\n                 'Control 3' : c3,     'Test 3' : t3,\n                 'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                 'Gender'    : gender, 'ID'  : id_col\n                })\ndf.head(5)\n\n\n\n\n\n\n\n\nControl 1\nTest 1\nControl 2\nTest 2\nControl 3\nTest 3\nTest 4\nTest 5\nTest 6\nGender\nID\n\n\n\n\n0\n2.793984\n3.420875\n3.324661\n1.707467\n3.816940\n1.796581\n4.440050\n2.937284\n3.486127\nFemale\n1\n\n\n1\n3.236759\n3.467972\n3.685186\n1.121846\n3.750358\n3.944566\n3.723494\n2.837062\n2.338094\nFemale\n2\n\n\n2\n3.019149\n4.377179\n5.616891\n3.301381\n2.945397\n2.832188\n3.214014\n3.111950\n3.270897\nFemale\n3\n\n\n3\n2.804638\n4.564780\n2.773152\n2.534018\n3.575179\n3.048267\n4.968278\n3.743378\n3.151188\nFemale\n4\n\n\n4\n2.858019\n3.220058\n2.550361\n2.796365\n3.692138\n3.276575\n2.662104\n2.977341\n2.328601\nFemale\n5",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Two-Group Experiments"
    ]
  },
  {
    "objectID": "tutorials/02-two_group.html#loading-data",
    "href": "tutorials/02-two_group.html#loading-data",
    "title": "Two-Group Experiments",
    "section": "Loading data",
    "text": "Loading data\nFirst, we need to load the data and specify the relevant groups.\nWe can achieve this by supplying the dataframe to dabest.load(). Additionally, we must provide the groups to be compared in the idx argument as a tuple or list.\nFor this tutorial, we will create two separate analyses:\n\nA singular two-group comparison between Control 1 and Test 1.\nA multi two-group comparison between Control 1 and Test 1, and between Control 2 and Test 2.\n\nThe multi two-group estimation plot tiles two or more Cumming plots horizontally, and is created by passing a nested tuple to idx when dabest.load() is first invoked.\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\nmulti_two_groups_unpaired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\")))\n\nIn addition, we can specify the paired argument to indicate paired data.\npaired can be set as 'baseline' or 'sequential' or left as None (unpaired).\nNote: For two-group, both 'baseline' and 'sequential' are equivalent.\n\ntwo_groups_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), paired='baseline', id_col='ID')\nmulti_two_groups_paired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\")), \n                                      paired='baseline', id_col='ID')\n\nThe dabest library features a range of effect sizes. In this case, we shall proceed with the default effect size, which is the mean difference.\nHere we will show the two-group unpaired analysis as an example.\n\ntwo_groups_unpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 15:59:53 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.48 [95%CI 0.205, 0.774].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\nA dataframe of the mean_diff results can be extracted by calling the results attribute of the dabest.mean_diff object.\n\ntwo_groups_unpaired.mean_diff.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\n...\npvalue_mann_whitney\nstatistic_mann_whitney\nbec_difference\nbec_bootstraps\nbec_bca_interval_idx\nbec_bca_low\nbec_bca_high\nbec_pct_interval_idx\nbec_pct_low\nbec_pct_high\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nmean difference\nNone\n0.48029\n95\n0.205161\n0.773647\n...\n0.001625\n83.0\n0.0\n[-0.09732932551566487, 0.08087009665445155, -0...\n(127, 4877)\n-0.256862\n0.259558\n(125, 4875)\n-0.25826\n0.25759\n\n\n\n\n1 rows √ó 35 columns",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Two-Group Experiments"
    ]
  },
  {
    "objectID": "tutorials/02-two_group.html#producing-estimation-plots",
    "href": "tutorials/02-two_group.html#producing-estimation-plots",
    "title": "Two-Group Experiments",
    "section": "Producing estimation plots",
    "text": "Producing estimation plots\nWe can now call the .plot() method to generate the estimation plot.\n\ntwo_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\nFor singular two-group comparisons, the plot will display the effect size curve by default to the right of the raw data. We term this a Gardner-Altman plot.\nThis can be changed by setting the float_contrast argument to False. Here, the effect size curve will be displayed below the raw data - a Cumming estimation plot.\n\ntwo_groups_unpaired.mean_diff.plot(float_contrast=False);\n\n\n\n\n\n\n\n\nFor multi two-group comparisons, the effect size curves will always be displayed below the raw data.\nThe lower axes in the Cumming plot is effectively a forest plot, commonly used in meta-analyses to aggregate and to compare data from different experiments.\nNote: If you‚Äôre interested in just plotting the contrast ax (the violin plots), you may be interested in the new forest plot feature added in v2025.03.27!\n\nmulti_two_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\nFor paired data, we use slopegraphs (another innovation from Edward Tufte) to connect paired observations. Both Gardner-Altman and Cumming plots support this.\n\ntwo_groups_paired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\ntwo_groups_paired.mean_diff.plot(float_contrast=False);\n\n\n\n\n\n\n\n\n\nmulti_two_groups_paired.mean_diff.plot();\n\n\n\n\n\n\n\n\nFor further aesthetic changes, the Plot Aesthetics Tutorial provides detailed examples of how to customize the plot.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Two-Group Experiments"
    ]
  },
  {
    "objectID": "tutorials/05-mini_meta.html",
    "href": "tutorials/05-mini_meta.html",
    "title": "Mini-Meta",
    "section": "",
    "text": "When scientists conduct replicates of the same experiment, the effect size of each replicate often varies, complicating the interpretation of the results. Starting from v2023.02.14, DABEST can now compute the meta-analyzed weighted effect size given multiple replicates of the same experiment. This can help resolve differences between replicates and simplify interpretation.\nFor this function, the generic inverse-variance weighting method is used to calculate a weighted mean difference, as follows:\n\\(\\hat{\\Delta}_w = \\frac{\\sum\\hat{\\Delta}_i\\,w_i}{\\sum w_i},\\quad w_i =\\frac{1}{\\hat{\\sigma}_i^{2}},\\quad \\hat{\\sigma}_i^{2} =\\operatorname{var}\\!\\big(\\hat{\\Delta}_i\\big)\\)\nThe variance used is calculated empirically as the sample variance of the bootstrapped values of the mean difference.\n\\(\\hat{\\Delta}_w=\\frac{\\sum\\hat{\\Delta}_i\\,\\hat{w}_i}{\\sum\\hat{w}_i},\\quad \\hat{w}_i=\\frac{n_i-1}{\\sum_{r=1}^{n_i}\\bigl(\\hat{\\Delta}_i^{(r)}-\\bar{\\Delta}_i^{\\mathrm{b}}\\bigr)^2},\\quad \\bar{\\Delta}_i^{\\mathrm{b}}=\\frac{1}{n_i}\\sum_{r=1}^{n_i}\\hat{\\Delta}_i^{(r)}.\\)\nWhere \\(\\hat{\\Delta}_w\\): estimated weighted delta;\n\\(w_i\\): weight for replicate \\(i\\);\n\\(\\hat{\\sigma}_i^2\\): sampling variance of the mean-difference estimator for replicate \\(i\\);\n\\(\\hat{\\Delta}_i\\): estimated mean difference for replicate \\(i\\);\n\\(\\hat{w}_i\\): estimated weight for replicate \\(i\\);\n\\(n_i\\): number of bootstrap replicates used for replicate \\(i\\);\n\\(\\hat{\\Delta}_i^{(r)}\\): the \\(r\\)-th bootstrap estimate of the mean difference for replicate \\(i\\);\n\\(\\bar{\\Delta}_i^{\\mathrm{b}}\\): bootstrap mean of the mean differences for replicate \\(i\\)\nNote that this utilizes the fixed-effects model of meta-analysis, in contrast to the random-effects model. In the fixed-effects model, all variation between the results of each replicate is assumed to be solely due to sampling error. Therefore, we recommend using this function exclusively for replications of the same experiment, where it can be safely assumed that each replicate estimates the same population mean \\(\\mu\\).\nAdditionally, be aware that as of v2023.02.14, DABEST can only compute weighted effect size for mean difference only, and not for standardized measures such as Cohen‚Äôs d.\nFor more information on meta-analysis, please refer to Chapter 10 of the Cochrane handbook.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mini-Meta"
    ]
  },
  {
    "objectID": "tutorials/05-mini_meta.html#load-libraries",
    "href": "tutorials/05-mini_meta.html#load-libraries",
    "title": "Mini-Meta",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 62.75it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mini-Meta"
    ]
  },
  {
    "objectID": "tutorials/05-mini_meta.html#creating-a-demo-dataset",
    "href": "tutorials/05-mini_meta.html#creating-a-demo-dataset",
    "title": "Mini-Meta",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                   'Control 2' : c2,     'Test 2' : t2,\n                   'Control 3' : c3,     'Test 3' : t3,\n                   'Gender'    : gender, 'ID'  : id_col\n                  })\ndf.head()\n\n\n\n\n\n\n\n\nControl 1\nTest 1\nControl 2\nTest 2\nControl 3\nTest 3\nGender\nID\n\n\n\n\n0\n2.793984\n3.420875\n3.324661\n1.707467\n3.816940\n1.796581\nFemale\n1\n\n\n1\n3.236759\n3.467972\n3.685186\n1.121846\n3.750358\n3.944566\nFemale\n2\n\n\n2\n3.019149\n4.377179\n5.616891\n3.301381\n2.945397\n2.832188\nFemale\n3\n\n\n3\n2.804638\n4.564780\n2.773152\n2.534018\n3.575179\n3.048267\nFemale\n4\n\n\n4\n2.858019\n3.220058\n2.550361\n2.796365\n3.692138\n3.276575\nFemale\n5\n\n\n\n\n\n\n\nWe now have three Control and three Test groups, simulating three replicates of the same experiment. Our dataset has also a non-numerical column indicating gender, and another column indicating the identity of each observation.\nThis is known as a ‚Äòwide‚Äô dataset. See this writeup for more details.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mini-Meta"
    ]
  },
  {
    "objectID": "tutorials/05-mini_meta.html#loading-data",
    "href": "tutorials/05-mini_meta.html#loading-data",
    "title": "Mini-Meta",
    "section": "Loading data",
    "text": "Loading data\nNext, we load data as usual using dabest.load(). However, this time, we also specify the argument mini_meta=True. Since we are loading data from three experiments, idx is passed as a tuple of tuples, as shown below.\nWhen this dabest object is invoked, it should indicate that effect sizes will be calculated for each group, along with the weighted delta. It is important to note once again that the weighted delta will only be calculated for mean differences.\n\nunpaired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), mini_meta=True)\nunpaired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:46 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 3\n4. weighted delta (only for mean difference)\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\nBy calling the mean_diff attribute, you can view the mean differences for each group as well as the weighted delta.\n\nunpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:47 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.48 [95%CI 0.205, 0.774].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 2 is -1.38 [95%CI -1.93, -0.905].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 3 and Test 3 is -0.255 [95%CI -0.696, 0.208].\nThe p-value of the two-sided permutation t-test is 0.293, calculated for legacy purposes only. \n\nThe weighted-average unpaired mean differences is -0.00983 [95%CI -0.225, 0.213].\nThe p-value of the two-sided permutation t-test is 0.941, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\nYou can view the details of each experiment by accessing the property mean_diff.results as follows.\n\npd.options.display.max_columns = 50\nunpaired.mean_diff.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps\nresamples\nrandom_seed\npermutations\npvalue_permutation\npermutation_count\npermutations_var\npvalue_welch\nstatistic_welch\npvalue_students_t\nstatistic_students_t\npvalue_mann_whitney\nstatistic_mann_whitney\nbec_difference\nbec_bootstraps\nbec_bca_interval_idx\nbec_bca_low\nbec_bca_high\nbec_pct_interval_idx\nbec_pct_low\nbec_pct_high\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nmean difference\nNone\n0.480290\n95\n0.205161\n0.773647\n(145, 4893)\n0.197427\n0.758752\n(125, 4875)\n[0.6148498102262239, 0.6752095203445543, 0.300...\n5000\n12345\n[-0.17259843762502491, 0.03802293852634886, -0...\n0.0010\n5000\n[0.26356588154404337, 0.2710249543904699, 0.26...\n0.002094\n-3.308806\n0.002057\n-3.308806\n0.001625\n83.0\n0.0\n[-0.09732932551566487, 0.08087009665445155, -0...\n(127, 4877)\n-0.256862\n0.259558\n(125, 4875)\n-0.258260\n0.257590\n\n\n1\nControl 2\nTest 2\n20\n20\nmean difference\nNone\n-1.381085\n95\n-1.934192\n-0.905164\n(94, 4838)\n-1.901802\n-0.877098\n(125, 4875)\n[-1.7266697532252988, -1.7990605927248775, -1....\n5000\n12345\n[0.015164519971271773, 0.017231919606192303, -...\n0.0000\n5000\n[1.2241741427801065, 1.2241565174150129, 1.128...\n0.000011\n5.138840\n0.000009\n5.138840\n0.000026\n356.0\n0.0\n[-0.7109511916465152, -0.3436697507223183, -0....\n(126, 4876)\n-0.578621\n0.598647\n(125, 4875)\n-0.579306\n0.598009\n\n\n2\nControl 3\nTest 3\n20\n20\nmean difference\nNone\n-0.254831\n95\n-0.696379\n0.207659\n(123, 4873)\n-0.694790\n0.208585\n(125, 4875)\n[0.3059887140714319, -0.22727011648745288, 0.0...\n5000\n12345\n[-0.05901068591042824, -0.13617667681797307, 0...\n0.2934\n5000\n[0.5835889750166371, 0.5796253365278035, 0.581...\n0.294766\n1.069798\n0.291459\n1.069798\n0.285305\n240.0\n0.0\n[0.07996849455952271, 0.24534680794041375, 0.0...\n(124, 4874)\n-0.243754\n0.240283\n(125, 4875)\n-0.243713\n0.240490\n\n\n\n\n\n\n\nNote, however, that this does not contain the relevant information for our weighted delta. The details of the weighted delta are stored as attributes of the mini_meta object, such as:\n\ngroup_var: the pooled group variances of each set of 2 experiment groups.\ndifference: the weighted mean difference calculated based on the raw data.\nbootstraps: the deltas of each set of 2 experiment groups calculated based on the bootstraps.\nbootstraps_weighted_delta: the weighted deltas calculated based on the bootstraps.\npermutations: the deltas of each set of 2 experiment groups calculated based on the permutation data.\npermutations_var: the pooled group variances of each set of 2 experiment groups calculated based on permutation data.\npermutations_weighted_delta: the weighted deltas calculated based on the permutation data.\n\nA dataframe of this mini meta dabest object can also be called via the mini_meta.results attribute.\n\nunpaired.mean_diff.mini_meta.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\ncontrol_var\ntest_var\ngroup_var\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps_deltas\nbootstraps_weighted_delta\npermutations\npermutations_var\npermutations_weighted_delta\npvalue_permutation\npermutation_count\nbias_correction\njackknives\n\n\n\n\n0\n[Control 1, Control 2, Control 3]\n[Test 1, Test 2, Test 3]\n[20, 20, 20]\n[20, 20, 20]\n[0.17628013404546258, 0.9584767911266554, 0.16...\n[0.24512071870152594, 0.48609989925165153, 0.9...\n[0.2107004263734943, 0.7222883451891535, 0.567...\n-0.00983\n95\n-0.225073\n0.213221\n(133, 4883)\n-0.227199\n0.210616\n(125, 4875)\n[[0.6148498102262239, 0.6752095203445543, 0.30...\n[0.1383993266160009, 0.040698566036827026, -0....\n[[-0.17259843762502491, 0.03802293852634886, -...\n[[0.26356588154404337, 0.2710249543904699, 0.2...\n[-0.11757207833491819, -0.01292867970093462, -...\n0.9412\n5000\n0.014539\n[-0.010633066723935882, -0.010613522663007862,...",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mini-Meta"
    ]
  },
  {
    "objectID": "tutorials/05-mini_meta.html#generating-mini-meta-plots",
    "href": "tutorials/05-mini_meta.html#generating-mini-meta-plots",
    "title": "Mini-Meta",
    "section": "Generating mini meta plots",
    "text": "Generating mini meta plots\n\nunpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\nYou can also hide the weighted delta by passing the argument show_mini_meta=False. In this case, the resulting graph would be identical to a multiple two-groups plot.\n\nunpaired.mean_diff.plot(show_mini_meta=False);\n\n\n\n\n\n\n\n\nAs with regular two-groups plots, you can also analyse paired mini meta experiments via the paired=baseline argument.\n\npaired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), mini_meta=True, id_col=\"ID\", paired=\"baseline\")\npaired.mean_diff.plot();\n\n\n\n\n\n\n\n\nFor further aesthetic changes, the Plot Aesthetics Tutorial provides detailed examples of how to customize the plot.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mini-Meta"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html",
    "href": "tutorials/08-plot_aesthetics.html",
    "title": "Controlling Plot Aesthetics",
    "section": "",
    "text": "Since v2024.03.29, swarmplots are, by default, plotted asymmetrically to the right side. For detailed information, please refer to Swarm Side.\nSince v2025.03.27, further aesthetic changes were added/updated which include:",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#load-libraries",
    "href": "tutorials/08-plot_aesthetics.html#load-libraries",
    "title": "Controlling Plot Aesthetics",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\nimport seaborn as sns\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 50.20it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#creating-a-demo-dataset",
    "href": "tutorials/08-plot_aesthetics.html#creating-a-demo-dataset",
    "title": "Controlling Plot Aesthetics",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                   'Control 2' : c2,     'Test 2' : t2,\n                   'Control 3' : c3,     'Test 3' : t3,\n                   'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                   'Gender'    : gender, 'ID'  : id_col\n                  })\n\nnp.random.seed(9999) # Fix the seed so the results are replicable.\n\n# Create samples\nN = 20\ny = norm.rvs(loc=3, scale=0.4, size=N*4)\ny[N:2*N] = y[N:2*N]+1\ny[2*N:3*N] = y[2*N:3*N]-0.5\n\n# Add a `Treatment` column\nt1 = np.repeat('Placebo', N*2).tolist()\nt2 = np.repeat('Drug', N*2).tolist()\ntreatment = t1 + t2 \n\n# Add a `Rep` column as the first variable for the 2 replicates of experiments done\nrep = []\nfor i in range(N*2):\n    rep.append('Rep1')\n    rep.append('Rep2')\n\n# Add a `Genotype` column as the second variable\nwt = np.repeat('W', N).tolist()\nmt = np.repeat('M', N).tolist()\nwt2 = np.repeat('W', N).tolist()\nmt2 = np.repeat('M', N).tolist()\n\ngenotype = wt + mt + wt2 + mt2\n\n# Add an `id` column for paired data plotting.\nid = list(range(0, N*2))\nid_col = id + id \n\n# Combine all columns into a DataFrame.\ndf_delta2 = pd.DataFrame({'ID'        : id_col,\n                  'Rep'      : rep,\n                   'Genotype'  : genotype, \n                   'Treatment': treatment,\n                   'Y'         : y\n                })\n\ndef create_demo_prop_dataset(seed=9999, N=40):\n    import numpy as np\n    import pandas as pd\n\n    np.random.seed(9999)  # Fix the seed to ensure reproducibility of results.\n    # Create samples\n    n = 1\n    c1 = np.random.binomial(n, 0.2, size=N)\n    c2 = np.random.binomial(n, 0.2, size=N)\n    c3 = np.random.binomial(n, 0.8, size=N)\n\n    t1 = np.random.binomial(n, 0.6, size=N)\n    t2 = np.random.binomial(n, 0.2, size=N)\n    t3 = np.random.binomial(n, 0.3, size=N)\n    t4 = np.random.binomial(n, 0.4, size=N)\n    t5 = np.random.binomial(n, 0.5, size=N)\n    t6 = np.random.binomial(n, 0.6, size=N)\n    t7 = np.ones(N)\n    t8 = np.zeros(N)\n    t9 = np.zeros(N)\n\n    # Add a `gender` column for coloring the data.\n    females = np.repeat('Female', N / 2).tolist()\n    males = np.repeat('Male', N / 2).tolist()\n    gender = females + males\n\n    # Add an `id` column for paired data plotting.\n    id_col = pd.Series(range(1, N + 1))\n\n    # Combine samples and gender into a DataFrame.\n    df = pd.DataFrame({'Control 1': c1, 'Test 1': t1,\n                       'Control 2': c2, 'Test 2': t2,\n                       'Control 3': c3, 'Test 3': t3,\n                       'Test 4': t4, 'Test 5': t5, 'Test 6': t6,\n                       'Test 7': t7, 'Test 8': t8, 'Test 9': t9,\n                       'Gender': gender, 'ID': id_col\n                       })\n\n    return df\ndf_prop = create_demo_prop_dataset()\n\n\ntwo_groups_prop_paired = dabest.load(df_prop, idx=(\"Control 1\", \"Test 1\"), proportional=True, paired=\"baseline\", id_col=\"ID\")\ntwo_groups_prop = dabest.load(df_prop, idx=(\"Control 1\", \"Test 1\"), proportional=True)\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\")))\nrepeated_measures = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\"),paired=\"baseline\", id_col=\"ID\")\ntwo_groups_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), paired=\"baseline\", id_col=\"ID\")\nmini_meta_paired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), mini_meta=True, id_col=\"ID\", paired=\"baseline\")\npaired_delta2 = dabest.load(data = df_delta2, \n                                paired = \"baseline\", id_col=\"ID\",\n                                x = [\"Treatment\", \"Rep\"], y = \"Y\", \n                                delta2 = True, experiment = \"Genotype\")",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#changing-the-graph-colours",
    "href": "tutorials/08-plot_aesthetics.html#changing-the-graph-colours",
    "title": "Controlling Plot Aesthetics",
    "section": "Changing the graph colours",
    "text": "Changing the graph colours\n\nColor categories from another variable\nUse the parameter color_col to specify which column in the dataframe will be used to create the different colours for your graph.\n\nmulti_2group.mean_diff.plot(color_col=\"Gender\");\n\ntwo_groups_paired.mean_diff.plot(color_col=\"Gender\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom palette\nThe colour palette for the graph can be changed using the parameter custom_palette. Multiple types of color palettes can be used:\n\nA list of colors (named colors, hex, rgb, etc) e.g.¬†['red', 'blue', 'green']\nA seaborn color palette e.g.¬†'Set1'\nA matplotlib color map e.g.¬†'viridis'\n\n'paired' is an interesting option for two-group (or multi two-group) comparisons\n\nA dictionary with the keys as the column names and the values as the colors e.g.¬†{'Control 1': 'red', 'Test 1': 'blue', 'Test 2': 'green'}\n\nOr, a dictionary with the keys as the binary options for proportion plots (barplots and sankey) and the values as the colors e.g.¬†{0: 'red', 1: 'blue'}\n\n\n\nA list of colors\n\nmulti_2group.mean_diff.plot(custom_palette=['red', 'blue', 'green', 'purple', 'orange', 'brown']);\n\n\n\n\n\n\n\n\n\n\nSeaborn color palette\n\nmulti_2group.mean_diff.plot(custom_palette=sns.color_palette(\"husl\", 6));\n\n\n\n\n\n\n\n\n\n\nMatplotlib color map/palette\n\nmulti_2group.mean_diff.plot(custom_palette=\"viridis\");\nmulti_2group.mean_diff.plot(custom_palette=\"Paired\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA user-defined dictionary\nThere are many ways to specify matplotlib colours. Find one example below using accepted colour names, hex strings (commonly used on the web), and RGB tuples.\n\nmy_color_palette = {\"Control 1\" : \"blue\",\n                        \"Test 1\"    : \"purple\",\n                        \"Control 2\" : \"#cb4b16\",     # This is a hex string.\n                        \"Test 2\"    : (0., 0.7, 0.2) # This is a RGB tuple.\n                       }\n\nmulti_2group.mean_diff.plot(custom_palette=my_color_palette);\n\n\n\n\n\n\n\n\nFor proportion plots (barplots and sankey), a color palette dict can also be supplied via {1: first_color, 0, second_color} where first_color and second_color are valid matplotlib colours.\n\ntwo_groups_prop.mean_diff.plot(custom_palette={1: \"red\", 0: \"blue\"});\n\n\n\n\n\n\n\n\n\ntwo_groups_prop_paired.mean_diff.plot(custom_palette={1: \"red\", 0: \"blue\"});\n\n\n\n\n\n\n\n\n\n\nColor palette changes also now affect the effect size curve colors in paired plots\nNote: The first color in the custom palette is used for the control group. As in the example below, if show_baseline_ec is set to False, it wont be represented in the plot.\n\nrepeated_measures.mean_diff.plot(custom_palette=[\"red\", \"blue\", \"green\", \"purple\"]);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#color-saturation",
    "href": "tutorials/08-plot_aesthetics.html#color-saturation",
    "title": "Controlling Plot Aesthetics",
    "section": "Color saturation",
    "text": "Color saturation\nBy default, dabest.plot() desaturates the colour of the dots in the swarmplot by 50%. This draws attention to the effect size bootstrap curves.\nYou can alter the default values with the parameters raw_desat and contrast_desat.\n\nmulti_2group.mean_diff.plot(custom_palette=my_color_palette,\n                                raw_desat=0.75,\n                                contrast_desat=0.25);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#alpha-transparency",
    "href": "tutorials/08-plot_aesthetics.html#alpha-transparency",
    "title": "Controlling Plot Aesthetics",
    "section": "Alpha (transparency)",
    "text": "Alpha (transparency)\nIt is possible change the transparency of the raw data by using the raw_alpha parameter. This can also be achieved by adding alpha to the relevant rawdata kwargs (barplot_kwargs, or swarmplot_kwargs, or slopegraph_kwargs, or sankey_kwargs)\n\nmulti_2group.mean_diff.plot(raw_alpha=0.2);\n\nmulti_2group.mean_diff.plot(swarmplot_kwargs={'alpha': 0.2});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is also possible change the transparency of the effect size curves by using the contrast_alpha parameter. This can also be achieved via adding alpha to the contrast_kwargs parameter.\n\nmulti_2group.mean_diff.plot(contrast_alpha=0.2);\n\nmulti_2group.mean_diff.plot(contrast_kwargs={'alpha':0.2});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#marker-size",
    "href": "tutorials/08-plot_aesthetics.html#marker-size",
    "title": "Controlling Plot Aesthetics",
    "section": "Marker size",
    "text": "Marker size\nIt is possible change the size of the dots used in the rawdata swarmplot, as well as those to indicate the effect sizes, by using the parameters raw_marker_size and contrast_marker_size respectively.\n\nmulti_2group.mean_diff.plot(raw_marker_size=3,\n                                contrast_marker_size=12);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#axes",
    "href": "tutorials/08-plot_aesthetics.html#axes",
    "title": "Controlling Plot Aesthetics",
    "section": "Axes",
    "text": "Axes\n\nLims\nTo change the y-limits for the rawdata axes, and the contrast axes, use the parameters raw_ylim and contrast_ylim.\n\nmulti_2group.mean_diff.plot(raw_ylim=(0, 5),\n                                contrast_ylim=(-2, 2));\n\n\n\n\n\n\n\n\nIf the effect size is qualitatively inverted (ie. a smaller value is a better outcome), you can simply invert the tuple passed to contrast_ylim.\n\nmulti_2group.mean_diff.plot(contrast_ylim=(2, -2));\n\n\n\n\n\n\n\n\nThe contrast axes share the same y-limits as those of the delta-delta plot. Thus, the y axis of the delta-delta plot changes as well.\n\npaired_delta2.mean_diff.plot(contrast_ylim=(3, -3));\n\n\n\n\n\n\n\n\nYou can also change the y-limit of the delta-delta axes and the regular delta axes via the delta2_ylim parameter.\n\npaired_delta2.mean_diff.plot(delta2_ylim=(3, -3));\n\n\n\n\n\n\n\n\n\n\nLabels\n\nraw_label - label the raw data y-axis\ncontrast_label - label the contrast y-axis\n\n\ntwo_groups_unpaired.mean_diff.plot(raw_label=\"This is my\\nrawdata\", \n                                   contrast_label=\"The bootstrap\\ndistribtions!\"\n                                );\n\n\n\n\n\n\n\n\nUnique for delta-delta: - delta2_ylim - to label the delta-delta y-axis\n\npaired_delta2.mean_diff.plot(delta2_label='delta-delta label');\n\n\n\n\n\n\n\n\n\n\nAxes ticks\nYou can add minor ticks and also change the tick frequency by accessing the axes directly.\nEach estimation plot produced by dabest has two axes. The first one contains the rawdata swarmplot while the second one contains the bootstrap effect size differences.\n\nimport matplotlib.ticker as Ticker\n\nf = two_groups_unpaired.mean_diff.plot()\n\nrawswarm_axes = f.axes[0]\ncontrast_axes = f.axes[1]\n\nrawswarm_axes.yaxis.set_major_locator(Ticker.MultipleLocator(1))\nrawswarm_axes.yaxis.set_minor_locator(Ticker.MultipleLocator(0.5))\n\ncontrast_axes.yaxis.set_major_locator(Ticker.MultipleLocator(0.5))\ncontrast_axes.yaxis.set_minor_locator(Ticker.MultipleLocator(0.25))\n\n\n\n\n\n\n\n\n\n\nAdd counts to tick labels\nBy default, the tick labels include the sample size for each group. This can be switched off via setting show_sample_size=False in the .plot() method.\n\ntwo_groups_unpaired.mean_diff.plot(show_sample_size=False\n                                );",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#changing-swarm-side",
    "href": "tutorials/08-plot_aesthetics.html#changing-swarm-side",
    "title": "Controlling Plot Aesthetics",
    "section": "Changing swarm side",
    "text": "Changing swarm side\nIn dabest, swarmplots are, by default, plotted asymmetrically to the right side. You may change this by using the parameter swarm_side.\nThere are only three valid values: \"right\" (default), \"left\", \"center\".\n\nmulti_2group.mean_diff.plot(swarm_side=\"right\");\nmulti_2group.mean_diff.plot(swarm_side=\"left\");\nmulti_2group.mean_diff.plot(swarm_side=\"center\");",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#creating-estimation-plots-in-existing-axes",
    "href": "tutorials/08-plot_aesthetics.html#creating-estimation-plots-in-existing-axes",
    "title": "Controlling Plot Aesthetics",
    "section": "Creating estimation plots in existing axes",
    "text": "Creating estimation plots in existing axes\nImplemented in v0.2.6 by Adam Nekimken.\ndabest.plot has an ax parameter that accepts Matplotlib Axes. The entire estimation plot will be created in the specified Axes.\n\ntwo_groups_paired_baseline = dabest.load(df, idx=(\"Control 1\", \"Test 1\"),\n                                  paired=\"baseline\", id_col=\"ID\")\nmulti_2group_paired = dabest.load(df,\n                            idx=((\"Control 1\", \"Test 1\"),\n                                 (\"Control 2\", \"Test 2\")),\n                            paired=\"baseline\", id_col=\"ID\")\n\n\nfrom matplotlib import pyplot as plt\nf, axx = plt.subplots(nrows=2, ncols=2,\n                      figsize=(15, 15),\n                      gridspec_kw={'wspace': 0.25} # ensure proper width-wise spacing.\n                     )\n\ntwo_groups_unpaired.mean_diff.plot(ax=axx.flat[0]);\n\ntwo_groups_paired_baseline.mean_diff.plot(ax=axx.flat[1]);\n\nmulti_2group.mean_diff.plot(ax=axx.flat[2]);\n\nmulti_2group_paired.mean_diff.plot(ax=axx.flat[3]);\n\n\n\n\n\n\n\n\nIn this case, to access the individual rawdata axes, use name_of_axes to manipulate the rawdata axes, and name_of_axes.contrast_axes to gain access to the effect size axes.\n\ntopleft_axes = axx.flat[0]\ntopleft_axes.set_ylabel(\"New y-axis label for rawdata\")\ntopleft_axes.contrast_axes.set_ylabel(\"New y-axis label for effect size\")\nf",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#legend",
    "href": "tutorials/08-plot_aesthetics.html#legend",
    "title": "Controlling Plot Aesthetics",
    "section": "Legend",
    "text": "Legend\nFor plots with a color_col specified, a legend will be created. Utilise the legend_kwargs parameter to adjust the legend.\n\nmulti_2group.mean_diff.plot(color_col=\"Gender\", \n                            legend_kwargs={'bbox_to_anchor': [0, 1], 'fontsize':8});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#hiding-options",
    "href": "tutorials/08-plot_aesthetics.html#hiding-options",
    "title": "Controlling Plot Aesthetics",
    "section": "Hiding options",
    "text": "Hiding options\nFor mini-meta plots, it is possible to hide the weighted average plot by setting the parameter show_mini_meta=False in the .plot() method.\n\nmini_meta_paired.mean_diff.plot(show_mini_meta=False);\n\n\n\n\n\n\n\n\nSimilarly, you can hide the delta-delta effect size by setting show_delta2=False in the .plot() method.\n\npaired_delta2.mean_diff.plot(show_delta2=False);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#effect-size-error-bar-and-marker",
    "href": "tutorials/08-plot_aesthetics.html#effect-size-error-bar-and-marker",
    "title": "Controlling Plot Aesthetics",
    "section": "Effect size error bar and marker",
    "text": "Effect size error bar and marker\nModifying the effect size marker can be done via contrast_marker_kwargs. This parameter accepts a dictionary of keyword arguments.\nThe available options are:\n\n'marker' - type of the marker\n'markersize' - size of the marker\n'color' - color of the marker\n'alpha' - alpha of the marker (transparency)\n'zorder' - zorder of the marker (the layering relative to other plot elements)\n\nNote: markersize can also be modified directly via the contrast_marker_size argument\n\ntwo_groups_unpaired.mean_diff.plot(contrast_marker_kwargs={\"marker\": \"x\", 'markersize': 15, 'color': 'green', 'alpha':0.8, 'zorder': 5});\n\n\n\n\n\n\n\n\nModifying the appearance of the effect size error bar can be done via the contrast_errorbar_kwargs parameter. This parameter accepts a dictionary of keyword arguments.\nThe relevant inputs to contrast_errorbar_kwargs are:\n\n'lw' - width of the error bar\n'linestyle' - line style of the error bar\n'color' - color of the error bar\n'zorder' - zorder of the error bar (the layering relative to other plot elements)\n'alpha' - alpha of the error bar (transparency)\n\n\ntwo_groups_unpaired.mean_diff.plot(contrast_errorbar_kwargs={'lw': 4, 'color': 'green', 'alpha':0.5, 'zorder': 2, 'linestyle': ':'});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#group-summaries",
    "href": "tutorials/08-plot_aesthetics.html#group-summaries",
    "title": "Controlling Plot Aesthetics",
    "section": "Group summaries",
    "text": "Group summaries\nGroup summaries represent the summary statistics of the sample and are included by default.\nIn swarmplots and proportion plots, these are represented by gapped lines.\nIn slopegraphs, these are represented by a solid line connecting the group mean/median with error bars.\nThe type of group summary can be specified via group_summaries in the .plot() method and must be one of these: 'median_quartiles', 'mean_sd', None.\nBy default, the group summary is set to 'mean_sd'.\n\ntwo_groups_unpaired.mean_diff.plot(group_summaries=\"mean_sd\");\ntwo_groups_unpaired.mean_diff.plot(group_summaries=\"median_quartiles\");\ntwo_groups_unpaired.mean_diff.plot(group_summaries=None);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor slopegraphs, the group summary is represented by a solid line connecting the group mean/median with error bars.\n\nrepeated_measures.mean_diff.plot(group_summaries=\"mean_sd\");\nrepeated_measures.mean_diff.plot(group_summaries=\"median_quartiles\");\nrepeated_measures.mean_diff.plot(group_summaries=None);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup summaries have an associated kwargs group_summaries_kwargs\nThe relevant inputs to group_summaries_kwargs are:\n\n'zorder' - zorder of the gapped lines (the layering relative to other plot elements)\n'lw' - linewidth of the gapped lines\n'alpha' - alpha of the gapped lines (transparency)\n'gap_width_percent' - gap size (for gapped lines only)\n'offset' - location adjustment of the gapped lines (x-axis; for gapped lines only)\n'color' - the shared color of the gapped lines\n\n\ntwo_groups_unpaired.mean_diff.plot(group_summaries_kwargs={'gap_width_percent': 3, 'alpha': 0.5, 'lw': 4, 'offset': 0.6, 'color':'red'});\n\n\n\n\n\n\n\n\n\nrepeated_measures.mean_diff.plot(group_summaries_kwargs={'gap_width_percent': 3, 'alpha': 0.5, 'lw': 4, 'offset': 0.6, 'color':'red'});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#raw-bars",
    "href": "tutorials/08-plot_aesthetics.html#raw-bars",
    "title": "Controlling Plot Aesthetics",
    "section": "Raw bars",
    "text": "Raw bars\nRaw bars are included in swarmplots by default. It can be turned off by setting raw_bars=False in the .plot() method.\n\nmulti_2group.mean_diff.plot(raw_bars=True, contrast_bars=False);\n\n\n\n\n\n\n\n\nRaw bar kwargs can be utilised via raw_bars_kwargs in the .plot() method.\nPass any keyword arguments accepted by matplotlib.patches.Rectangle here, as a string.\n\nmulti_2group.mean_diff.plot(raw_bars=True, contrast_bars=False,\n                            raw_bars_kwargs={'color': \"red\", 'alpha': 0.2}, \n                            );",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#contrast-bars",
    "href": "tutorials/08-plot_aesthetics.html#contrast-bars",
    "title": "Controlling Plot Aesthetics",
    "section": "Contrast bars",
    "text": "Contrast bars\nContrast bars are included in all plots by default. It can be turned off by setting contrast_bars=False in the .plot() method.\n\nmulti_2group.mean_diff.plot(contrast_bars=True, raw_bars=False);\n\n\n\n\n\n\n\n\nContrast bar kwargs can be utilised via contrast_bars_kwargs in the .plot() method.\nPass any keyword arguments accepted by matplotlib.patches.Rectangle here, as a string.\n\nmulti_2group.mean_diff.plot(contrast_bars=True, raw_bars=False, \n                            contrast_bars_kwargs={'color': \"red\", 'alpha': 0.1}\n                            );",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#reference-band",
    "href": "tutorials/08-plot_aesthetics.html#reference-band",
    "title": "Controlling Plot Aesthetics",
    "section": "Reference band",
    "text": "Reference band\nA reference band can be added for each relevant contrast object as desired via supplying a list to the argument reference_band in the .plot() method.\n\nmulti_2group.mean_diff.plot(reference_band=[0, 1], contrast_bars=False, raw_bars=False);\n\n\n\n\n\n\n\n\nReference band kwargs can be utilised via reference_band_kwargs in the .plot() method.\nThe relevant inputs to reference_band_kwargs are:\n\n'span_ax' - Whether the reference band(s) should span the entire x-axis or start from the relevant effect size curve\n'color' - Color of the reference band(s). If color is not specified, the color of the effect size curve will be used.\n'alpha' - Alpha of the reference band(s) (transparency)\n'zorder' - Zorder of the reference band(s) (the layering relative to other plot elements)\n\n\nmulti_2group.mean_diff.plot(reference_band=[0,1], contrast_bars=False, raw_bars=False,\n                            reference_band_kwargs={\"alpha\": 0.2, \"color\": 'black', 'span_ax': True}\n                            );",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#delta-text",
    "href": "tutorials/08-plot_aesthetics.html#delta-text",
    "title": "Controlling Plot Aesthetics",
    "section": "Delta text",
    "text": "Delta text\nDelta text is included in all plots by default. It can be turned off by setting delta_text=False in the .plot() method.\n\nmulti_2group.mean_diff.plot(delta_text=True);\n\n\n\n\n\n\n\n\nDelta text kwargs can be utilised via delta_text_kwargs in the .plot() method.\nThe relevant inputs to delta_text_kwargs are:\n\n'color' - Color. If color is not specified, the color of the effect size curve will be used.\n'alpha'- Alpha (transparency)\n'fontsize' - Font size\n'ha' - Horizontal alignment\n'va' - Vertical alignment\n'rotation' - Text rotation\n'x_coordinates' - Specify the x-coordinates of the text\n'y_coordinates' - Specify the y-coordinates of the text\n'offset' - Am x-axis coordinate adjuster for minor movement of all text\n\nOtherwise, pass any keyword arguments accepted by matplotlib.text.Text, as a string.\n\nmulti_2group.mean_diff.plot(delta_text=True, \n                            delta_text_kwargs={\"color\":\"red\", \"rotation\":45, \"va\":\"bottom\", \"alpha\":0.7});\n\n\n\n\n\n\n\n\n'x_coordinates' and/or 'y_coordinates' if you would like to specify the text locations manually.\n\nmulti_2group.mean_diff.plot(delta_text=True, \n                            delta_text_kwargs={\"x_coordinates\":(0.5, 2.75), \n                                               \"y_coordinates\":(0.5, -1.7)});\n\n\n\n\n\n\n\n\n'offset' to adjust the x location of all the texts (positive moves right, negative left).\n\nmulti_2group.mean_diff.plot(delta_text=True, \n                            delta_text_kwargs={\"offset\":0.1});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#adding-jitter-to-slopegraph-plots",
    "href": "tutorials/08-plot_aesthetics.html#adding-jitter-to-slopegraph-plots",
    "title": "Controlling Plot Aesthetics",
    "section": "Adding jitter to slopegraph plots",
    "text": "Adding jitter to slopegraph plots\nFor paired plots, you can add jitter to the slopegraph by adding a value for jitter in the slopegraph_kwargs parameter.\nThis can be useful for specific paired plots when there are many overlapping points.\nCurrently, jitter is only available for slopegraphs and only in the x-direction (vertical plots) or y-direction (horizontal plots).\n\n# Jitter tests\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\nNs = 20 # The number of samples taken from each population\n# Create samples\nc1 = [0.5]*Ns + [1.5]*Ns\nc2 = [2]*Ns + [1]*Ns\nt1 = [1]*Ns + [2]*Ns\nt2 = [1.5]*Ns + [2.5]*Ns\nt3 = [2]*Ns + [1]*Ns\nt4 = [1]*Ns + [2]*Ns\nt5 = [1.5]*Ns + [2.5]*Ns\nid_col = pd.Series(range(1, 2*Ns+1))\ndf_jittertest= pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                 'Control 2' : c2,     'Test 2' : t2, 'Test 3' : t3,\n                    'Test 4'    : t4,     'Test 5' : t5, 'ID'  : id_col})\n\nFor the example below, there are many overlapping points for the paired plot, which makes it look like only one sample.\n\nmulti_2group = dabest.load(df_jittertest, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\", \"Test 3\", \"Test 4\", \"Test 5\")), paired='baseline', id_col='ID')\nmulti_2group.mean_diff.plot(horizontal=False, group_summaries=None);\n\n\n\n\n\n\n\n\nAdding jitter can help to visualize the data better.\n\nmulti_2group.mean_diff.plot(horizontal=False, slopegraph_kwargs={'jitter': 1}, group_summaries=None);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#gridkey",
    "href": "tutorials/08-plot_aesthetics.html#gridkey",
    "title": "Controlling Plot Aesthetics",
    "section": "Gridkey",
    "text": "Gridkey\nYou can utilise a gridkey table format for representing the index groupings. This can be reached via gridkey in the .plot() method.\nYou can either use gridkey='auto' to automatically generate the gridkey, or pass a list of indexes to represent the groupings (e.g., gridkey=['Control', 'Test']).\n\npaired_delta2.mean_diff.plot(gridkey='auto');\n\n\n\n\n\n\n\n\nGridkey kwargs can be utilised via gridkey_kwargs in the .plot() method.\nThe relevant inputs to gridkey_kwargs are:\n\n'show_es' - Whether to show the effect size in the gridkey\n'show_Ns' - Whether to show the sample sizes in the gridkey\n'merge_pairs' - Whether to merge the pairs in the gridkey (paired data only)\n'delimiters' - Delimiters to use for the autoparser. E.g., [‚Äò;‚Äô, ‚Äò&gt;‚Äô, ‚Äô_‚Äô]\n'marker' - Marker to use for filling the gridkey\n'fontsize' - Font size of the gridkey text\n'labels_fontsize' - Font size of the labels in the gridkey\n\n\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Control 2\"), (\"Test 1\", \"Test 2\")),paired='baseline', id_col='ID')\nmulti_2group.mean_diff.plot(gridkey=['Control', 'Test'], \n                            gridkey_kwargs={'merge_pairs': True, 'show_es': False, 'show_Ns': False, 'marker': '‚àö',\n                                            'fontsize': 8, 'labels_fontsize': 12});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#delta-dot",
    "href": "tutorials/08-plot_aesthetics.html#delta-dot",
    "title": "Controlling Plot Aesthetics",
    "section": "Delta dot",
    "text": "Delta dot\nBy default, delta dots are included in paired experiment plots (excluding proportion plots).\nThis feature can be turned off by setting delta_dot=False in the .plot() method.\n\nmulti_2group_paired.mean_diff.plot(delta_dot=False);\n\n\n\n\n\n\n\n\nDelta dot kwargs can be utilised via delta_dot_kwargs in the .plot() method.\nThe relevant inputs to delta_dot_kwargs are:\n\n'color' - Specify the color of the delta dots. If color is not specified, the color of the effect size curve will be used.\n'marker' - Marker of the dots. The default are triangles (‚Äò^‚Äô)\n'alpha' - Alpha (Transparency)\n'zorder' - Zorder (the layering relative to other plot elements)\n'size' - Marker size\n'side' - Which side to plot the delta dots. The options are 'left', 'right', or 'center'. This functions like the swarm_side parameter.\n\n\nmulti_2group_paired.mean_diff.plot(delta_dot_kwargs={\"color\":'red', \"alpha\":0.1, 'zorder': 2, 'size': 5, 'side': 'center'});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#effect-size-paired-lines",
    "href": "tutorials/08-plot_aesthetics.html#effect-size-paired-lines",
    "title": "Controlling Plot Aesthetics",
    "section": "Effect size paired lines",
    "text": "Effect size paired lines\nBy default, effect size paired lines are included in paired experiment plots (excluding proportion plots).\nThis feature can be turned off by setting contrast_paired_lines=False in the .plot() method.\n\nrepeated_measures.mean_diff.plot(contrast_paired_lines=True);\n\n\n\n\n\n\n\n\nEffect size line kwargs can be utilised via contrast_paired_lines_kwargs in the .plot() method.\nBy default, the following keywords are passed:\n\n'linestyle' - Linestyle\n'linewidth' - Linewidth\n'zorder' - Zorder (the layering relative to other plot elements)\n'color' - Color. Default is ‚Äòdimgray‚Äô\n'alpha' - Alpha (transparency)\n\n\nrepeated_measures.mean_diff.plot(contrast_paired_lines=True, \n                                 contrast_paired_lines_kwargs={\"color\": \"red\", \"alpha\": 0.5, \"linestyle\": \"-\"});",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/08-plot_aesthetics.html#baseline-error-curve",
    "href": "tutorials/08-plot_aesthetics.html#baseline-error-curve",
    "title": "Controlling Plot Aesthetics",
    "section": "Baseline error curve",
    "text": "Baseline error curve\nIn DABEST v2025.03.27, we introduce a new aspect to the contrast axes: the baseline dot and error curve. While the baseline dot is always present, the error curve can be turned on by setting show_baseline_ec=True in the .plot() method.\n\nrepeated_measures.mean_diff.plot(show_baseline_ec=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Controlling Plot Aesthetics"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html",
    "href": "tutorials/07-horizontal_plot.html",
    "title": "Horizontal Plots",
    "section": "",
    "text": "In DABEST v2025.03.27, we introduce a new plotting orientation: horizontal plots.\nTo access this, provide horizontal=True to the .plot() method.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#load-libraries",
    "href": "tutorials/07-horizontal_plot.html#load-libraries",
    "title": "Horizontal Plots",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 42.06it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#creating-a-demo-dataset",
    "href": "tutorials/07-horizontal_plot.html#creating-a-demo-dataset",
    "title": "Horizontal Plots",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                 'Control 2' : c2,     'Test 2' : t2,\n                 'Control 3' : c3,     'Test 3' : t3,\n                 'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                 'Gender'    : gender, 'ID'  : id_col\n                })",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-two-group-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-two-group-plots",
    "title": "Horizontal Plots",
    "section": "Generating two-group plots",
    "text": "Generating two-group plots\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\ntwo_groups_unpaired.mean_diff.plot(horizontal=True);\n\ntwo_groups_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), paired='baseline', id_col='ID')\ntwo_groups_paired.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-shared-control-and-repeated-measures-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-shared-control-and-repeated-measures-plots",
    "title": "Horizontal Plots",
    "section": "Generating shared-control and repeated-measures plots",
    "text": "Generating shared-control and repeated-measures plots\n\nshared_control = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\", \"Test 5\"))\nshared_control.mean_diff.plot(horizontal=True);\n\nrepeated_measures_baseline = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\", \"Test 5\"), paired='baseline', id_col='ID')    \nrepeated_measures_baseline.mean_diff.plot(horizontal=True);\n\nrepeated_measures_sequential = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\", \"Test 5\"), paired='sequential', id_col='ID')    \nrepeated_measures_sequential.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-multi-group-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-multi-group-plots",
    "title": "Horizontal Plots",
    "section": "Generating multi-group plots",
    "text": "Generating multi-group plots\n\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\", \"Test 4\", \"Test 5\")))\nmulti_2group.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-proportion-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-proportion-plots",
    "title": "Horizontal Plots",
    "section": "Generating proportion plots",
    "text": "Generating proportion plots\n\ndef create_demo_prop_dataset(seed=9999, N=40):\n    import numpy as np\n    import pandas as pd\n\n    np.random.seed(9999)  # Fix the seed to ensure reproducibility of results.\n    # Create samples\n    n = 1\n    c1 = np.random.binomial(n, 0.2, size=N)\n    c2 = np.random.binomial(n, 0.2, size=N)\n    c3 = np.random.binomial(n, 0.8, size=N)\n\n    t1 = np.random.binomial(n, 0.6, size=N)\n    t2 = np.random.binomial(n, 0.2, size=N)\n    t3 = np.random.binomial(n, 0.3, size=N)\n    t4 = np.random.binomial(n, 0.4, size=N)\n    t5 = np.random.binomial(n, 0.5, size=N)\n    t6 = np.random.binomial(n, 0.6, size=N)\n    t7 = np.ones(N)\n    t8 = np.zeros(N)\n    t9 = np.zeros(N)\n\n    # Add a `gender` column for coloring the data.\n    females = np.repeat('Female', N / 2).tolist()\n    males = np.repeat('Male', N / 2).tolist()\n    gender = females + males\n\n    # Add an `id` column for paired data plotting.\n    id_col = pd.Series(range(1, N + 1))\n\n    # Combine samples and gender into a DataFrame.\n    df = pd.DataFrame({'Control 1': c1, 'Test 1': t1,\n                       'Control 2': c2, 'Test 2': t2,\n                       'Control 3': c3, 'Test 3': t3,\n                       'Test 4': t4, 'Test 5': t5, 'Test 6': t6,\n                       'Test 7': t7, 'Test 8': t8, 'Test 9': t9,\n                       'Gender': gender, 'ID': id_col\n                       })\n\n    return df\ndf_prop = create_demo_prop_dataset()\n\n\nmulti_two_groups_unpaired = dabest.load(df_prop, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Test 3\", \"Test 4\"), (\"Test 5\", \"Test 6\")), proportional=True)\nmulti_two_groups_unpaired.mean_diff.plot(horizontal=True);\n\nmulti_group_baseline = dabest.load(df_prop, idx=(((\"Control 1\", \"Test 1\",\"Test 2\", \"Test 3\"),(\"Test 4\", \"Test 5\", \"Test 6\"))),proportional=True, paired=\"baseline\", id_col=\"ID\")\nmulti_group_baseline.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-delta-delta-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-delta-delta-plots",
    "title": "Horizontal Plots",
    "section": "Generating delta-delta plots",
    "text": "Generating delta-delta plots\n\nfrom scipy.stats import norm # Used in generation of populations.\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\n# Create samples\nN = 20\ny = norm.rvs(loc=3, scale=0.4, size=N*4)\ny[N:2*N] = y[N:2*N]+1\ny[2*N:3*N] = y[2*N:3*N]-0.5\n\n# Add a `Treatment` column\nt1 = np.repeat('Placebo', N*2).tolist()\nt2 = np.repeat('Drug', N*2).tolist()\ntreatment = t1 + t2 \n\n# Add a `Rep` column as the first variable for the 2 replicates of experiments done\nrep = []\nfor i in range(N*2):\n    rep.append('Rep1')\n    rep.append('Rep2')\n\n# Add a `Genotype` column as the second variable\nwt = np.repeat('W', N).tolist()\nmt = np.repeat('M', N).tolist()\nwt2 = np.repeat('W', N).tolist()\nmt2 = np.repeat('M', N).tolist()\n\n\ngenotype = wt + mt + wt2 + mt2\n\n# Add an `id` column for paired data plotting.\nid = list(range(0, N*2))\nid_col = id + id \n\n\n# Combine all columns into a DataFrame.\ndf_delta2 = pd.DataFrame({'ID'        : id_col,\n                  'Rep'      : rep,\n                   'Genotype'  : genotype, \n                   'Treatment': treatment,\n                   'Y'         : y\n                })\n\n\nunpaired_delta2 = dabest.load(data = df_delta2, x = [\"Genotype\", \"Genotype\"], y = \"Y\", delta2 = True, experiment = \"Treatment\")\nunpaired_delta2.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#generating-mini-meta-plots",
    "href": "tutorials/07-horizontal_plot.html#generating-mini-meta-plots",
    "title": "Horizontal Plots",
    "section": "Generating mini-meta plots",
    "text": "Generating mini-meta plots\n\nunpaired = dabest.load(df, idx=((\"Control 1\", \"Test 2\"), (\"Control 2\", \"Test 3\"), (\"Test 4\", \"Test 5\")), mini_meta=True)\nunpaired.mean_diff.plot(horizontal=True);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/07-horizontal_plot.html#controlling-aesthetics",
    "href": "tutorials/07-horizontal_plot.html#controlling-aesthetics",
    "title": "Horizontal Plots",
    "section": "Controlling aesthetics",
    "text": "Controlling aesthetics\nAs with the vertical plots, horizontal plots can be customized using the same options. Shown below are a few cases where the aesthetics are modified, added functionality, or just less intuitive.\n\nSwarm side\nAs with the vertical plots, you can specify the side of the swarms via swarm_side in the .plot() method.\nIn this case, swarm_side='left' would plot the swarms upwards, and swarm_side='right' would plot the swarms downwards.\nDefault is swarm_side='left'\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\", 'Test 2'), resamples=5000)\ntwo_groups_unpaired.mean_diff.plot(swarm_side='left', horizontal=True);\n\n\n\n\n\n\n\n\nswarm_side='center'\n\ntwo_groups_unpaired.mean_diff.plot(swarm_side='center', horizontal=True);\n\n\n\n\n\n\n\n\nswarm_side='right'\n\ntwo_groups_unpaired.mean_diff.plot(swarm_side='right', horizontal=True);\n\n\n\n\n\n\n\n\n\n\nTable kwargs\nThe table axis can be customized using the horizontal_table_kwargs argument. A dict of keywords can be passed to customize the table.\nIf None, the following keywords are passed:\n\n'show' - Whether to show the table. Default is True.\n'color' - The color of the table. Default is ‚Äòyellow‚Äô.\n'alpha' - The transparency of the table. Default is 0.2.\n'fontsize' - The fontsize of the table. Default is 12.\n'text_color' - The color of the text in the table. Default is ‚Äòblack‚Äô.\n'text_units' - The units of the text in the table. Default is None.\n'control_marker' - The marker for the control group. Default is ‚Äò-‚Äô.\n'fontsize_label' - The fontsize of the table x-label. Default is 12.\n'label' - The table x-label.\n\n\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\"),(\"Test 4\", \"Test 5\")))\nmulti_2group.mean_diff.plot(horizontal=True, \n                            horizontal_table_kwargs={'color': 'red', \n                                                     'alpha': 0.5, \n                                                     'text_color': \n                                                     'white',\n                                                     'text_units':'mm', \n                                                     'label': 'delta mm',\n                                                     'control_marker': 'o',\n                                                    });\n\n\n\n\n\n\n\n\nThe table axis can be hidden using the 'show':False in the horizontal_table_kwargs dict.\n\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\"),(\"Test 4\", \"Test 5\")))\nmulti_2group.mean_diff.plot(horizontal=True, horizontal_table_kwargs={'show': False});\n\n\n\n\n\n\n\n\n\n\nGridkey\nAs with the vertical plots, you can utilise a gridkey table for representing the groupings. This can be reached via gridkey in the .plot() method.\nYou can either use gridkey='auto' to automatically generate the gridkey, or pass a list of indexes to represent the groupings (e.g., gridkey=['Control', 'Test']).\nSee the examples in the Plot Aesthetics Tutorial for more information with regards to kwargs.\n\nmulti_2group = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\"),(\"Test 4\", \"Test 5\")))\nmulti_2group.mean_diff.plot(horizontal=True, gridkey=['Control', 'Test']);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Horizontal Plots"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html",
    "href": "tutorials/06-delta_delta.html",
    "title": "Delta-Delta",
    "section": "",
    "text": "Since v2023.02.14, DABEST also supports the calculation of delta-delta, an experimental function that facilitates the comparison between two bootstrapped effect sizes computed from two independent categorical variables.\nSince v2025.03.27, DABEST also supports the calculation of delta-delta for binary data (proportion plots).\nMany experimental designs investigate the effects of two interacting independent variables on a dependent variable. The delta-delta effect size enables us distill the net effect of the two variables. To illustrate this, let‚Äôs explore the following problem.\nConsider an experiment where we test the efficacy of a drug named Drug on a disease-causing mutation M based on disease metric Y. The greater the value Y has, the more severe the disease phenotype is. Phenotype Y has been shown to be caused by a gain-of-function mutation M, so we expect a difference between wild type (W) subjects and mutant subjects (M). Now, we want to know whether this effect is ameliorated by the administration of Drug treatment. We also administer a placebo as a control. In theory, we only expect Drug to have an effect on the M group, although in practice, many drugs have non-specific effects on healthy populations too.\nEffectively, we have four groups of subjects for comparison.\nThere are two Treatment conditions, Placebo (control group) and Drug (test group). There are two Genotype: W (wild type population) and M (mutant population). Additionally, each experiment was conducted twice (Rep1 and Rep2). We will perform several analyses to visualise these differences in a simulated dataset.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#load-libraries",
    "href": "tutorials/06-delta_delta.html#load-libraries",
    "title": "Delta-Delta",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#creating-a-demo-dataset",
    "href": "tutorials/06-delta_delta.html#creating-a-demo-dataset",
    "title": "Delta-Delta",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\nfrom scipy.stats import norm # Used in generation of populations.\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\n# Create samples\nN = 20\ny = norm.rvs(loc=3, scale=0.4, size=N*4)\ny[N:2*N] = y[N:2*N]+1\ny[2*N:3*N] = y[2*N:3*N]-0.5\n\n# Add a `Treatment` column\nt1 = np.repeat('Placebo', N*2).tolist()\nt2 = np.repeat('Drug', N*2).tolist()\ntreatment = t1 + t2 \n\n# Add a `Rep` column as the first variable for the 2 replicates of experiments done\nrep = []\nfor i in range(N*2):\n    rep.append('Rep1')\n    rep.append('Rep2')\n\n# Add a `Genotype` column as the second variable\nwt = np.repeat('W', N).tolist()\nmt = np.repeat('M', N).tolist()\nwt2 = np.repeat('W', N).tolist()\nmt2 = np.repeat('M', N).tolist()\n\n\ngenotype = wt + mt + wt2 + mt2\n\n# Add an `id` column for paired data plotting.\nid = list(range(0, N*2))\nid_col = id + id \n\n\n# Combine all columns into a DataFrame.\ndf_delta2 = pd.DataFrame({'ID'        : id_col,\n                  'Rep'      : rep,\n                   'Genotype'  : genotype, \n                   'Treatment': treatment,\n                   'Y'         : y\n                })\ndf_delta2.head(5)\n\n\n\n\n\n\n\n\nID\nRep\nGenotype\nTreatment\nY\n\n\n\n\n0\n0\nRep1\nW\nPlacebo\n2.793984\n\n\n1\n1\nRep2\nW\nPlacebo\n3.236759\n\n\n2\n2\nRep1\nW\nPlacebo\n3.019149\n\n\n3\n3\nRep2\nW\nPlacebo\n2.804638\n\n\n4\n4\nRep1\nW\nPlacebo\n2.858019",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#loading-data",
    "href": "tutorials/06-delta_delta.html#loading-data",
    "title": "Delta-Delta",
    "section": "Loading data",
    "text": "Loading data\nTo create a delta-delta plot, you simply need to set delta2=True in the dabest.load() method. However, in this case,x needs to be declared as a list consisting of 2 elements, unlike most cases where it is a single element. The first element in x will represent the variable plotted along the horizontal axis, and the second one will determine the color of dots for scattered plots or the color of lines for slope graphs. We use the experiment input to specify the grouping of the data.\n\nunpaired_delta2 = dabest.load(data = df_delta2, x = [\"Genotype\", \"Genotype\"], y = \"Y\", delta2 = True, experiment = \"Treatment\")\nunpaired_delta2\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:50 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. M Placebo minus W Placebo\n2. M Drug minus W Drug\n3. Drug minus Placebo (only for mean difference)\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nunpaired_delta2.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:51 2025.\n\nThe unpaired mean difference between W Placebo and M Placebo is 1.23 [95%CI 0.937, 1.51].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between W Drug and M Drug is 0.326 [95%CI 0.0956, 0.574].\nThe p-value of the two-sided permutation t-test is 0.0122, calculated for legacy purposes only. \n\nThe delta-delta between Placebo and Drug is -0.903 [95%CI -1.27, -0.522].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing the effect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#generating-delta-delta-plots",
    "href": "tutorials/06-delta_delta.html#generating-delta-delta-plots",
    "title": "Delta-Delta",
    "section": "Generating delta-delta plots",
    "text": "Generating delta-delta plots\n\nunpaired_delta2.mean_diff.plot();\n\n\n\n\n\n\n\n\nIn the above plot, the horizontal axis represents the Genotype condition and the dot colour is also specified by Genotype. The left pair of scattered plots is based on the Placebo group while the right pair is based on the Drug group. The bottom left axis contains the two primary deltas: the Placebo delta and the Drug delta. We can easily see that when only the placebo was administered, the mutant phenotype is around 1.23 [95%CI 0.948, 1.52]. This difference was shrunken to around 0.326 [95%CI 0.0934, 0.584] when the drug was administered. This gives us some indication that the drug is effective in amiliorating the disease phenotype. Since the Drug did not completely eliminate the mutant phenotype, we have to calculate how much net effect the drug had. This is where delta-delta comes in. We use the Placebo delta as a reference for how much the mutant phenotype is supposed to be, and we subtract the Drug delta from it. The bootstrapped mean differences (delta-delta) between the Placebo and Drug group are plotted at the right bottom with a separate y-axis from other bootstrap plots. This effect size, at about -0.903 [95%CI -1.28, -0.513], is the net effect size of the drug treatment. That is to say that treatment with drug A reduced disease phenotype by 0.903.\nThe mean difference between mutants and wild types given the placebo treatment is:\n\\(\\Delta_{1} = \\overline{X}_{P, M} - \\overline{X}_{P, W}\\)\nThe mean difference between mutants and wild types given the drug treatment is:\n\\(\\Delta_{2} = \\overline{X}_{D, M} - \\overline{X}_{D, W}\\)\nThe net effect of the drug on mutants is:\n\\(\\Delta_{\\Delta} = \\Delta_{2} - \\Delta_{1}\\)\nwhere \\(\\overline{X}\\) is the sample mean, \\(\\Delta\\) is the mean difference.\nThe configuration of comparison we performed above is reminiscent of a two-way ANOVA. In fact, the delta - delta is an effect size estimated for the interaction term between Treatment and Genotype. Main effects of Treatment and Genotype, on the other hand, can be determined by simpler, univariate contrast plots.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#specifying-grouping-for-comparisons",
    "href": "tutorials/06-delta_delta.html#specifying-grouping-for-comparisons",
    "title": "Delta-Delta",
    "section": "Specifying grouping for comparisons",
    "text": "Specifying grouping for comparisons\nIn the example above, we used the convention of test - control but you can manipulate the orders of the experiment groups as well as the horizontal axis variable by setting the paremeters experiment_label and x1_level.\n\nunpaired_delta2_specified = dabest.load(data = df_delta2, \n                                            x = [\"Genotype\", \"Genotype\"], y = \"Y\", \n                                            delta2 = True, experiment = \"Treatment\",\n                                            experiment_label = [\"Drug\", \"Placebo\"],\n                                            x1_level = [\"M\", \"W\"])\n\nunpaired_delta2_specified.mean_diff.plot();\n\n\n\n\n\n\n\n\nUtilising the show_delta2 argument within the .plot() method allows for control of whether the delta-delta effect size is displayed on the plot. By default, this is set to True.\n\nunpaired_delta2_specified.mean_diff.plot(show_delta2=False);\n\n\n\n\n\n\n\n\nThe delta-delta function also supports paired data, providing a useful alternative visualization of the data. Assuming that the placebo and drug treatment were administered to the same subjects, our data is paired between the treatment conditions. We can specify this by using Treatment as x and Genotype as experiment, and we further specify that id_col is ID, linking data from the same subject with each other. Since we have conducted two replicates of the experiments, we can also colour the slope lines according to Rep.\n\npaired_delta2 = dabest.load(data = df_delta2, \n                                paired = \"baseline\", id_col=\"ID\",\n                                x = [\"Treatment\", \"Rep\"], y = \"Y\", \n                                delta2 = True, experiment = \"Genotype\")\npaired_delta2.mean_diff.plot();\n\n\n\n\n\n\n\n\nWe see that the drug had a non-specific effect of -0.321 [95%CI -0.498, -0.131] on wild type subjects even when they were not sick, and it had a bigger effect of -1.22 [95%CI -1.52, -0.906] in mutant subjects. In this visualisation, we can see the delta-delta value of -0.903 [95%CI -1.21, -0.587] as the net effect of the drug accounting for non-specific actions in healthy individuals.\nThe mean difference between drug and placebo treatments in wild type subjects is:\n\\[\\Delta_{1} = \\overline{X}_{D, W} - \\overline{X}_{P, W}\\]\nThe mean difference between drug and placebo treatments in mutant subjects is:\n\\[\\Delta_{2} = \\overline{X}_{D, M} - \\overline{X}_{P, M}\\]\nThe net effect of the drug on mutants is:\n\\[\\Delta_{\\Delta} = \\Delta_{2} - \\Delta_{1}\\]\nwhere \\(\\overline{X}\\) is the sample mean, \\(\\Delta\\) is the mean difference.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#standardising-delta-delta-effect-sizes-with-delta-g",
    "href": "tutorials/06-delta_delta.html#standardising-delta-delta-effect-sizes-with-delta-g",
    "title": "Delta-Delta",
    "section": "Standardising delta-delta effect sizes with Delta g",
    "text": "Standardising delta-delta effect sizes with Delta g\nStandardized mean difference statistics like Cohen‚Äôs d and Hedges‚Äô g quantify effect sizes in terms of the sample variance. We have introduced a metric, Delta g, to standardize delta-delta effects. This metric enables the comparison between measurements of different dimensions.\nThe standard deviation of the delta-delta value is calculated from a pooled variance of the 4 samples:\n\\[s_{\\Delta_{\\Delta}} = \\sqrt{\\frac{(n_{D, W}-1)s_{D, W}^2+(n_{P, W}-1)s_{P, W}^2+(n_{D, M}-1)s_{D, M}^2+(n_{P, M}-1)s_{P, M}^2}{(n_{D, W} - 1) + (n_{P, W} - 1) + (n_{D, M} - 1) + (n_{P, M} - 1)}}\\]\nwhere \\(s\\) is the standard deviation and \\(n\\) is the sample size.\nA delta g value is then calculated as delta-delta value divided by pooled standard deviation \\(s_{\\Delta_{\\Delta}}\\):\n\\(\\Delta_{g} = \\frac{\\Delta_{\\Delta}}{s_{\\Delta_{\\Delta}}}\\)\nThis metric can be accessed via the ‚Äòhedges_g‚Äô effect size when utilising delta2=True in dabest.load().\n\nunpaired_delta2.hedges_g\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:53 2025.\n\nThe unpaired Hedges' g between W Placebo and M Placebo is 2.54 [95%CI 1.71, 3.31].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired Hedges' g between W Drug and M Drug is 0.793 [95%CI 0.17, 1.33].\nThe p-value of the two-sided permutation t-test is 0.0122, calculated for legacy purposes only. \n\nThe delta g between Placebo and Drug is -2.11 [95%CI -2.97, -1.22].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing the effect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.hedges_g.statistical_tests`\n\n\nWe see the standardised delta-delta (delta g) value of -2.11 standard deviations [95%CI -2.98, -1.2] as the net effect of the drug accounting for non-specific actions in healthy individuals.\n\nunpaired_delta2.hedges_g.plot();",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#delta-delta-for-binary-data",
    "href": "tutorials/06-delta_delta.html#delta-delta-for-binary-data",
    "title": "Delta-Delta",
    "section": "Delta-delta for binary data",
    "text": "Delta-delta for binary data\nSince v2025.03.27, the delta-delta function also supports binary data (proportion plots). In this case, the delta-delta value is calculated as the difference between the two proportions. This can be used for both unpaired and paired binary data.\n\ndef create_demo_dataset_delta(seed=9999, N=20):\n    \n    import numpy as np\n    import pandas as pd\n    from scipy.stats import norm # Used in generation of populations.\n\n    np.random.seed(seed) # Fix the seed so the results are replicable.\n    # pop_size = 10000 # Size of each population.\n\n    from scipy.stats import norm # Used in generation of populations.\n\n    # Create samples\n    y = norm.rvs(loc=3, scale=0.4, size=N*4)\n    y[N:2*N] = y[N:2*N]+1\n    y[2*N:3*N] = y[2*N:3*N]-0.5\n    ind = np.random.binomial(1, 0.5, size=N*4)\n    ind[N:2*N] = np.random.binomial(1, 0.2, size=N)\n    ind[2*N:3*N] = np.random.binomial(1, 0.1, size=N)\n\n    # Add drug column\n    t1 = np.repeat('Placebo', N*2).tolist()\n    t2 = np.repeat('Drug', N*2).tolist()\n    treatment = t1 + t2 \n\n    # Add a `rep` column as the first variable for the 2 replicates of experiments done\n    rep = []\n    for i in range(N*2):\n        rep.append('Rep1')\n        rep.append('Rep2')\n\n    # Add a `genotype` column as the second variable\n    wt = np.repeat('WT', N).tolist()\n    mt = np.repeat('Mut', N).tolist()\n    wt2 = np.repeat('WT', N).tolist()\n    mt2 = np.repeat('Mut', N).tolist()\n\n\n    genotype = wt + mt + wt2 + mt2\n\n    # Add an `id` column for paired data plotting.\n    id = list(range(0, N*2))\n    id_col = id + id \n\n\n    # Combine all columns into a DataFrame.\n    df_prop = pd.DataFrame({'ID'        : id_col,\n                      'Rep'        : rep,\n                       'Genotype'  : genotype, \n                       'Treatment' : treatment,\n                       'Y'         : y,\n                       'Cat'       :ind\n                    })\n    return df_prop\n\ndf_prop = create_demo_dataset_delta()\n\nunpaired_prop = dabest.load(data = df_prop, proportional=True,\n                            # id_col=\"index\", paired='baseline', \n                            x = [\"Treatment\", \"Treatment\"], \n                            y = \"Cat\", delta2=True,\n                            experiment=\"Genotype\",)\n\nunpaired_prop.mean_diff.plot();",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/06-delta_delta.html#statistics",
    "href": "tutorials/06-delta_delta.html#statistics",
    "title": "Delta-Delta",
    "section": "Statistics",
    "text": "Statistics\nYou can find all outputs of the delta-delta calculation by assessing the attribute named delta_delta of the effect size object.\n\nunpaired_delta2.mean_diff.delta_delta\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:54 2025.\n\nThe delta-delta between Placebo and Drug is -0.903 [95%CI -1.27, -0.522].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing the effect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\n\nThe delta_delta object has its own attributes, containing various information of delta-delta.\n\ndifference: the mean bootstrapped differences between the 2 groups of bootstrapped mean differences\nbootstraps: the 2 groups of bootstrapped mean differences\nbootstraps_delta_delta: the bootstrapped differences between the 2 groups of bootstrapped mean differences\npermutations: the mean difference between the two groups of bootstrapped mean differences calculated based on the permutation data\npermutations_var: the pooled group variances of two groups of bootstrapped mean differences calculated based on permutation data\npermutations_delta_delta: the delta-delta calculated based on the permutation data\n\nA dataframe of this delta delta dabest object can also be called via the delta_delta.results attribute.\n\nunpaired_delta2.mean_diff.delta_delta.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps_control\nbootstraps_test\nbootstraps_delta_delta\npermutations_control\npermutations_test\npermutations_delta_delta\npvalue_permutation\npermutation_count\nbias_correction\njackknives\n\n\n\n\n0\nPlacebo\nDrug\n-0.903179\n95\n-1.271483\n-0.521935\n(124, 4874)\n-1.270426\n-0.519652\n(125, 4875)\n[1.0890043559982234, 1.1472720447282119, 1.072...\n[0.6003430615628478, 0.6547912656551773, 0.294...\n[-0.43421309034304567, -0.7324573148122022, -1...\n[-0.15899787281865496, 0.23958268043726694, 0....\n[-0.036113268018566735, -0.05491466432013192, ...\n[0.12288460480008823, -0.29449734475739886, -0...\n0.0\n5000\n-0.000501\n[-0.9006797310317582, -0.9006200702547091, -0....\n\n\n\n\n\n\n\nSimilarly, for the standardised delta-delta effect size, the hedges_g object has its own delta delta (Delta g) results attribute.\n\nunpaired_delta2.hedges_g.delta_delta.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps_control\nbootstraps_test\nbootstraps_delta_delta\npermutations_control\npermutations_test\npermutations_delta_delta\npvalue_permutation\npermutation_count\nbias_correction\njackknives\n\n\n\n\n0\nPlacebo\nDrug\n-2.106681\n95\n-2.965759\n-1.217424\n(124, 4874)\n-2.963294\n-1.212099\n(125, 4875)\n[2.3610871907095192, 2.7764672664031567, 2.350...\n[1.549355181508767, 1.7247260954921417, 0.6471...\n[-1.0128104949604284, -1.708470960574333, -2.7...\n[-0.1986457235842243, 0.3014021841951519, 0.31...\n[-0.08117530110708499, -0.12358349103957916, -...\n[0.11747042247713932, -0.4249856752347311, -0....\n0.0\n5000\n-0.000501\n[-2.1008530246437576, -2.10071386471865, -2.10...\n\n\n\n\n\n\n\nFor further aesthetic changes, the Plot Aesthetics Tutorial provides detailed examples of how to customize the plot.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Delta-Delta"
    ]
  },
  {
    "objectID": "tutorials/03-shared_control_and_repeated_measures.html",
    "href": "tutorials/03-shared_control_and_repeated_measures.html",
    "title": "Shared Control & Repeated Measures",
    "section": "",
    "text": "The shared control plot and repeated measures plot display common experimental paradigms, where several test samples are compared against a common reference sample. The shared control plot is for unpaired data, while the repeated measures plot is for paired data.\nThese types of Cumming plots are automatically generated if the tuple passed to idx has more than two data columns.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Shared Control & Repeated Measures"
    ]
  },
  {
    "objectID": "tutorials/03-shared_control_and_repeated_measures.html#load-libraries",
    "href": "tutorials/03-shared_control_and_repeated_measures.html#load-libraries",
    "title": "Shared Control & Repeated Measures",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 62.10it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Shared Control & Repeated Measures"
    ]
  },
  {
    "objectID": "tutorials/03-shared_control_and_repeated_measures.html#creating-a-demo-dataset",
    "href": "tutorials/03-shared_control_and_repeated_measures.html#creating-a-demo-dataset",
    "title": "Shared Control & Repeated Measures",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed so the results are reproducible.\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                   'Control 2' : c2,     'Test 2' : t2,\n                   'Control 3' : c3,     'Test 3' : t3,\n                   'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                   'Gender'    : gender, 'ID'  : id_col\n                  })",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Shared Control & Repeated Measures"
    ]
  },
  {
    "objectID": "tutorials/03-shared_control_and_repeated_measures.html#shared-control-plot",
    "href": "tutorials/03-shared_control_and_repeated_measures.html#shared-control-plot",
    "title": "Shared Control & Repeated Measures",
    "section": "Shared control plot",
    "text": "Shared control plot\n\nshared_control = dabest.load(df, idx=(\"Control 1\", \"Test 1\",\n                                          \"Test 2\", \"Test 3\",\n                                          \"Test 4\", \"Test 5\", \"Test 6\")\n                                 )\nshared_control\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:11 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 1\n3. Test 3 minus Control 1\n4. Test 4 minus Control 1\n5. Test 5 minus Control 1\n6. Test 6 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nshared_control.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:12 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.48 [95%CI 0.205, 0.774].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 2 is -0.542 [95%CI -0.915, -0.206].\nThe p-value of the two-sided permutation t-test is 0.0042, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 3 is 0.174 [95%CI -0.273, 0.647].\nThe p-value of the two-sided permutation t-test is 0.479, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 4 is 0.79 [95%CI 0.325, 1.33].\nThe p-value of the two-sided permutation t-test is 0.0042, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 5 is 0.265 [95%CI 0.0115, 0.497].\nThe p-value of the two-sided permutation t-test is 0.0404, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 6 is 0.288 [95%CI 0.00913, 0.524].\nThe p-value of the two-sided permutation t-test is 0.0324, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nshared_control.mean_diff.plot();\n\n\n\n\n\n\n\n\ndabest allows for combining both two-group and shared control experiments into the same plot. This empowers you to perform robust analyses and present complex visualizations of your statistics elegantly.\n\nmulti_groups = dabest.load(df, idx=((\"Control 1\", \"Test 1\",),\n                                         (\"Control 2\", \"Test 2\",\"Test 3\"),\n                                         (\"Control 3\", \"Test 4\",\"Test 5\", \"Test 6\")\n                                       ))\nmulti_groups\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:12 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 2\n4. Test 4 minus Control 3\n5. Test 5 minus Control 3\n6. Test 6 minus Control 3\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nmulti_groups.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:13 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.48 [95%CI 0.205, 0.774].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 2 is -1.38 [95%CI -1.93, -0.905].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 3 is -0.666 [95%CI -1.29, -0.0788].\nThe p-value of the two-sided permutation t-test is 0.0352, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 3 and Test 4 is 0.362 [95%CI -0.111, 0.901].\nThe p-value of the two-sided permutation t-test is 0.161, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 3 and Test 5 is -0.164 [95%CI -0.398, 0.0747].\nThe p-value of the two-sided permutation t-test is 0.208, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 3 and Test 6 is -0.14 [95%CI -0.4, 0.0937].\nThe p-value of the two-sided permutation t-test is 0.282, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nmulti_groups.mean_diff.plot();",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Shared Control & Repeated Measures"
    ]
  },
  {
    "objectID": "tutorials/03-shared_control_and_repeated_measures.html#repeated-measures-plot",
    "href": "tutorials/03-shared_control_and_repeated_measures.html#repeated-measures-plot",
    "title": "Shared Control & Repeated Measures",
    "section": "Repeated measures plot",
    "text": "Repeated measures plot\nDABEST v2023.02.14 expands the repertoire of plots for experiments with repeated-measures designs. DABEST now allows the visualization of paired experiments with one control and multiple test groups, as well as repeated measurements of the same group. This is an improved version of paired data plotting in previous versions, which only supported computations involving one test group and one control group.\nThe repeated-measures function supports the calculation of effect sizes for paired data, either based on sequential comparisons (group i vs group i + 1) or baseline comparisons (control vs group i). To use these features, you can simply declare the argument paired = \"sequential\" or paired = \"baseline\" correspondingly while running dabest.load(). As in the previous version, you must also pass a column in the dataset that indicates the identity of each observation, using the id_col keyword.\n\n(Please note that paired = True and paired = False are no longer valid since v2023.02.14)\n\n\nbaseline_repeated_measures = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\"),\n                                               paired=\"baseline\", id_col=\"ID\")\nbaseline_repeated_measures\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:13 2025.\n\nPaired effect size(s) for repeated measures against baseline \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 1\n3. Test 3 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nbaseline_repeated_measures.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:14 2025.\n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 1 is 0.48 [95%CI 0.241, 0.749].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 2 is -0.542 [95%CI -0.977, -0.179].\nThe p-value of the two-sided permutation t-test is 0.014, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 3 is 0.174 [95%CI -0.303, 0.702].\nThe p-value of the two-sided permutation t-test is 0.505, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nbaseline_repeated_measures.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nsequential_repeated_measures = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\"),\n                                               paired=\"sequential\", id_col=\"ID\")\nsequential_repeated_measures\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:14 2025.\n\nPaired effect size(s) for the sequential design of repeated-measures experiment \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Test 1\n3. Test 3 minus Test 2\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nsequential_repeated_measures.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:15 2025.\n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Control 1 and Test 1 is 0.48 [95%CI 0.241, 0.749].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Test 1 and Test 2 is -1.02 [95%CI -1.35, -0.709].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Test 2 and Test 3 is 0.716 [95%CI 0.153, 1.2].\nThe p-value of the two-sided permutation t-test is 0.022, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nsequential_repeated_measures.mean_diff.plot();\n\n\n\n\n\n\n\n\nSimilar to unpaired data, DABEST empowers you to perform complex visualizations and statistics for paired data.\n\nmulti_baseline_repeated_measures = dabest.load(df, idx=((\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\"),\n                                                      (\"Control 2\", \"Test 4\", \"Test 5\", \"Test 6\")),\n                                               paired=\"baseline\", id_col=\"ID\")\nmulti_baseline_repeated_measures.mean_diff.plot();\n\n\n\n\n\n\n\n\nFor further aesthetic changes, the Plot Aesthetics Tutorial provides detailed examples of how to customize the plot.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Shared Control & Repeated Measures"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html",
    "href": "tutorials/09-forest_plot.html",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "",
    "text": "In DABEST v2025.03.27, we introduce a new function to plot separately calculated effect sizes in the same axes to allow direct visual comparisons.\nCurrently you can make a forest plot for delta-delta, mini-meta, or standard delta effect sizes. In addition, for delta-delta and mini-meta experiments, you can also plot the effect sizes of the original comparisons alongside the delta-delta/mini-meta measurement.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html#load-libraries",
    "href": "tutorials/09-forest_plot.html#load-libraries",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\nimport matplotlib.pyplot as plt\nimport dabest \nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 23.74it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html#delta-delta-effects",
    "href": "tutorials/09-forest_plot.html#delta-delta-effects",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "Delta-delta effects",
    "text": "Delta-delta effects\nFirst please revisit the notebook Delta-Delta Tutorial for how to generate a delta-delta effect size. We will generate three of them plot them into the same axes. Here we test the efficacy of 3 drugs named Drug1, Drug2 , and Drug3 on a disease-causing mutation M based on disease metric Tumor Size. We want to know how the three drugs fare in ameliorating the phenotype metric Tumor Size.\n\n\n\n\nWildtype\nMutant\n\n\n\n\nDrug1\nXD1, W\nXD1, M\n\n\nPlacebo\nXP1, W\nXP1, M\n\n\n\n\n\n\n\nWildtype\nMutant\n\n\n\n\nDrug2\nXD2, W\nXD2, M\n\n\nPlacebo\nXP2, W\nXP2, M\n\n\n\n\n\n\n\nWildtype\nMutant\n\n\n\n\nDrug3\nXD3, W\nXD3, M\n\n\nPlacebo\nXP3, W\nXP3, M\n\n\n\nIn each scenario, there are two Treatment conditions, Placebo (control group) and Drug (test group). There are two Genotype's: W (wild type population) and M (mutant population). Additionally, each experiment was conducted twice (Rep1 and Rep2). We will perform several analyses to visualise these differences in a simulated dataset. We will simulate three separte datasets below.\n\nCreating a demo dataset\n\nfrom scipy.stats import norm\ndef create_delta_dataset(N=20, \n                        seed=9999, \n                        second_quarter_adjustment=3, \n                        third_quarter_adjustment=-0.1):\n    np.random.seed(seed)  # Set the seed for reproducibility\n\n    # Create samples\n    y = norm.rvs(loc=3, scale=0.4, size=N*4)\n    y[N:2*N] += second_quarter_adjustment\n    y[2*N:3*N] += third_quarter_adjustment\n\n    # Treatment, Rep, Genotype, and ID columns\n    treatment = np.repeat(['Placebo', 'Drug'], N*2).tolist()\n    rep = ['Rep1', 'Rep2'] * (N*2)\n    genotype = np.repeat(['W', 'M', 'W', 'M'], N).tolist()\n    id_col = list(range(0, N*2)) * 2\n\n    # Combine all columns into a DataFrame\n    df = pd.DataFrame({\n        'ID': id_col,\n        'Rep': rep,\n        'Genotype': genotype,\n        'Treatment': treatment,\n        'Tumor Size': y\n    })\n\n    return df\n\n# Generate the first dataset with a different seed and adjustments\ndf_delta2_drug1 = create_delta_dataset(seed=9999, second_quarter_adjustment=1, third_quarter_adjustment=-0.5)\n\n# Generate the second dataset with a different seed and adjustments\ndf_delta2_drug2 = create_delta_dataset(seed=9999, second_quarter_adjustment=0.1, third_quarter_adjustment=-1)\n\n# Generate the third dataset with the same seed as the first but different adjustments\ndf_delta2_drug3 = create_delta_dataset(seed=9999, second_quarter_adjustment=3, third_quarter_adjustment=-0.1)\n\n\n\nLoading data\n\nunpaired_delta_01 = dabest.load(data = df_delta2_drug1, \n                                x = [\"Genotype\", \"Genotype\"], \n                                y = \"Tumor Size\", delta2 = True, \n                                experiment = \"Treatment\")\nunpaired_delta_02 = dabest.load(data = df_delta2_drug2, \n                                x = [\"Genotype\", \"Genotype\"], \n                                y = \"Tumor Size\", delta2 = True, \n                                experiment = \"Treatment\")\nunpaired_delta_03 = dabest.load(data = df_delta2_drug3, \n                                x = [\"Genotype\", \"Genotype\"], \n                                y = \"Tumor Size\", \n                                delta2 = True, \n                                experiment = \"Treatment\")\ncontrasts = [unpaired_delta_01, unpaired_delta_02, unpaired_delta_03]\n\n\n\nGenerate delta-delta plots for each datasets\nTo create a delta-delta plot, you simply need to set delta2=True in the dabest.load() function and mean_diff.plot()\nIn this case,x needs to be declared as a list consisting of 2 elements, unlike most cases where it is a single element. The first element in x will represent the variable plotted along the horizontal axis, and the second one will determine the color of dots for scattered plots or the color of lines for slope graphs. We use the experiment input to specify the grouping of the data.\n\nf1 = unpaired_delta_01.mean_diff.plot(\n    contrast_label='Mean Diff',\n    fig_size = (7, 4),\n    raw_marker_size = 1,\n    contrast_marker_size = 5,\n);\nf1.suptitle('Delta-delta plot for Drug 1');\n\n\nf2 = unpaired_delta_02.mean_diff.plot(                  \n            contrast_label='Mean Diff',\n            fig_size = (7, 4),\n            raw_marker_size = 1,\n            contrast_marker_size = 5,\n);\nf2.suptitle('Delta-delta plot for Drug 2');\n\n\nf3 = unpaired_delta_03.mean_diff.plot(                  \n                    contrast_label='Mean Diff',\n                    fig_size = (7, 4),\n                    raw_marker_size = 1,\n                    contrast_marker_size = 5,\n);\nf3.suptitle('Delta-delta plot for Drug 3');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate a forest plot\nThis will allow for comparisons of different Drug effects.\nKey Parameters:\n\ndata: A list of dabest objects\nlabels: A list of labels for the dabest objects. E.g., ['Drug1', 'Drug2', 'Drug3']\neffect_size: For delta-delta experiments, you can select the effect size metric from \"mean_diff\", or \"hedges_g\" / \"delta_g\". The default is \"mean_diff\".\nci_type: A string specifying the confidence interval type to use. The options are either bca or pct. Default is bca.\n\nNote: ‚Äúhedges_g‚Äù and ‚Äúdelta_g‚Äù can be used interchangeably for delta-delta experiments - both plot hedges_g regular effect sizes and our Delta g delta-delta effect size.\n\nhorizontal: A boolean input (True/ False) to adjust the plot orientation. The default is vertical orientation (False)\nax: Optional argument to specify an existing matplotlib axes (otherwise a standalone figure will be created)\n\nSee the Controlling aesthetics section for more information on how to alter the aesthetics of the plots.\n\nf_forest_delta2 = dabest.forest_plot(\n                        data = contrasts, \n                        labels = ['Drug1', 'Drug2', 'Drug3']\n);\n\n\n\n\n\n\n\n\n\n\nGenerate a forest plot with delta effect sizes alongside the delta-delta effect sizes\nIf you want to plot the original effect sizes alongside the delta-delta effect sizes, you can do so by utilising the idx parameter. This parameter takes a tuple/list of indices of the original effect sizes you want to plot.\nFor example, if you want to plot only the first effect size and the delta-delta effect size for each of the three dabest object supplied, you can do so by setting idx=[[0, 2],[0, 2],[0, 2]].\n\nf_forest_delta2 = dabest.forest_plot(\n                        data = contrasts, \n                        labels = ['Drug1 Delta1', 'Drug1 Delta-Delta', 'Drug2 Delta1', 'Drug2 Delta-Delta', 'Drug3 Delta1', 'Drug3 Delta-Delta'],\n                        idx=[[0, 2], [0, 2], [0, 2]]\n);\n\n\n\n\n\n\n\n\n\n\nSelecting normalised effect sizes via hedges_g or delta_g\nRemember, hedges_g and delta_g are interchangeable for delta-delta experiments. However, when plotting the original effect sizes alongside the delta-delta effect sizes, you should note that hedges_g effect sizes will be plotted alongside the Delta g effect sizes.\n\nf_forest_delta2 = dabest.forest_plot(\n                            data = contrasts, \n                            labels = ['Drug1', 'Drug2', 'Drug3'],\n                            effect_size='hedges_g');\nf_forest_delta2 = dabest.forest_plot(\n                            data = contrasts, \n                            labels = ['Drug1', 'Drug2', 'Drug3'],\n                            effect_size='delta_g');\n\nf_forest_delta2 = dabest.forest_plot(\n                            data = contrasts, \n                            labels = ['Drug1 Delta1', 'Drug1 Delta-Delta', 'Drug2 Delta1', 'Drug2 Delta-Delta', 'Drug3 Delta1', 'Drug3 Delta-Delta'],\n                            effect_size='hedges_g',\n                            idx=[[0, 2], [0, 2], [0, 2]]);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html#mini-meta-effects",
    "href": "tutorials/09-forest_plot.html#mini-meta-effects",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "Mini-meta effects",
    "text": "Mini-meta effects\nNext we will generate a similar forest plot for mini-meta effect sizes. Please revisit the notebook Mini-Meta Tutorial on how to generate a mini-meta effect size. We will generate three mini-meta effect sizes for three separate mini-meta analyses:\nNote: the only effect size metric currently available for mini-meta is \"mean_diff\".\n\nCreating a demo dataset\n\ndef create_mini_meta_dataset(N=20, seed=9999, control_locs=[3, 3.5, 3.25], control_scales=[0.4, 0.75, 0.4], \n                             test_locs=[3.5, 2.5, 3], test_scales=[0.5, 0.6, 0.75]):\n    np.random.seed(seed)  # Set the seed for reproducibility\n\n    # Create samples for controls and tests\n    controls_tests = []\n    for loc, scale in zip(control_locs + test_locs, control_scales + test_scales):\n        controls_tests.append(norm.rvs(loc=loc, scale=scale, size=N))\n\n    # Add a `Gender` column for coloring the data\n    gender = ['Female'] * (N // 2) + ['Male'] * (N // 2)\n\n    # Add an `ID` column for paired data plotting\n    id_col = list(range(1, N + 1))\n\n    # Combine samples and gender into a DataFrame\n    df_columns = {f'Control {i+1}': controls_tests[i] for i in range(len(control_locs))}\n    df_columns.update({f'Test {i+1}': controls_tests[i + len(control_locs)] for i in range(len(test_locs))})\n    df_columns['Gender'] = gender\n    df_columns['ID'] = id_col\n\n    df = pd.DataFrame(df_columns)\n\n    return df\n\n# Customizable dataset creation with different arguments\ndf_mini_meta01 = create_mini_meta_dataset(seed=9999, \n                                          control_locs=[3, 3.5, 3.25], \n                                          control_scales=[0.4, 0.75, 0.4], \n                                          test_locs=[3.5, 2.5, 3], \n                                          test_scales=[0.5, 0.6, 0.75])\n\ndf_mini_meta02 = create_mini_meta_dataset(seed=9999, \n                                          control_locs=[4, 2, 3.25], \n                                          control_scales=[0.3, 0.75, 0.45], \n                                          test_locs=[2, 1.5, 2.75], \n                                          test_scales=[0.5, 0.6, 0.4])\n\ndf_mini_meta03 = create_mini_meta_dataset(seed=9999, \n                                          control_locs=[6, 5.5, 4.25], \n                                          control_scales=[0.4, 0.75, 0.45], \n                                          test_locs=[4.5, 3.5, 3], \n                                          test_scales=[0.5, 0.6, 0.9])\n\n\n\nLoading data\n\ncontrast_mini_meta01 = dabest.load(data = df_mini_meta01,\n                                   idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), \n                                   mini_meta=True)\ncontrast_mini_meta02 = dabest.load(data = df_mini_meta02,\n                                    idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), \n                                    mini_meta=True)\ncontrast_mini_meta03 = dabest.load(data = df_mini_meta03,\n                                   idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")),\n                                    mini_meta=True)\ncontrasts_mini_meta = [contrast_mini_meta01, contrast_mini_meta02, contrast_mini_meta03]\n\n\n\nGenerate a forest plot\n\nf_forest_minimeta = dabest.forest_plot(\n                            data = contrasts_mini_meta, \n                            labels=['mini_meta1', 'mini_meta2', 'mini_meta3']\n);\n\n\n\n\n\n\n\n\n\n\nGenerate a forest plot with delta effect sizes alongside the mini-meta effect sizes\nIf you want to plot the original effect sizes alongside the mini-meta effect sizes, you can do so by utilising the idx parameter. This parameter takes a tuple/list of indices of the original effect sizes you want to plot.\nFor example, if you want to plot only the first effect size and the mini-meta effect size for each of the three dabest object supplied, you can do so by setting idx=[[0, final_idx],[0, final_idx],[0, final_idx]] (where final_idx is the index of the last contrast object which will be the mini-meta effect size.)\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        idx = [[0, 3],[0, 3], [0, 3]],\n                        labels=['Contrast 1A', 'mini_meta1', 'Contrast 2A', 'mini_meta2', 'Contrast 3A', 'mini_meta3']\n);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html#delta-effects",
    "href": "tutorials/09-forest_plot.html#delta-effects",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "Delta effects",
    "text": "Delta effects\nNext we will generate a similar forest plot of regular delta effect sizes. In the example below, we will generate three regular mean_diff experiments. Here, we will only plot the effect size between the first group (Test 1 - Control 1) for each of the three dabest object supplied.\n\ndelta1 = dabest.load(data = df_mini_meta01,\n                                   idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")))\ndelta2 = dabest.load(data = df_mini_meta02,\n                                    idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")))\ndelta3 = dabest.load(data = df_mini_meta03,\n                                   idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")))\ncontrasts_deltas = [delta1, delta2, delta3]\n\n\ndabest.forest_plot(contrasts_deltas, idx=((0,),(0,), (0,)), \n            labels=['Drug1 \\nTest 1 - Control 1', 'Drug2 \\nTest 2 - Control 2', 'Drug3 \\nTest 3 - Control 3']);\n\n\n\n\n\n\n\n\nUnlike delta-delta and mini-meta experiments, here you can choose between more effect size metrics (where applicable): mean_diff, cohens_d, cohens_h, hedges_g, and cliffs_delta\n\ndabest.forest_plot(contrasts_deltas, idx=((0,),(0,), (0,)), effect_size = 'cohens_d',\n            labels=['Drug1 \\nTest 1 - Control 1', 'Drug2 \\nTest 2 - Control 2', 'Drug3 \\nTest 3 - Control 3']);",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/09-forest_plot.html#controlling-aesthetics",
    "href": "tutorials/09-forest_plot.html#controlling-aesthetics",
    "title": "Forest Plots: Visualizing Multiple Contrasts",
    "section": "Controlling aesthetics",
    "text": "Controlling aesthetics\nThe main aesthetic parameters for the forest_plot function are:\n\nfig_size: The size of the figure\nhorizontal: A boolean input (True/ False) to adjust the plot orientation. The default is vertical orientation (False)\ncustom_palette: A list or dictionary of colors, one for each contrast object. E.g., ['gray', 'blue', 'green'] or {'Drug1':'gray', 'Drug2':'blue', 'Drug3':'green'} or a set of colors from seaborn color palettes.\nmarker_size: The size of the markers for the effect sizes. The default is 10.\ncontrast_alpha: Transparency level for violin plots. The default is 0.8.\ncontrast_desat: Saturation level for violin plots. The default is 1.\nlabels_rotation: Rotation angle for contrast labels. The default is 45 (for horizontal=False).\nlabels_fontsize: Font size for contrast labels. The default is 10.\ntitle: The plot title. The default is None.\ntitle_fontsize: Font size for the plot title. The default is 16.\nylabel: The axis label of dependent variable (Y-axis for vertical layout, X-axis for horizontal layout). The default will be given via the effect size selected. (eg., \"Mean Difference\" for \"mean_diff\")\nylabel_fontsize: Font size for the axis label (Y-axis for vertical layout, X-axis for horizontal layout). The default is 12.\nylim: Limits for the dependent variable (Y-axis for vertical layout, X-axis for horizontal layout). The default is None.\nyticks: Custom ticks (Y-axis for vertical layout, X-axis for horizontal layout) for the plot. The default is None.\nyticklabels: Custom tick labels (Y-axis for vertical layout, X-axis for horizontal layout) for the plot. The default is None.\nremove_spines: If True, removes plot spines (except the relevant dependent variable spine). The default is True.\nviolin_kwargs: A dictionary of keyword arguments for the violin plots.\n  The default violin_kwargs = {\"widths\": 0.5, \"showextrema\": False, \"showmedians\": False, \"vert\": not horizontal}\nzeroline_kwargs: A dictionary of keyword arguments for the zero line. The default is None.\n  The default zeroline_kwargs = {\"linewidth\": 1, \"color\": \"black\"}\nmarker_kwargs: A dictionary of keyword arguments for the effect size markers. The default is None.\n  The default marker_kwargs = {'marker': 'o', 'markersize': 12, 'color': 'black', 'alpha': 1, 'zorder': 2}\nerrorbar_kwargs: A dictionary of keyword arguments for the effect size error bars. The default is None.\n  The default errorbar_kwargs = {'color': 'black', 'lw': 2.5, 'linestyle': '-', 'alpha': 1, 'zorder': 1}\n\n\nChanging layout with horizontal\nForest plot assumes a vertical layout by default, but you can change it to a horizontal layout by setting horizontal to be True:\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        horizontal=True,)\n\n\n\n\n\n\n\n\n\n\nUsing a custom palette\nYou can color the half-violins with custom_palette:\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#00FF00', '#0000FF'],)\n\n\n\n\n\n\n\n\n\n\nPlotting other effect sizes\nForest plots can be drawn for effect sizes other than mean_difference, such as hedges_g, by setting effect_size:\n\nf_forest_hedgesg = dabest.forest_plot(\n                            data = contrasts, \n                            labels =['Drug1', 'Drug2', 'Drug3'], \n                            effect_size='hedges_g',\n);\n\n\n\n\n\n\n\n\n\n\nDelta text\nYou can add/remove delta text via the delta_text argument. It is on by default.\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#00FF00', '#0000FF'],\n                        delta_text=True)\n\n\n\n\n\n\n\n\nYou can set a variety of kwargs to customize the delta text via delta_text_kwargs.\nThe relevant inputs to delta_text_kwargs are:\n\n'color' - Color. If color is not specified, the color of the effect size curve will be used.\n'alpha'- Alpha (transparency)\n'fontsize' - Font size\n'ha' - Horizontal alignment\n'va' - Vertical alignment\n'rotation' - Text rotation\n'x_coordinates' - Specify the x-coordinates of the text\n'y_coordinates' - Specify the y-coordinates of the text\n'offset' - Am x-axis coordinate adjuster for minor movement of all text\n\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#00FF00', '#0000FF'],\n                        delta_text=True,\n                        delta_text_kwargs={'color': 'red', 'offset': 0.1,\n                                           'fontsize': 8, 'rotation': 45,\n                                           'va': 'bottom',\n                                           'x_coordinates': [1.4,2.4,3.4], \n                                           'y_coordinates': [0,-1.4,-1.6]})\n\n\n\n\n\n\n\n\n\n\nContrast bars\nYou can add/remove contrast bars via the contrast_bars argument. It is on by default.\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#00FF00', '#0000FF'],\n                        contrast_bars=True,)\n\n\n\n\n\n\n\n\nYou can set a variety of kwargs to customize the delta text via contrast_bars_kwargs.\nPass any keyword arguments accepted by matplotlib.patches.Rectangle here, as a string.\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#00FF00', '#0000FF'],\n                        contrast_bars=True,\n                        contrast_bars_kwargs={'color': 'red', 'alpha': 0.4})\n\n\n\n\n\n\n\n\n\n\nReference band\nYou can add reference bands by supplying a list/tuple to the reference_band argument, indicating the contrast to highlight. None are displayed by default.\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#0000FF', '#00FF00'],\n                        reference_band=[1,])\n\n\n\n\n\n\n\n\nYou can set a variety of kwargs to customize the reference bands via reference_band_kwargs.\nPass any keyword arguments accepted by matplotlib.patches.Rectangle here, as a string.\nIn addition, the span_ax keyword argument can be used to expand the reference band across the whole plot.\n\nf_forest_minimeta = dabest.forest_plot(\n                        data = contrasts_mini_meta, \n                        labels=['mini_meta1', 'mini_meta2', 'mini_meta3'],\n                        custom_palette=['#FF0000', '#0000FF', '#00FF00'],\n                        reference_band=[1,],\n                        reference_band_kwargs={'span_ax': True, 'color': 'grey', 'alpha': 0.2})\n\n\n\n\n\n\n\n\n\n\nEmbedding forest plots into an existing Axes\nYou can plot a forest plot into an existing Axes as a subplot by using the with the ax parameter.\n\nf_forest_drug_profiles, axes  = plt.subplots(2, 2, figsize=[15, 14])\nf_forest_drug_profiles.subplots_adjust(hspace=0.3, wspace=0.3)\n\nfor ax, contrast in zip(axes.flatten(), [unpaired_delta_01, unpaired_delta_02, unpaired_delta_03]):\n    contrast.mean_diff.plot(                  \n                    contrast_label='Mean Diff',\n                    raw_marker_size = 1,\n                    contrast_marker_size = 5,\n                    color_col='Genotype',\n                    ax = ax\n    )\n\ndabest.forest_plot(\n    data = contrasts, \n    labels = ['Drug1', 'Drug2', 'Drug3'], \n    ax = axes[1,1], \n    )\n\nfor ax, title in zip(axes.flatten(), ['Drug 1', 'Drug 2', 'Drug 3', 'Forest plot']):\n    ax.set_title(title, fontsize = 12)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Forest Plots: Visualizing Multiple Contrasts"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html",
    "href": "tutorials/01-basics.html",
    "title": "Basics",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 57.10it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#load-libraries",
    "href": "tutorials/01-basics.html#load-libraries",
    "title": "Basics",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 57.10it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#create-dataset-for-demo",
    "href": "tutorials/01-basics.html#create-dataset-for-demo",
    "title": "Basics",
    "section": "Create dataset for demo",
    "text": "Create dataset for demo\nHere, we create a dataset to illustrate how dabest works. In this dataset, each column corresponds to a group of observations.\n\nfrom scipy.stats import norm # Used in generation of populations.\n\nnp.random.seed(9999) # Fix the seed to ensure reproducibility of results.\n\nNs = 20 # The number of samples taken from each population\n\n# Create samples\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nt4 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nt5 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt6 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n\n# Add a `gender` column for coloring the data.\nfemales = np.repeat('Female', Ns/2).tolist()\nmales = np.repeat('Male', Ns/2).tolist()\ngender = females + males\n\n# Add an `id` column for paired data plotting.\nid_col = pd.Series(range(1, Ns+1))\n\n# Combine samples and gender into a DataFrame.\ndf = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                 'Control 2' : c2,     'Test 2' : t2,\n                 'Control 3' : c3,     'Test 3' : t3,\n                 'Test 4'    : t4,     'Test 5' : t5, 'Test 6' : t6,\n                 'Gender'    : gender, 'ID'  : id_col\n                })\ndf.head()\n\n\n\n\n\n\n\n\nControl 1\nTest 1\nControl 2\nTest 2\nControl 3\nTest 3\nTest 4\nTest 5\nTest 6\nGender\nID\n\n\n\n\n0\n2.793984\n3.420875\n3.324661\n1.707467\n3.816940\n1.796581\n4.440050\n2.937284\n3.486127\nFemale\n1\n\n\n1\n3.236759\n3.467972\n3.685186\n1.121846\n3.750358\n3.944566\n3.723494\n2.837062\n2.338094\nFemale\n2\n\n\n2\n3.019149\n4.377179\n5.616891\n3.301381\n2.945397\n2.832188\n3.214014\n3.111950\n3.270897\nFemale\n3\n\n\n3\n2.804638\n4.564780\n2.773152\n2.534018\n3.575179\n3.048267\n4.968278\n3.743378\n3.151188\nFemale\n4\n\n\n4\n2.858019\n3.220058\n2.550361\n2.796365\n3.692138\n3.276575\n2.662104\n2.977341\n2.328601\nFemale\n5\n\n\n\n\n\n\n\nNote that we have 9 groups (3 Control samples and 6 Test samples). Our dataset has also a non-numerical column indicating gender, and another column indicating the identity of each observation.\nThis is known as a wide dataset. See this writeup for more details.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#loading-data",
    "href": "tutorials/01-basics.html#loading-data",
    "title": "Basics",
    "section": "Loading data",
    "text": "Loading data\nBefore creating estimation plots and obtaining confidence intervals for our effect sizes, we need to load the data and specify the relevant groups.\nWe can achieve this by supplying the dataframe to dabest.load(). Additionally, we must provide the two groups to be compared in the idx argument as a tuple or list.\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), resamples=5000)\n\nCalling this Dabest object gives you a gentle greeting, as well as the comparisons that can be computed.\n\ntwo_groups_unpaired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:03 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nChanging statistical parameters\nYou can change the width of the confidence interval by manipulating the ci argument.\n\ntwo_groups_unpaired_ci90 = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), ci=90)\ntwo_groups_unpaired_ci90\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:03 2025.\n\nEffect size(s) with 90% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#effect-sizes",
    "href": "tutorials/01-basics.html#effect-sizes",
    "title": "Basics",
    "section": "Effect sizes",
    "text": "Effect sizes\nThe dabest library now features a range of effect sizes:\n\nMean difference (meanÔºødiff)\nMedian difference (medianÔºødiff)\nCohen‚Äôs d (cohensÔºød)\nHedges‚Äô g (hedgesÔºøg)\nCohen‚Äôs h (cohensÔºøh)\nCliff‚Äôs delta (cliffsÔºødelta)\n\nEach of these are attributes of the Dabest object.\n\ntwo_groups_unpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:03 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.48 [95%CI 0.205, 0.774].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\nFor each comparison, the type of effect size is reported (here, it‚Äôs the ‚Äúunpaired mean difference‚Äù). The confidence interval is reported as: [confidenceIntervalWidth LowerBound, UpperBound]\nThis confidence interval is generated through bootstrap resampling. See bootstraps for more details.\nSince v0.3.0, DABEST will report the p-value of the non-parametric two-sided approximate permutation t-test. This is also known as the Monte Carlo permutation test.\nFor unpaired comparisons, the p-values and test statistics of Welch‚Äôs t test, Student‚Äôs t test, and Mann-Whitney U test can be found. For paired comparisons, the p-values and test statistics of the paired Student‚Äôs t and Wilcoxon tests are presented.\n\npd.options.display.max_columns = 50\ntwo_groups_unpaired.mean_diff.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps\nresamples\nrandom_seed\npermutations\npvalue_permutation\npermutation_count\npermutations_var\npvalue_welch\nstatistic_welch\npvalue_students_t\nstatistic_students_t\npvalue_mann_whitney\nstatistic_mann_whitney\nbec_difference\nbec_bootstraps\nbec_bca_interval_idx\nbec_bca_low\nbec_bca_high\nbec_pct_interval_idx\nbec_pct_low\nbec_pct_high\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nmean difference\nNone\n0.48029\n95\n0.205161\n0.773647\n(145, 4893)\n0.197427\n0.758752\n(125, 4875)\n[0.6148498102262239, 0.6752095203445543, 0.300...\n5000\n12345\n[-0.17259843762502491, 0.03802293852634886, -0...\n0.001\n5000\n[0.26356588154404337, 0.2710249543904699, 0.26...\n0.002094\n-3.308806\n0.002057\n-3.308806\n0.001625\n83.0\n0.0\n[-0.09732932551566487, 0.08087009665445155, -0...\n(127, 4877)\n-0.256862\n0.259558\n(125, 4875)\n-0.25826\n0.25759\n\n\n\n\n\n\n\n\ntwo_groups_unpaired.mean_diff.statistical_tests\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\npvalue_permutation\npvalue_welch\nstatistic_welch\npvalue_students_t\nstatistic_students_t\npvalue_mann_whitney\nstatistic_mann_whitney\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nmean difference\nNone\n0.48029\n95\n0.205161\n0.773647\n0.001\n0.002094\n-3.308806\n0.002057\n-3.308806\n0.001625\n83.0\n\n\n\n\n\n\n\nNote: A research paper Phipson & Smyth (2010) suggested that permutation p-values should never be zero, and provided a slightly adjusted formula to compute permutation p-values.\nSince v2025.03.27, DABEST provides a ps_adjust parameter in the .load() function. This parameter allows you to adjust the permutation p-values using the formula suggested by Phipson & Smyth (2010). By default, DABEST uses the unadjusted p-values.\n\ntwo_groups_unpaired_adjusted = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), resamples=5000, ps_adjust=True)\ntwo_groups_unpaired_adjusted.mean_diff.statistical_tests\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\npvalue_permutation\npvalue_welch\nstatistic_welch\npvalue_students_t\nstatistic_students_t\npvalue_mann_whitney\nstatistic_mann_whitney\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nmean difference\nNone\n0.48029\n95\n0.205161\n0.773647\n0.0012\n0.002094\n-3.308806\n0.002057\n-3.308806\n0.001625\n83.0\n\n\n\n\n\n\n\nLet‚Äôs compute the Hedges‚Äôg for our comparison.\n\ntwo_groups_unpaired.hedges_g\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:04 2025.\n\nThe unpaired Hedges' g between Control 1 and Test 1 is 1.03 [95%CI 0.317, 1.62].\nThe p-value of the two-sided permutation t-test is 0.001, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.hedges_g.statistical_tests`\n\n\n\ntwo_groups_unpaired.hedges_g.results\n\n\n\n\n\n\n\n\ncontrol\ntest\ncontrol_N\ntest_N\neffect_size\nis_paired\ndifference\nci\nbca_low\nbca_high\nbca_interval_idx\npct_low\npct_high\npct_interval_idx\nbootstraps\nresamples\nrandom_seed\npermutations\npvalue_permutation\npermutation_count\npermutations_var\npvalue_welch\nstatistic_welch\npvalue_students_t\nstatistic_students_t\npvalue_mann_whitney\nstatistic_mann_whitney\nbec_difference\nbec_bootstraps\nbec_bca_interval_idx\nbec_bca_low\nbec_bca_high\nbec_pct_interval_idx\nbec_pct_low\nbec_pct_high\n\n\n\n\n0\nControl 1\nTest 1\n20\n20\nHedges' g\nNone\n1.025525\n95\n0.316506\n1.616235\n(42, 4725)\n0.44486\n1.745146\n(125, 4875)\n[1.469217954462509, 1.5972518056777079, 0.6051...\n5000\n12345\n[-0.329508986559053, 0.07158401210924781, -0.2...\n0.001\n5000\n[0.26356588154404337, 0.2710249543904699, 0.26...\n0.002094\n-3.308806\n0.002057\n-3.308806\n0.001625\n83.0\n0.0\n[-0.2669450878059954, 0.21187593591106418, -0....\n(127, 4877)\n-0.642387\n0.629464\n(125, 4875)\n-0.643604\n0.627968",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#producing-estimation-plots",
    "href": "tutorials/01-basics.html#producing-estimation-plots",
    "title": "Basics",
    "section": "Producing estimation plots",
    "text": "Producing estimation plots\nTo generate a Gardner-Altman estimation plot, simply use the .plot() method. You can learn more about its genesis and design inspiration at robust-beautiful.\nEach instance of an effect size has access to the .plot() method. This allows you to quickly create plots for different effect sizes with ease.\n\ntwo_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\ntwo_groups_unpaired.hedges_g.plot();\n\n\n\n\n\n\n\n\nInstead of a Gardner-Altman plot, you can generate a Cumming estimation plot by setting float_contrast=False in the .plot() method. This will plot the bootstrap effect sizes below the raw data, and also displays the the mean (gap) and ¬± standard deviation of each group (vertical ends) as gapped lines. This design was inspired by Edward Tufte‚Äôs dictum to maximise the data-ink ratio.\n\ntwo_groups_unpaired.hedges_g.plot(float_contrast=False);\n\n\n\n\n\n\n\n\nThe confidence interval shown on the contrast axis is a BCa confidence interval by default. This can be modified using the ci_type parameter in the .plot() method, whereby you can select between bca and pct (percentile).\n\ntwo_groups_unpaired.mean_diff.plot(ci_type='pct');\n\n\n\n\n\n\n\n\n\nUsing long (aka ‚Äòmelted‚Äô) data frames\ndabest can also handle ‚Äòmelted‚Äô or ‚Äòlong‚Äô data. This term is used because each row now corresponds to a single data point, with one column carrying the value and other columns containing ‚Äòmetadata‚Äô describing that data point.\nFor more details on wide vs long or ‚Äòmelted‚Äô data, refer to this Wikipedia article. The pandas documentation provides recipes for melting dataframes.\n\nx='group'\ny='metric'\n\nvalue_cols = df.columns[:-2] # select all but the \"Gender\" and \"ID\" columns.\n\ndf_melted = pd.melt(df.reset_index(),\n                    id_vars=[\"Gender\", \"ID\"],\n                    value_vars=value_cols,\n                    value_name=y,\n                    var_name=x)\n\ndf_melted.head() # Gives the first five rows of `df_melted`.\n\n\n\n\n\n\n\n\nGender\nID\ngroup\nmetric\n\n\n\n\n0\nFemale\n1\nControl 1\n2.793984\n\n\n1\nFemale\n2\nControl 1\n3.236759\n\n\n2\nFemale\n3\nControl 1\n3.019149\n\n\n3\nFemale\n4\nControl 1\n2.804638\n\n\n4\nFemale\n5\nControl 1\n2.858019\n\n\n\n\n\n\n\nWhen your data is in this format, you need to specify the x and y columns in dabest.load().\n\nanalysis_of_long_df = dabest.load(df_melted, idx=(\"Control 1\", \"Test 1\"),\n                                     x=\"group\", y=\"metric\")\n\nanalysis_of_long_df\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:04 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/01-basics.html#dabest-estimation-plot-designs",
    "href": "tutorials/01-basics.html#dabest-estimation-plot-designs",
    "title": "Basics",
    "section": "Dabest estimation plot designs",
    "text": "Dabest estimation plot designs\nThe dabest package implements a range of estimation plot designs aimed at depicting common experimental designs:\n\nTwo-Group\nShared Control (Unpaired) and Repeated Measures (Paired)\nProportion Plots\nMini-Meta\nDelta-Delta\nForest Plots\n\nIn addition, as of Dabest v2025.03.27, we introduce a new plotting orientation: Horizontal Plots.\nLastly, we have a whole tutorial page for making aesthetic changes to dabest plots.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Basics"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with dabest‚Äôs features.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\nBasics\n\n\nAn end-to-end tutorial on how to use the dabest library.\n\n\n\n\n\n\nTwo-Group Experiments\n\n\nExplanation of how to use dabest for two-group and multi two-group analysis.\n\n\n\n\n\n\nShared Control & Repeated Measures\n\n\nExplanation of how to use dabest for shared control and repeated measures analyses.\n\n\n\n\n\n\nProportion Plots\n\n\nA guide to plot proportion plots with binary data.\n\n\n\n\n\n\nMini-Meta\n\n\nExplanation of how to compute the meta-analyzed weighted effect size using dabest.\n\n\n\n\n\n\nDelta-Delta\n\n\nExplanation of how to calculate delta-delta using DABEST.\n\n\n\n\n\n\nHorizontal Plots\n\n\nA guide to plot data in a horizontal format.\n\n\n\n\n\n\nControlling Plot Aesthetics\n\n\nA guide to various plot aesthetic changes that can be done.\n\n\n\n\n\n\nForest Plots: Visualizing Multiple Contrasts\n\n\nExplanation of how to use forest_plot for contrast objects e.g delta-delta and mini-meta or regular deltas.\n\n\n\n\n\n\nWhorlmaps: Visualizing Even More Contrasts\n\n\nExplanation of how to use forest_plot for contrast objects e.g delta-delta and mini-meta or regular deltas.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tutorials/04-proportion_plot.html",
    "href": "tutorials/04-proportion_plot.html",
    "title": "Proportion Plots",
    "section": "",
    "text": "As of v2023.02.14, DABEST can be used to generate Cohen‚Äôs h and the corresponding proportion plot for binary data. It‚Äôs important to note that the code we provide only supports numerical proportion data, where the values are limited to 0 (failure) and 1 (success). This means that the code is not suitable for analyzing proportion data that contains non-numeric values, such as strings like ‚Äòyes‚Äô and ‚Äòno‚Äô.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#load-libraries",
    "href": "tutorials/04-proportion_plot.html#load-libraries",
    "title": "Proportion Plots",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport numpy as np\nimport pandas as pd\nimport dabest\n\nprint(\"We're using DABEST v{}\".format(dabest.__version__))\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 61.07it/s]\n\n\nNumba compilation complete!\nWe're using DABEST v2025.10.20",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#creating-a-demo-dataset",
    "href": "tutorials/04-proportion_plot.html#creating-a-demo-dataset",
    "title": "Proportion Plots",
    "section": "Creating a demo dataset",
    "text": "Creating a demo dataset\n\ndef create_demo_prop_dataset(seed=9999, N=40):\n    import numpy as np\n    import pandas as pd\n\n    np.random.seed(9999)  # Fix the seed to ensure reproducibility of results.\n    # Create samples\n    n = 1\n    c1 = np.random.binomial(n, 0.2, size=N)\n    c2 = np.random.binomial(n, 0.2, size=N)\n    c3 = np.random.binomial(n, 0.8, size=N)\n\n    t1 = np.random.binomial(n, 0.6, size=N)\n    t2 = np.random.binomial(n, 0.2, size=N)\n    t3 = np.random.binomial(n, 0.3, size=N)\n    t4 = np.random.binomial(n, 0.4, size=N)\n    t5 = np.random.binomial(n, 0.5, size=N)\n    t6 = np.random.binomial(n, 0.6, size=N)\n    t7 = np.ones(N)\n    t8 = np.zeros(N)\n    t9 = np.zeros(N)\n\n    # Add a `gender` column for coloring the data.\n    females = np.repeat('Female', N / 2).tolist()\n    males = np.repeat('Male', N / 2).tolist()\n    gender = females + males\n\n    # Add an `id` column for paired data plotting.\n    id_col = pd.Series(range(1, N + 1))\n\n    # Combine samples and gender into a DataFrame.\n    df = pd.DataFrame({'Control 1': c1, 'Test 1': t1,\n                       'Control 2': c2, 'Test 2': t2,\n                       'Control 3': c3, 'Test 3': t3,\n                       'Test 4': t4, 'Test 5': t5, 'Test 6': t6,\n                       'Test 7': t7, 'Test 8': t8, 'Test 9': t9,\n                       'Gender': gender, 'ID': id_col\n                       })\n\n    return df\ndf = create_demo_prop_dataset()\ndf.head()\n\n\n\n\n\n\n\n\nControl 1\nTest 1\nControl 2\nTest 2\nControl 3\nTest 3\nTest 4\nTest 5\nTest 6\nTest 7\nTest 8\nTest 9\nGender\nID\n\n\n\n\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n1.0\n0.0\n0.0\nFemale\n1\n\n\n1\n0\n1\n0\n1\n1\n1\n0\n0\n0\n1.0\n0.0\n0.0\nFemale\n2\n\n\n2\n0\n1\n0\n0\n1\n0\n1\n1\n0\n1.0\n0.0\n0.0\nFemale\n3\n\n\n3\n0\n1\n0\n0\n1\n0\n0\n1\n0\n1.0\n0.0\n0.0\nFemale\n4\n\n\n4\n0\n0\n0\n0\n1\n0\n0\n0\n1\n1.0\n0.0\n0.0\nFemale\n5\n\n\n\n\n\n\n\n\nHelper function to create a binary table - dabest.prop_dataset\nIn DABEST v2024.3.29, we incorporated feedback from biologists who may not have tables of 0‚Äôs and 1‚Äôs readily available. As a result, a convenient function - dabest.prop_dataset - to generate a binary dataset based on the specified sample sizes is provided. Users can generate a pandas.DataFrame containing the sample sizes for each element in the groups and the group names (optional if the sample sizes are provided in a dict).\n\nsample_size_1 = {'a':[3, 4], 'b':[2, 5]}\nsample_size_2 = [3, 4, 2, 5]\nnames = ['a', 'b']\nsample_df_1 = dabest.prop_dataset(sample_size_1)\nsample_df_2 = dabest.prop_dataset(sample_size_2, names)\nprint(all(sample_df_1 == sample_df_2))\nsample_df_1.head()\n\nTrue\n\n\n\n\n\n\n\n\n\na\nb\nID\n\n\n\n\n0\n0\n0\n1\n\n\n1\n0\n0\n2\n\n\n2\n0\n1\n3\n\n\n3\n1\n1\n4\n\n\n4\n1\n1\n5",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#loading-data",
    "href": "tutorials/04-proportion_plot.html#loading-data",
    "title": "Proportion Plots",
    "section": "Loading data",
    "text": "Loading data\nWhen loading data, you need to set the parameter proportional=True.\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), proportional=True)\ntwo_groups_unpaired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:22 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#effect-sizes",
    "href": "tutorials/04-proportion_plot.html#effect-sizes",
    "title": "Proportion Plots",
    "section": "Effect sizes",
    "text": "Effect sizes\nTo generate a proportion plot, the dabest library features two effect sizes:\n\nMean difference (mean_diff)\nCohen‚Äôs h (cohensÔºøh)\n\nThese are attributes of the Dabest object.\n\ntwo_groups_unpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:23 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.575 [95%CI 0.35, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\nLet‚Äôs compute the Cohen‚Äôs h for our comparison.\n\ntwo_groups_unpaired.cohens_h\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:23 2025.\n\nThe unpaired Cohen's h between Control 1 and Test 1 is 1.24 [95%CI 0.784, 1.66].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.cohens_h.statistical_tests`",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#generating-proportion-plots",
    "href": "tutorials/04-proportion_plot.html#generating-proportion-plots",
    "title": "Proportion Plots",
    "section": "Generating proportion plots",
    "text": "Generating proportion plots\nTo generate an estimation plot, simply use the .plot() method.\nEach effect size instance has access to the .plot() method, allowing you to quickly create plots for different effect sizes with ease.\n\nUnpaired proportion plots\nUnpaired proportion plots utilise the common bar plot. The bar plot displays the proportion of observations in the dataset that belong to the category of interest:\n\nThe white portion represents the proportion of observations that do not belong to the category (proportion of 0s in the data).\nThe colored portion represents the proportion of observations belonging to the category (proportion of 1s in the data).\n\n\nTwo-Group\n\ntwo_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\ntwo_groups_unpaired.cohens_h.plot();\n\n\n\n\n\n\n\n\nInstead of a Gardner-Altman plot, you can generate a Cumming estimation plot by setting float_contrast=False in the .plot() method. This will plot the bootstrap effect sizes below the raw data.\n\ntwo_groups_unpaired.mean_diff.plot(float_contrast=False);\n\n\n\n\n\n\n\n\n\n\nMulti Two-Group, Shared-Control, and Multi Groups\nAs with regular (non-binary) unpaired data, multi two-group, shared-control, and multi group plots can be generated for binary data.\n\nmulti_two_groups_unpaired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\")),\n                                        proportional=True)\nmulti_two_groups_unpaired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:24 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 3\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nmulti_two_groups_unpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:25 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.575 [95%CI 0.35, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 2 is 0.025 [95%CI -0.15, 0.15].\nThe p-value of the two-sided permutation t-test is 0.535, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 3 and Test 3 is -0.6 [95%CI -0.75, -0.425].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nmulti_two_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nshared_control = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\"),\n                                        proportional=True)\nshared_control\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:25 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 1\n3. Test 3 minus Control 1\n4. Test 4 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nshared_control.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:26 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.575 [95%CI 0.35, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 2 is 0.025 [95%CI -0.15, 0.15].\nThe p-value of the two-sided permutation t-test is 0.539, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 3 is 0.125 [95%CI -0.025, 0.325].\nThe p-value of the two-sided permutation t-test is 0.0936, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 1 and Test 4 is 0.15 [95%CI -0.05, 0.3].\nThe p-value of the two-sided permutation t-test is 0.0604, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nshared_control.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nmulti_groups_unpaired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\", \"Test 3\", \"Test 4\")),\n                                        proportional=True)\nmulti_groups_unpaired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:26 2025.\n\nEffect size(s) with 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 2\n4. Test 4 minus Control 2\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nmulti_groups_unpaired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:26 2025.\n\nThe unpaired mean difference between Control 1 and Test 1 is 0.575 [95%CI 0.35, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 2 is 0.025 [95%CI -0.15, 0.15].\nThe p-value of the two-sided permutation t-test is 0.535, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 3 is 0.125 [95%CI -0.05, 0.325].\nThe p-value of the two-sided permutation t-test is 0.099, calculated for legacy purposes only. \n\nThe unpaired mean difference between Control 2 and Test 4 is 0.15 [95%CI -0.05, 0.3].\nThe p-value of the two-sided permutation t-test is 0.0604, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nmulti_groups_unpaired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\n\n\nPaired proportion plots\nFor the paired version of the proportion plot, we adopt the style of a Sankey Diagram. The width of each bar in each xtick represents the proportion of the corresponding label in the group, and the strip denotes the paired relationship for each observation.\nStarting from v2024.3.29, the paired version of the proportion plot receives a major upgrade. We introduce the sankey and flow parameters to control the plot. By default, both sankey and flow are set to True to cater the needs of repeated measures. When sankey is set to False, DABEST will generate a bar plot with a similar aesthetic to the paired proportion plot. When flow is set to False, each group of comparsion forms a Sankey diagram that does not connect to other groups of comparison.\nSimilar to the unpaired version, the .plot() method is used to produce an estimation plot.\n\nTwo-Group\n\ntwo_groups_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), \n                                  proportional=True, paired=\"baseline\", id_col=\"ID\")\ntwo_groups_paired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:27 2025.\n\nPaired effect size(s) for repeated measures against baseline \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\ntwo_groups_paired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:27 2025.\n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 1 is 0.575 [95%CI 0.325, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\ntwo_groups_paired.mean_diff.plot();\n\n\n\n\n\n\n\n\nThe Sankey plots for paired proportions also supports the float_contrast parameter, which can be set to False to produce a Cumming estimation plot.\n\ntwo_groups_paired.mean_diff.plot(float_contrast=False);\n\n\n\n\n\n\n\n\n\n\nMulti Two-Group, Repeated Measures, and Multi Groups\nAs with regular (non-binary) unpaired data, multi two-group, repeated-measures, and multi group plots can be generated for binary data.\n\nmulti_two_groups_paired = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\"),(\"Control 3\", \"Test 3\")),\n                                        proportional=True, paired=\"baseline\", id_col=\"ID\")\nmulti_two_groups_paired\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:27 2025.\n\nPaired effect size(s) for repeated measures against baseline \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 3\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nmulti_two_groups_paired.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:28 2025.\n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 1 is 0.575 [95%CI 0.325, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 2 and Test 2 is 0.025 [95%CI -0.15, 0.175].\nThe p-value of the two-sided permutation t-test is 0.571, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 3 and Test 3 is -0.6 [95%CI -0.775, -0.425].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nmulti_two_groups_paired.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nrepeated_measures_baseline = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\"),\n                                        proportional=True, paired=\"baseline\", id_col=\"ID\")\nrepeated_measures_baseline\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:28 2025.\n\nPaired effect size(s) for repeated measures against baseline \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 1\n3. Test 3 minus Control 1\n4. Test 4 minus Control 1\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nrepeated_measures_baseline.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:29 2025.\n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 1 is 0.575 [95%CI 0.325, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 2 is 0.025 [95%CI -0.15, 0.175].\nThe p-value of the two-sided permutation t-test is 0.555, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 3 is 0.125 [95%CI -0.075, 0.275].\nThe p-value of the two-sided permutation t-test is 0.277, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 4 is 0.15 [95%CI -0.05, 0.325].\nThe p-value of the two-sided permutation t-test is 0.075, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nrepeated_measures_baseline.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nrepeated_measures_sequential = dabest.load(df, idx=(\"Control 1\", \"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\"),\n                                        proportional=True, paired=\"sequential\", id_col=\"ID\")\nrepeated_measures_sequential\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:29 2025.\n\nPaired effect size(s) for the sequential design of repeated-measures experiment \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Test 1\n3. Test 3 minus Test 2\n4. Test 4 minus Test 3\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nrepeated_measures_sequential.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:30 2025.\n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Control 1 and Test 1 is 0.575 [95%CI 0.325, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Test 1 and Test 2 is -0.55 [95%CI -0.725, -0.4].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Test 2 and Test 3 is 0.1 [95%CI -0.075, 0.225].\nThe p-value of the two-sided permutation t-test is 0.342, calculated for legacy purposes only. \n\nThe paired mean difference for the sequential design of repeated-measures experiment \nbetween Test 3 and Test 4 is 0.025 [95%CI -0.2, 0.2].\nThe p-value of the two-sided permutation t-test is 0.624, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nrepeated_measures_sequential.mean_diff.plot();\n\n\n\n\n\n\n\n\n\nmulti_groups_baseline = dabest.load(df, idx=((\"Control 1\", \"Test 1\"),(\"Control 2\", \"Test 2\", \"Test 3\", \"Test 4\")),\n                                        proportional=True, paired=\"baseline\", id_col=\"ID\")\nmulti_groups_baseline\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:30 2025.\n\nPaired effect size(s) for repeated measures against baseline \nwith 95% confidence intervals will be computed for:\n1. Test 1 minus Control 1\n2. Test 2 minus Control 2\n3. Test 3 minus Control 2\n4. Test 4 minus Control 2\n\n5000 resamples will be used to generate the effect size bootstraps.\n\n\n\nmulti_groups_baseline.mean_diff\n\nDABEST v2025.10.20\n==================\n                  \nGood afternoon!\nThe current time is Sun Oct 19 16:00:31 2025.\n\nThe paired mean difference for repeated measures against baseline \nbetween Control 1 and Test 1 is 0.575 [95%CI 0.325, 0.725].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 2 and Test 2 is 0.025 [95%CI -0.15, 0.175].\nThe p-value of the two-sided permutation t-test is 0.571, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 2 and Test 3 is 0.125 [95%CI -0.075, 0.3].\nThe p-value of the two-sided permutation t-test is 0.309, calculated for legacy purposes only. \n\nThe paired mean difference for repeated measures against baseline \nbetween Control 2 and Test 4 is 0.15 [95%CI -0.025, 0.3].\nThe p-value of the two-sided permutation t-test is 0.0362, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\n\nmulti_groups_baseline.mean_diff.plot();",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tutorials/04-proportion_plot.html#aesthetic-adjustments",
    "href": "tutorials/04-proportion_plot.html#aesthetic-adjustments",
    "title": "Proportion Plots",
    "section": "Aesthetic adjustments",
    "text": "Aesthetic adjustments\nHere we demonstrate a few proportion plot specific aesthetic adjustments.\n\nBar Width\nYou can modify the width of the bar plot bars (unpaired data) by setting the parameter bar_width in the .plot() method.\n\ntwo_groups_unpaired.mean_diff.plot(bar_width=0.3);\n\n\n\n\n\n\n\n\n\n\nBar desaturation\nThe raw_desat is used to control the amount of desaturation applied to the bar plot bar colors (specific to unpaired data). A value of 0.0 means full desaturation (i.e., grayscale), while a value of 1.0 means no desaturation (i.e., full color saturation). The default one is 0.8.\n\ntwo_groups_unpaired.mean_diff.plot(raw_desat=1.0);\n\n\n\n\n\n\n\n\n\n\nRaw Label and Contrast Label\nThe parameters raw_label and contrast_label can be used to set labels for the y-axis of the bar plot and the contrast plot.\n\ntwo_groups_unpaired.mean_diff.plot(raw_label=\"success\",contrast_label=\"difference\");\ntwo_groups_paired.mean_diff.plot(raw_label=\"success\",contrast_label=\"difference\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBarplot kwargs\nThe parameters barplot_kwargs can be used to alter the aesthetics of the bar plot. This is a dictionary that can be used to pass additional arguments to the bar plot.\n\ntwo_groups_unpaired.mean_diff.plot(barplot_kwargs={\"alpha\":0.5, \"edgecolor\":\"red\", \"linewidth\":2, 'errorbar': ('sd', 0.1)});\n\n\n\n\n\n\n\n\n\n\nSankey and Flow\nBy changing the sankey and flow parameters, you can generate different types of Sankey plots for paired proportions.\n\nseparate_control = dabest.load(df, idx=(((\"Control 1\", \"Test 1\"),\n                                (\"Test 2\", \"Test 3\"),\n                                (\"Test 4\", \"Test 7\", \"Test 6\"))),\n                    proportional=True, paired=\"sequential\", id_col=\"ID\")\n\nseparate_control.mean_diff.plot();\nseparate_control.mean_diff.plot(sankey_kwargs={'sankey':False});\nseparate_control.mean_diff.plot(sankey_kwargs={'flow':False});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSankey kwargs\nSeveral exclusive parameters can be provided to the .plot() method to customize the Sankey plots for paired proportions. By modifying the sankey_kwargs parameter, you can customize the Sankey plot. The following parameters are supported:\n\nalign: The alignment of each Sankey bar. Default is ‚Äúcenter‚Äù.\nalpha: The transparency of each Sankey bar. Default is 0.4.\nbar_width: The width of each bar on the side in the plot. Default is 0.1.\n\n\nrepeated_measures_baseline.mean_diff.plot(sankey_kwargs = {\"alpha\": 0.2,\n                                                  \"bar_width\": 0.4});\n\n\n\n\n\n\n\n\n\n\nCustom Palette\nThe custom_palette parameter functions in a similar way for proportion plots as for other plots - however, there are some differences!\nA custom_palette dict can be passed for sankey plots, whereby two keys used are 0 and 1. The color associated with these keys will be used to color the bars in the sankey plot.\nFor bar plots, the custom_palette dict can be passed like a regular plot, with a color associated to each group. The chosen color will then be used to color the filled portion of the bar plot.\n\nrepeated_measures_baseline.mean_diff.plot(custom_palette={0: \"red\", 1: \"blue\"});\nshared_control.mean_diff.plot(custom_palette={'Control 1': \"red\", 'Test 1': \"blue\", 'Test 2': \"green\", 'Test 3': \"purple\", 'Test 4': \"orange\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, premade matplotlib/seaborn color palette can be passed. For sankey plots, the first two colors in the palette will be used to color the bars in the sankey plot. For bar plots, the colors will be used to color the filled portion of the bar plot.\n\nrepeated_measures_baseline.mean_diff.plot(custom_palette='Set1');\nshared_control.mean_diff.plot(custom_palette='Set1');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPassing a custom palette list functions differently for bar plots and sankey plots:\n\nFor bar plots, the list should contain the colors associated with each group.\nFor sankey plots, the list should contain two colors, the first color will be used to color the binary ‚Äô1‚Äôs, and the second color will be used to color the ‚Äô0‚Äôs.\n\n\nrepeated_measures_baseline.mean_diff.plot(custom_palette=['red', 'blue']);\nshared_control.mean_diff.plot(custom_palette=['red', 'blue', 'green', 'purple', 'orange']);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdd counts to proportion plots\nBy default, the sample counts for each bar in proportion plots are not shown.\nThis feature can be turned on by setting prop_sample_counts=True in the .plot() method.\nNote: This feature is not compatible with flow=False in sankey_kwargs.\n\ntwo_groups_unpaired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"), proportional=True)\ntwo_groups_unpaired.mean_diff.plot(prop_sample_counts=True);\n\n\n\n\n\n\n\n\nThe sample counts kwargs can be utilised via prop_sample_counts_kwargs in the .plot() method.\n\ntwo_groups_unpaired.mean_diff.plot(prop_sample_counts=True, prop_sample_counts_kwargs={\"color\":\"red\"});\n\n\n\n\n\n\n\n\nFor further aesthetic changes, the Plot Aesthetics Tutorial provides detailed examples of how to customize the plot.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Proportion Plots"
    ]
  },
  {
    "objectID": "tests/test_99_confidence_intervals.html",
    "href": "tests/test_99_confidence_intervals.html",
    "title": "dabest",
    "section": "",
    "text": "import numpy as np\nfrom scipy.stats import norm\nfrom scipy.stats import skewnorm\nimport pandas as pd\nimport pytest\n\n\n\nfrom dabest._api import load\n\ntest_paired_mean_diff_ci\n\n# See Altman et al., Statistics with Confidence: \n# Confidence Intervals and Statistical Guidelines (Second Edition). Wiley, 2000.\n# Pg 31.\n# Added in v0.2.5.\nblood_pressure = {\"before\": [148, 142, 136, 134, 138, 140, 132, 144,\n                            128, 170, 162, 150, 138, 154, 126, 116],\n                  \"after\" : [152, 152, 134, 148, 144, 136, 144, 150, \n                            146, 174, 162, 162, 146, 156, 132, 126],\n                 \"subject_id\" : np.arange(1, 17)}\nexercise_bp = pd.DataFrame(blood_pressure)\n\n\nex_bp = load(data=exercise_bp, idx=(\"before\", \"after\"), \n             paired=\"baseline\", id_col=\"subject_id\")\npaired_mean_diff = ex_bp.mean_diff.results\n\n\nassert pytest.approx(3.625) == paired_mean_diff.bca_low[0]\nassert pytest.approx(9.125) == paired_mean_diff.bca_high[0]\n\ntest_unpaired_ci\n\n# Dropped to 30 reps to save time. v0.2.5.\nreps=30\nci=95\nPOPULATION_N = 10000\nSAMPLE_N = 10\n\n# Create data for hedges g and cohens d.\nCONTROL_MEAN = np.random.randint(1, 1000)\nPOP_SD       = np.random.randint(1, 15)\nPOP_D        = np.round(np.random.uniform(-2, 2, 1)[0], 2)\n\nTRUE_STD_DIFFERENCE = CONTROL_MEAN + (POP_D * POP_SD)\nnorm_sample_kwargs = dict(scale=POP_SD, size=SAMPLE_N)\nc1 = norm.rvs(loc=CONTROL_MEAN, **norm_sample_kwargs)\nt1 = norm.rvs(loc=CONTROL_MEAN+TRUE_STD_DIFFERENCE, **norm_sample_kwargs)\n\nstd_diff_df = pd.DataFrame({'Control' : c1, 'Test': t1})\n\n\n\n# Create mean_diff data\nCONTROL_MEAN = np.random.randint(1, 1000)\nPOP_SD       = np.random.randint(1, 15)\nTRUE_DIFFERENCE = np.random.randint(-POP_SD*5, POP_SD*5)\n\nc1 = norm.rvs(loc=CONTROL_MEAN, **norm_sample_kwargs)\nt1 = norm.rvs(loc=CONTROL_MEAN+TRUE_DIFFERENCE, **norm_sample_kwargs)\n\nmean_df = pd.DataFrame({'Control' : c1, 'Test': t1})\n\n\n\n# Create median_diff data\nMEDIAN_DIFFERENCE = np.random.randint(-5, 5)\nA = np.random.randint(-7, 7)\n\nskew_kwargs = dict(a=A, scale=5, size=POPULATION_N)\nskewpop1 = skewnorm.rvs(**skew_kwargs, loc=100)\nskewpop2 = skewnorm.rvs(**skew_kwargs, loc=100+MEDIAN_DIFFERENCE)\n\nsample_kwargs = dict(replace=False, size=SAMPLE_N)\nskewsample1 = np.random.choice(skewpop1, **sample_kwargs)\nskewsample2 = np.random.choice(skewpop2, **sample_kwargs)\n\nmedian_df = pd.DataFrame({'Control' : skewsample1, 'Test': skewsample2})\n\n\n\n# Create two populations with a 50% overlap.\nCD_DIFFERENCE = np.random.randint(1, 10)\nSD = np.abs(CD_DIFFERENCE)\n\npop_kwargs = dict(scale=SD, size=POPULATION_N)\npop1 = norm.rvs(loc=100, **pop_kwargs)\npop2 = norm.rvs(loc=100+CD_DIFFERENCE, **pop_kwargs)\n\nsample_kwargs = dict(replace=False, size=SAMPLE_N)\nsample1 = np.random.choice(pop1, **sample_kwargs)\nsample2 = np.random.choice(pop2, **sample_kwargs)\n\ncd_df = pd.DataFrame({'Control' : sample1, 'Test': sample2})\n\n\n\n# Create several CIs and see if the true population difference lies within.\nerror_count_cohens_d     = 0\nerror_count_hedges_g     = 0\nerror_count_mean_diff    = 0\nerror_count_median_diff  = 0\nerror_count_cliffs_delta = 0\n\nfor i in range(0, reps):\n    print(i) # for debug.\n    # pick a random seed\n    rnd_sd = np.random.randint(0, 999999)\n    load_kwargs = dict(ci=ci, random_seed=rnd_sd)\n\n    std_diff_data = load(data=std_diff_df, idx=(\"Control\", \"Test\"), **load_kwargs)\n    cd = std_diff_data.cohens_d.results\n    # print(\"cohen's d\")  # for debug.\n    cd_low, cd_high = float(cd.bca_low), float(cd.bca_high)\n    if cd_low &lt; POP_D &lt; cd_high is False:\n        error_count_cohens_d += 1\n\n    hg = std_diff_data.hedges_g.results\n    # print(\"hedges' g\") # for debug.\n    hg_low, hg_high = float(hg.bca_low), float(hg.bca_high)\n    if hg_low &lt; POP_D &lt; hg_high is False:\n        error_count_hedges_g += 1\n\n\n    mean_diff_data = load(data=mean_df, idx=(\"Control\", \"Test\"), **load_kwargs)\n    mean_d = mean_diff_data.mean_diff.results\n    # print(\"mean diff\") # for debug.\n    mean_d_low, mean_d_high = float(mean_d.bca_low), float(mean_d.bca_high)\n    if mean_d_low &lt; TRUE_DIFFERENCE &lt; mean_d_high is False:\n        error_count_mean_diff += 1\n\n\n    median_diff_data = load(data=median_df, idx=(\"Control\", \"Test\"),\n                         **load_kwargs)\n    median_d = median_diff_data.median_diff.results\n    # print(\"median diff\") # for debug.\n    median_d_low, median_d_high = float(median_d.bca_low), float(median_d.bca_high)\n    if median_d_low &lt; MEDIAN_DIFFERENCE &lt; median_d_high is False:\n        error_count_median_diff += 1\n\n\n    cd_data = load(data=cd_df, idx=(\"Control\", \"Test\"), **load_kwargs)\n    cliffs = cd_data.cliffs_delta.results\n    # print(\"cliff's delta\") # for debug.\n    low, high = float(cliffs.bca_low), float(cliffs.bca_high)\n    if low &lt; 0.5 &lt; high is False:\n        error_count_cliffs_delta += 1\n\n\nmax_errors = int(np.ceil(reps * (100 - ci) / 100))\n\nassert error_count_cohens_d     &lt;= max_errors\nassert error_count_hedges_g     &lt;= max_errors\nassert error_count_mean_diff    &lt;= max_errors\nassert error_count_median_diff  &lt;= max_errors\nassert error_count_cliffs_delta &lt;= max_errors"
  },
  {
    "objectID": "tests/test_04_repeated_measures_effsizes_pvals.html",
    "href": "tests/test_04_repeated_measures_effsizes_pvals.html",
    "title": "dabest",
    "section": "",
    "text": "import pytest\nimport lqrt\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\n\n\nfrom dabest import Dabest\nfrom data.mocked_data_test_01 import dabest_default_kwargs\nfrom data.mocked_data_test_04 import df\n\n\n# example of sequential repeated measures\nsequential = Dabest(df, id_col = \"ID\",\n                         idx=(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\"),\n                         paired = \"sequential\",\n                         **dabest_default_kwargs)\n\n# example of baseline repeated measures\nbaseline = Dabest(df, id_col = \"ID\",\n                       idx=(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\"),\n                       paired = \"baseline\",\n                       **dabest_default_kwargs)\n\ntest_mean_diff_sequential\n\nmean_diff = sequential.mean_diff.results['difference'].to_list()\nnp_result = [np.mean(df.iloc[:,i+1]-df.iloc[:,i]) for i in range(1,5)]\nassert mean_diff == pytest.approx(np_result)\n\ntest_median_diff_sequential\n\nmedian_diff = sequential.median_diff.results['difference'].to_list()\nnp_result = [np.median(df.iloc[:,i+1]-df.iloc[:,i]) for i in range(1,5)]\nassert median_diff == pytest.approx(np_result)\n\ntest_mean_diff_baseline\n\nmean_diff = baseline.mean_diff.results['difference'].to_list()\nnp_result = [np.mean(df.iloc[:,i]-df.iloc[:,1]) for i in range(2,6)]\nassert mean_diff == pytest.approx(np_result)\n\ntest_median_diff_baseline\n\nmedian_diff = baseline.median_diff.results['difference'].to_list()\nnp_result = [np.median(df.iloc[:,i]-df.iloc[:,1]) for i in range(2,6)]\nassert median_diff == pytest.approx(np_result)\n\ntest_cohens_d_sequential\n\ncohens_d = sequential.cohens_d.results['difference'].to_list()\nnp_result = [np.mean(df.iloc[:,i+1]-df.iloc[:,i])\n                /np.sqrt((np.var(df.iloc[:,i+1], ddof=1)+np.var(df.iloc[:,i], ddof=1))/2) \n            for i in range(1,5)]\nassert cohens_d == pytest.approx(np_result)\n\ntest_hedges_g_sequential\n\nfrom math import gamma\nhedges_g = sequential.hedges_g.results['difference'].to_list()\na = 47*2-2\nfac = gamma(a/2)/(np.sqrt(a/2)*gamma((a-1)/2))\nnp_result = [np.mean(df.iloc[:,i+1]-df.iloc[:,i])*fac\n                /np.sqrt((np.var(df.iloc[:,i+1], ddof=1)+np.var(df.iloc[:,i], ddof=1))/2) \n            for i in range(1,5)] \nassert hedges_g == pytest.approx(np_result)\n\ntest_cohens_d_baseline\n\ncohens_d = baseline.cohens_d.results['difference'].to_list()\nnp_result = [np.mean(df.iloc[:,i]-df.iloc[:,1])\n                /np.sqrt((np.var(df.iloc[:,i], ddof=1)+np.var(df.iloc[:,1], ddof=1))/2) \n            for i in range(2,6)]\nassert cohens_d == pytest.approx(np_result)\n\ntest_hedges_g_baseline\n\nfrom math import gamma\nhedges_g = baseline.hedges_g.results['difference'].to_list()\na = 47*2-2\nfac = gamma(a/2)/(np.sqrt(a/2)*gamma((a-1)/2))\nnp_result = [np.mean(df.iloc[:,i]-df.iloc[:,1])*fac\n                /np.sqrt((np.var(df.iloc[:,i], ddof=1)+np.var(df.iloc[:,1], ddof=1))/2) \n            for i in range(2,6)]\nassert hedges_g == pytest.approx(np_result)\n\ntest_paired_stats_sequential\n\nnp_result = sequential.mean_diff.results\n    \np1 = [sp.stats.ttest_rel(df.iloc[:,i], df.iloc[:,i+1], nan_policy='omit').pvalue\n            for i in range(1,5)] \nassert np_result[\"pvalue_paired_students_t\"].to_list() == pytest.approx(p1)\n\np2 = [sp.stats.wilcoxon(df.iloc[:,i], df.iloc[:,i+1]).pvalue\n            for i in range(1,5)] \nassert np_result[\"pvalue_wilcoxon\"].to_list() == pytest.approx(p2)\n\ntest_paired_stats_baseline\n\nnp_result = baseline.mean_diff.results\n    \np1 = [sp.stats.ttest_rel(df.iloc[:,1], df.iloc[:,i], nan_policy='omit').pvalue\n            for i in range(2,6)] \nassert np_result[\"pvalue_paired_students_t\"].to_list() == pytest.approx(p1)\n\np2 = [sp.stats.wilcoxon(df.iloc[:,1], df.iloc[:,i]).pvalue\n            for i in range(2,6)] \nassert np_result[\"pvalue_wilcoxon\"].to_list() == pytest.approx(p2)\n\ntest_lqrt_paired_sequential\n\nlqrt_result = sequential.mean_diff.lqrt[\"pvalue_paired_lqrt\"].to_list()\n                             \np1 = [lqrt.lqrtest_rel(df.iloc[:,i], df.iloc[:,i+1], random_state=12345).pvalue\n            for i in range(1,5)] \n\nassert lqrt_result == pytest.approx(p1)\n\ntest_lqrt_paired_baseline\n\nlqrt_result = baseline.mean_diff.lqrt[\"pvalue_paired_lqrt\"].to_list()\n                             \np1 = [lqrt.lqrtest_rel(df.iloc[:,1], df.iloc[:,i], random_state=12345).pvalue\n            for i in range(2,6)] \n\nassert lqrt_result == pytest.approx(p1)"
  },
  {
    "objectID": "tests/test_08_mini_meta_pvals.html",
    "href": "tests/test_08_mini_meta_pvals.html",
    "title": "dabest",
    "section": "",
    "text": "import numpy as np\nimport pytest\n\n\n\nfrom dabest._stats_tools import effsize\nfrom dabest._stats_tools import confint_2group_diff as ci2g\nfrom dabest import Dabest, PermutationTest\nfrom data.mocked_data_test_08 import df_mini_meta, rep1_yes, rep1_no, rep2_yes, rep2_no, N, dabest_default_kwargs\n\nPre-compiling numba functions for DABEST...\n\n\nCompiling numba functions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00&lt;00:00, 41.81it/s]\n\n\nNumba compilation complete!\n\n\n\n\n\n\nunpaired = Dabest(data = df_mini_meta, idx =((\"Rep1_No\", \"Rep1_Yes\"), \n                                             (\"Rep2_No\", \"Rep2_Yes\")), \n                                             mini_meta=True,\n                                             **dabest_default_kwargs)\n\nunpaired.mean_diff.mini_meta.bootstraps_var\n\narray([ 1.51539707, 10.22387374])\n\n\ntest_mean_diff\n\nmean_diff = unpaired.mean_diff.results['difference'].to_list()\nnp_result = [np.mean(rep1_yes)-np.mean(rep1_no), \n             np.mean(rep2_yes)-np.mean(rep2_no)]\nassert mean_diff == pytest.approx(np_result)\n\ntest_pooled_variances\n\nmini_meta_delta = unpaired.mean_diff.mini_meta\n\ncontrol_var    = mini_meta_delta.control_var\nnp_control_var = [np.var(rep1_no, ddof=1),\n                  np.var(rep2_no, ddof=1)]\nassert control_var == pytest.approx(np_control_var)\n\ntest_var    = mini_meta_delta.test_var\nnp_test_var = [np.var(rep1_yes, ddof=1),\n               np.var(rep2_yes, ddof=1)]\nassert test_var == pytest.approx(np_test_var)\n\ngroup_var    = mini_meta_delta.group_var\nnp_group_var = [ci2g.calculate_group_var(control_var[i], mini_meta_delta.control_N[i],\n                                         test_var[i], mini_meta_delta.test_N[i])\n                for i in range(0, 2)]\nassert group_var == pytest.approx(np_group_var)\n\ntest_bootstrap_distribution_variances\n\nbootstrap_distributions = unpaired.mean_diff.mini_meta.bootstraps\nbootstrap_distribution_variances = unpaired.mean_diff.mini_meta.bootstraps_var\n\nnp_bootstrap_distribution_variances = np.array([np.var(x, ddof=1) for x in bootstrap_distributions])\n\nassert bootstrap_distribution_variances == pytest.approx(np_bootstrap_distribution_variances)\n\ntest_weighted_mean_delta\n\ndifference = unpaired.mean_diff.mini_meta.difference\n\nnp_means = np.array([np.mean(rep1_yes)-np.mean(rep1_no), \n            np.mean(rep2_yes)-np.mean(rep2_no)])\n\nnp_var   = np_bootstrap_distribution_variances\n\nnp_difference = effsize.weighted_delta(np_means, np_var)\n\nweight = np.true_divide(1, np_var)\nnp_difference_calc = np.sum(np_means*weight)/np.sum(weight)\n\nassert difference == pytest.approx(np_difference) == pytest.approx(np_difference_calc)\n\n\nmini_meta_delta.permutations_weighted_delta\n\narray([-1.32919358,  1.17274469,  0.51495794, ...,  0.20620551,\n       -2.86746452,  2.19964192])\n\n\ntest_unpaired_permutation_test\n\nmini_meta_delta   = unpaired.mean_diff.mini_meta\npvalue             = mini_meta_delta.pvalue_permutation\npermutations_delta = mini_meta_delta.permutations_weighted_delta\n\nperm_test_1 = PermutationTest(rep1_no, rep1_yes, \n                            effect_size=\"mean_diff\", \n                            is_paired=False)\nperm_test_2 = PermutationTest(rep2_no, rep2_yes, \n                            effect_size=\"mean_diff\", \n                            is_paired=False)\npermutations_1 = perm_test_1.permutations\npermutations_2 = perm_test_2.permutations\npermutations_1_var = perm_test_1.permutations_var\npermutations_2_var = perm_test_2.permutations_var\n\nweight_1 = np.true_divide(1,permutations_1_var)\nweight_2 = np.true_divide(1,permutations_2_var)\n\nweighted_deltas = (weight_1*permutations_1 + weight_2*permutations_2)/(weight_1+weight_2)\nassert permutations_delta == pytest.approx(weighted_deltas)\n\n\nnp_means = [np.mean(rep1_yes)-np.mean(rep1_no), \n            np.mean(rep2_yes)-np.mean(rep2_no)]\n\nnp_weight = np.true_divide(1, np.array([np.var(x, ddof=1) for x in mini_meta_delta.bootstraps]))\n\nnp_difference = np.sum(np_means*np_weight)/np.sum(np_weight)\n\nnp_pvalues = len(list(filter(lambda x: np.abs(x)&gt;np.abs(np_difference), \n                            weighted_deltas)))/len(weighted_deltas)\n\nassert pvalue == pytest.approx(np_pvalues)"
  },
  {
    "objectID": "03-citation.html",
    "href": "03-citation.html",
    "title": "Citing DABEST",
    "section": "",
    "text": "If your publication features a graphic generated with this software library, please cite the following publication.\nMoving beyond P values: Everyday data analysis with estimation plots Joses Ho, Tayfun Tumkaya, Sameer Aryal, Hyungwon Choi, Adam Claridge-Chang\nNature Methods 2019, 1548-7105. doi:10.1038/s41592-019-0470-3\nFree-to-view PDF\nPaywalled publisher site",
    "crumbs": [
      "Get Started",
      "Citing DABEST"
    ]
  },
  {
    "objectID": "blog/posts/bootstraps/bootstraps.html",
    "href": "blog/posts/bootstraps/bootstraps.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "In a typical scientific experiment, we are interested in two populations (Control and Test), and whether there is a difference between their means \\((\\mu_{Test}-\\mu_{Control})\\).\n\nWe go about this by collecting observations from the control population and from the test population.\n\nWe can easily compute the mean difference in our observed samples. This is our estimate of the population effect size that we are interested in.\nBut how do we obtain a measure of the precision and confidence about our estimate? Can we get a sense of how it relates to the population mean difference?"
  },
  {
    "objectID": "blog/posts/bootstraps/bootstraps.html#sampling-from-populations",
    "href": "blog/posts/bootstraps/bootstraps.html#sampling-from-populations",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "In a typical scientific experiment, we are interested in two populations (Control and Test), and whether there is a difference between their means \\((\\mu_{Test}-\\mu_{Control})\\).\n\nWe go about this by collecting observations from the control population and from the test population.\n\nWe can easily compute the mean difference in our observed samples. This is our estimate of the population effect size that we are interested in.\nBut how do we obtain a measure of the precision and confidence about our estimate? Can we get a sense of how it relates to the population mean difference?"
  },
  {
    "objectID": "blog/posts/bootstraps/bootstraps.html#the-bootstrap-confidence-interval",
    "href": "blog/posts/bootstraps/bootstraps.html#the-bootstrap-confidence-interval",
    "title": "Bootstrap Confidence Intervals",
    "section": "The bootstrap confidence interval",
    "text": "The bootstrap confidence interval\nWe want to obtain a 95% confidence interval (95% CI) around our estimate of the mean difference. The 95% indicates that any such confidence interval will capture the population mean difference 95% of the time.\nIn other words, if we were to repeat our experiment 100 times, gathering 100 independent sets of observations and computing a 95% confidence interval for the mean difference each time, 95 of these intervals would capture the population mean difference. That is to say, we can be 95% confident the interval contains the true mean of the population.\nWe can calculate the 95% CI of the mean difference with bootstrap resampling.\n\nThe bootstrap in action\nThe bootstrap[1] is a simple but powerful technique. It was first described by Bradley Efron.\nIt creates multiple resamples (with replacement) from a single set of observations, and computes the effect size of interest on each of these resamples. The bootstrap resamples of the effect size can then be used to determine the 95% CI.\nWith computers, we can perform 5000 resamples very easily.\n\nThe resampling distribution of the difference in means approaches a normal distribution. This is due to the Central Limit Theorem: a large number of independent random samples will approach a normal distribution even if the underlying population is not normally distributed.\nBootstrap resampling gives us two important benefits:\n\nNon-parametric statistical analysis. There is no need to assume that our observations, or the underlying populations, are normally distributed. Thanks to the Central Limit Theorem, the resampling distribution of the effect size will approach a normality.\nEasy construction of the 95% CI from the resampling distribution. In the context of bootstrap resampling or other non-parametric methods, the 2.5th and 97.5th percentiles are often used to define the lower and upper limits, respectively. The use of these percentiles ensures that the resulting interval contains the central 95% of the resampled distribution. Such an interval construction is known as a percentile interval."
  },
  {
    "objectID": "blog/posts/bootstraps/bootstraps.html#adjusting-for-asymmetrical-resampling-distributions",
    "href": "blog/posts/bootstraps/bootstraps.html#adjusting-for-asymmetrical-resampling-distributions",
    "title": "Bootstrap Confidence Intervals",
    "section": "Adjusting for asymmetrical resampling distributions",
    "text": "Adjusting for asymmetrical resampling distributions\nWhile resampling distributions of the difference in means often have a normal distribution, it is not uncommon to encounter a skewed distribution. Thus, Efron developed the bias-corrected and accelerated bootstrap (BCa bootstrap) to account for the skew, and still obtain the central 95% of the distribution.\nDABEST applies the BCa correction to the resampling bootstrap distributions of the effect size."
  },
  {
    "objectID": "blog/posts/bootstraps/bootstraps.html#estimation-plots-incorporate-bootstrap-resampling",
    "href": "blog/posts/bootstraps/bootstraps.html#estimation-plots-incorporate-bootstrap-resampling",
    "title": "Bootstrap Confidence Intervals",
    "section": "Estimation plots incorporate bootstrap resampling",
    "text": "Estimation plots incorporate bootstrap resampling\nThe estimation plot produced by DABEST presents the raw data and the bootstrap confidence interval of the effect size (the difference in means) side-by-side as a single integrated plot.\n\nThus, it tightly couples a visual presentation of the raw data with an indication of the population mean difference plus its confidence interval.\n [1]: The name is derived from the saying ‚Äúpull oneself by one‚Äôs bootstraps‚Äù, often used as an exhortation to achieve success without external help."
  },
  {
    "objectID": "API/delta_objects.html",
    "href": "API/delta_objects.html",
    "title": "Delta objects",
    "section": "",
    "text": "DeltaDelta\n\n DeltaDelta (effectsizedataframe, permutation_count,\n             bootstraps_delta_delta, ci=95)\n\n*A class to compute and store the delta-delta statistics for experiments with a 2-by-2 arrangement where two independent variables, A and B, each have two categorical values, 1 and 2. The data is divided into two pairs of two groups, and a primary delta is first calculated as the mean difference between each of the pairs:\n\\[\\Delta_{1} = \\overline{X}_{A_{2}, B_{1}} - \\overline{X}_{A_{1}, B_{1}}\\]\n\\[\\Delta_{2} = \\overline{X}_{A_{2}, B_{2}} - \\overline{X}_{A_{1}, B_{2}}\\]\nwhere \\(\\overline{X}_{A_{i}, B_{j}}\\) is the mean of the sample with A = i and B = j, \\(\\Delta\\) is the mean difference between two samples.\nA delta-delta value is then calculated as the mean difference between the two primary deltas:\n\\[\\Delta_{\\Delta} = \\Delta_{2} - \\Delta_{1}\\]\nand a delta g value is calculated as the mean difference between the two primary deltas divided by the standard deviation of the delta-delta value, which is calculated from a pooled variance of the 4 samples:\n\\[\\Delta_{g} = \\frac{\\Delta_{\\Delta}}{s_{\\Delta_{\\Delta}}}\\]\n\\[s_{\\Delta_{\\Delta}} = \\sqrt{\\frac{(n_{A_{2}, B_{1}}-1)s_{A_{2}, B_{1}}^2+(n_{A_{1}, B_{1}}-1)s_{A_{1}, B_{1}}^2+(n_{A_{2}, B_{2}}-1)s_{A_{2}, B_{2}}^2+(n_{A_{1}, B_{2}}-1)s_{A_{1}, B_{2}}^2}{(n_{A_{2}, B_{1}} - 1) + (n_{A_{1}, B_{1}} - 1) + (n_{A_{2}, B_{2}} - 1) + (n_{A_{1}, B_{2}} - 1)}}\\]\nwhere \\(s\\) is the standard deviation and \\(n\\) is the sample size.*\nand the standard deviation of the delta-delta value is calculated from a pooled variance of the 4 samples:\n\\[s_{\\Delta_{\\Delta}} = \\sqrt{\\frac{(n_{A_{2}, B_{1}}-1)s_{A_{2}, B_{1}}^2+(n_{A_{1}, B_{1}}-1)s_{A_{1}, B_{1}}^2+(n_{A_{2}, B_{2}}-1)s_{A_{2}, B_{2}}^2+(n_{A_{1}, B_{2}}-1)s_{A_{1}, B_{2}}^2}{(n_{A_{2}, B_{1}} - 1) + (n_{A_{1}, B_{1}} - 1) + (n_{A_{2}, B_{2}} - 1) + (n_{A_{1}, B_{2}} - 1)}}\\]\nwhere \\(s\\) is the standard deviation and \\(n\\) is the sample size.\n\nExample: delta-delta\n\nnp.random.seed(9999) # Fix the seed so the results are replicable.\nN = 20\n# Create samples\ny = norm.rvs(loc=3, scale=0.4, size=N*4)\ny[N:2*N] = y[N:2*N]+1\ny[2*N:3*N] = y[2*N:3*N]-0.5\n# Add a `Treatment` column\nt1 = np.repeat('Placebo', N*2).tolist()\nt2 = np.repeat('Drug', N*2).tolist()\ntreatment = t1 + t2 \n# Add a `Rep` column as the first variable for the 2 replicates of experiments done\nrep = []\nfor i in range(N*2):\n    rep.append('Rep1')\n    rep.append('Rep2')\n# Add a `Genotype` column as the second variable\nwt = np.repeat('W', N).tolist()\nmt = np.repeat('M', N).tolist()\nwt2 = np.repeat('W', N).tolist()\nmt2 = np.repeat('M', N).tolist()\ngenotype = wt + mt + wt2 + mt2\n# Add an `id` column for paired data plotting.\nid = list(range(0, N*2))\nid_col = id + id \n# Combine all columns into a DataFrame.\ndf_delta2 = pd.DataFrame({'ID'        : id_col,\n                  'Rep'      : rep,\n                   'Genotype'  : genotype, \n                   'Treatment': treatment,\n                   'Y'         : y\n                })\nunpaired_delta2 = dabest.load(data = df_delta2, x = [\"Genotype\", \"Genotype\"], y = \"Y\", delta2 = True, experiment = \"Treatment\")\nunpaired_delta2.mean_diff.plot();\n\nC:\\Users\\maiyi\\anaconda3\\Lib\\site-packages\\dabest\\plot_tools.py:2537: UserWarning: 5.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\nC:\\Users\\maiyi\\anaconda3\\Lib\\site-packages\\dabest\\plot_tools.py:2537: UserWarning: 5.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\nC:\\Users\\maiyi\\anaconda3\\Lib\\site-packages\\dabest\\plot_tools.py:2537: UserWarning: 20.0% of the points cannot be placed. You might want to decrease the size of the markers.\n  warnings.warn(err)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiniMetaDelta\n\n MiniMetaDelta (effectsizedataframe, permutation_count, ci=95)\n\nA class to compute and store the weighted delta. A weighted delta is calculated if the argument mini_meta=True is passed during dabest.load().\nThe weighted delta is calcuated as follows:\n\\[\\theta_{\\text{weighted}} = \\frac{\\Sigma\\hat{\\theta_{i}}w_{i}}{{\\Sigma}w_{i}}\\]\nwhere:\n\\[\\hat{\\theta_{i}} = \\text{Mean difference for replicate }i\\]\n\\[w_{i} = \\text{Weight for replicate }i = \\frac{1}{s_{i}^2} \\]\n\\[s_{i}^2 = \\text{Pooled variance for replicate }i = \\frac{(n_{test}-1)s_{test}^2+(n_{control}-1)s_{control}^2}{n_{test}+n_{control}-2}\\]\n\\[n = \\text{sample size and }s^2 = \\text{variance for control/test.}\\]\n\nExample: mini-meta-delta\n\nNs = 20\nc1 = norm.rvs(loc=3, scale=0.4, size=Ns)\nc2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\nc3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\nt1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\nt2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\nt3 = norm.rvs(loc=3, scale=0.75, size=Ns)\nmy_df   = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n                   'Control 2' : c2,     'Test 2' : t2,\n                   'Control 3' : c3,     'Test 3' : t3})\nmy_dabest_object = dabest.load(my_df, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), mini_meta=True)\nmy_dabest_object.mean_diff.mini_meta\n\nDABEST v2025.03.27\n==================\n                  \nGood afternoon!\nThe current time is Mon Sep  1 16:03:47 2025.\n\nThe weighted-average unpaired mean differences is 0.0336 [95%CI -0.136, 0.236].\nThe p-value of the two-sided permutation t-test is 0.736, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\n\nAs of version 2023.02.14, weighted delta can only be calculated for mean difference, and not for standardized measures such as Cohen‚Äôs d.\nDetails about the calculated weighted delta are accessed as attributes of the mini_meta class. See the minimetadelta for details on usage.\nRefer to Chapter 10 of the Cochrane handbook for further information on meta-analysis: https://training.cochrane.org/handbook/current/chapter-10",
    "crumbs": [
      "Get Started",
      "API",
      "Delta objects"
    ]
  },
  {
    "objectID": "API/bootstrap.html",
    "href": "API/bootstrap.html",
    "title": "Bootstrap",
    "section": "",
    "text": "bootstrap\n\n bootstrap (x1:&lt;built-infunctionarray&gt;, x2:&lt;built-infunctionarray&gt;=None,\n            paired:bool=False, stat_function:&lt;built-\n            infunctioncallable&gt;=&lt;function mean at 0x7f07ed12f4b0&gt;,\n            smoothboot:bool=False, alpha_level:float=0.05, reps:int=5000)\n\nComputes the summary statistic and a bootstrapped confidence interval.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx1\narray\n\nThe data in a one-dimensional array form. Only x1 is required. If x2 is given, the bootstrapped summary difference between the two groups (x2-x1) is computed. NaNs are automatically discarded.\n\n\nx2\narray\nNone\nThe data in a one-dimensional array form. Only x1 is required. If x2 is given, the bootstrapped summary difference between the two groups (x2-x1) is computed. NaNs are automatically discarded.\n\n\npaired\nbool\nFalse\nWhether or not x1 and x2 are paired samples. If ‚Äòpaired‚Äô is None then the data will not be treated as paired data in the subsequent calculations. If ‚Äòpaired‚Äô is ‚Äòbaseline‚Äô, then in each tuple of x, other groups will be paired up with the first group (as control). If ‚Äòpaired‚Äô is ‚Äòsequential‚Äô, then in each tuple of x, each group will be paired up with the previous group (as control).\n\n\nstat_function\ncallable\nmean\nThe summary statistic called on data.\n\n\nsmoothboot\nbool\nFalse\nTaken from seaborn.algorithms.bootstrap. If True, performs a smoothed bootstrap (draws samples from a kernel destiny estimate).\n\n\nalpha_level\nfloat\n0.05\nDenotes the likelihood that the confidence interval produced does not include the true summary statistic. When alpha = 0.05, a 95% confidence interval is produced.\n\n\nreps\nint\n5000\nNumber of bootstrap iterations to perform.\n\n\nReturns\nAn bootstrap object reporting the summary statistics, percentile CIs, bias-corrected and accelerated (BCa) CIs, and the settings used:\n\nsummary: float. The summary statistic.is_difference: boolean. Whether or not the summary is the difference between two groups. If False, only x1 was supplied.is_paired: string, default None The type of the experiment under which the data are obtainedstatistic: callable The function used to compute the summary.reps: int The number of bootstrap iterations performed.stat_array:array A sorted array of values obtained by bootstrapping the input arrays.ci:float The size of the confidence interval reported (in percentage).pct_ci_low,pct_ci_high:floats The upper and lower bounds of the confidence interval as computed by taking the percentage bounds.pct_low_high_indices:array An array with the indices in stat_array corresponding to the percentage confidence interval bounds.bca_ci_low, bca_ci_high: floats The upper and lower bounds of the bias-corrected and accelerated(BCa) confidence interval. See Efron 1977.bca_low_high_indices: array An array with the indices in stat_array corresponding to the BCa confidence interval bounds.pvalue_1samp_ttest: float P-value obtained from scipy.stats.ttest_1samp. If 2 arrays were passed (x1 and x2), returns ‚ÄòNIL‚Äô. See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_1samp.htmlpvalue_2samp_ind_ttest: float P-value obtained from scipy.stats.ttest_ind. If a single array was given (x1 only), or if paired is not None, returns ‚ÄòNIL‚Äô. See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_ind.htmlpvalue_2samp_related_ttest: float P-value obtained from scipy.stats.ttest_rel. If a single array was given (x1 only), or if paired is None, returns ‚ÄòNIL‚Äô. See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_rel.htmlpvalue_wilcoxon: float P-value obtained from scipy.stats.wilcoxon. If a single array was given (x1 only), or if paired is None, returns ‚ÄòNIL‚Äô. The Wilcoxons signed-rank test is a nonparametric paired test of the null hypothesis that the related samples x1 and x2 are from the same distribution. See https://docs.scipy.org/doc/scipy-1.0.0/reference/scipy.stats.wilcoxon.htmlpvalue_mann_whitney: float Two-sided p-value obtained from scipy.stats.mannwhitneyu. If a single array was given (x1 only), returns ‚ÄòNIL‚Äô. The Mann-Whitney U-test is a nonparametric unpaired test of the null hypothesis that x1 and x2 are from the same distribution. See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.mannwhitneyu.html\n\n\n\n\n\n\nbca\n\n bca (data, alphas, stat_array, stat_function, ostat, reps)\n\nSubroutine called to calculate the BCa statistics. Borrowed heavily from scikits.bootstrap code.\n\n\n\njackknife_indexes\n\n jackknife_indexes (data)\n\n*From the scikits.bootstrap package. Given an array, returns a list of arrays where each array is a set of jackknife indexes.\nFor a given set of data Y, the jackknife sample J[i] is defined as the data set Y with the ith data point deleted.*",
    "crumbs": [
      "Get Started",
      "API",
      "Bootstrap"
    ]
  },
  {
    "objectID": "API/effsize.html",
    "href": "API/effsize.html",
    "title": "effsize",
    "section": "",
    "text": "source\n\ntwo_group_difference\n\n two_group_difference (control:list|tuple|numpy.ndarray,\n                       test:list|tuple|numpy.ndarray, is_paired=None,\n                       effect_size:str='mean_diff')\n\n*Computes the following metrics for control and test:\n- Unstandardized mean difference\n- Standardized mean differences (paired or unpaired)\n    * Cohen's d\n    * Hedges' g\n- Median difference\n- Cliff's Delta\n- Cohen's h (distance between two proportions)\nSee the Wikipedia entry here\neffect_size:\nmean_diff:      This is simply the mean of `control` subtracted from\n                the mean of `test`.\n\ncohens_d:       This is the mean of control subtracted from the\n                mean of test, divided by the pooled standard deviation\n                of control and test. The pooled SD is the square as:\n\n                       (n1 - 1) * var(control) + (n2 - 1) * var(test)\n                sqrt (   -------------------------------------------  )\n                                         (n1 + n2 - 2)\n\n                where n1 and n2 are the sizes of control and test\n                respectively.\n\nhedges_g:       This is Cohen's d corrected for bias via multiplication\n                 with the following correction factor:\n\n                                gamma(n/2)\n                J(n) = ------------------------------\n                       sqrt(n/2) * gamma((n - 1) / 2)\n\n                where n = (n1 + n2 - 2).\n\nmedian_diff:    This is the median of `control` subtracted from the\n                median of `test`.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncontrol\nlist | tuple | numpy.ndarray\n\nAccepts lists, tuples, or numpy ndarrays of numeric types.\n\n\ntest\nlist | tuple | numpy.ndarray\n\nAccepts lists, tuples, or numpy ndarrays of numeric types.\n\n\nis_paired\nNoneType\nNone\nIf not None, returns the paired Cohen‚Äôs d\n\n\neffect_size\nstr\nmean_diff\nAny one of the following effect sizes: [‚Äúmean_diff‚Äù, ‚Äúmedian_diff‚Äù, ‚Äúcohens_d‚Äù, ‚Äúhedges_g‚Äù, ‚Äúcliffs_delta‚Äù]\n\n\nReturns\nfloat\n\nThe desired effect size.\n\n\n\n\nsource\n\n\nfunc_difference\n\n func_difference (control:list|tuple|numpy.ndarray,\n                  test:list|tuple|numpy.ndarray, func, is_paired:str)\n\nApplies func to control and test, and then returns the difference.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncontrol\nlist | tuple | numpy.ndarray\nNaNs are automatically discarded.\n\n\ntest\nlist | tuple | numpy.ndarray\nNaNs are automatically discarded.\n\n\nfunc\n\nSummary function to apply.\n\n\nis_paired\nstr\nIf not None, computes func(test - control). If None, computes func(test) - func(control).\n\n\nReturns\nfloat\n\n\n\n\n\nsource\n\n\ncohens_d\n\n cohens_d (control:list|tuple|numpy.ndarray,\n           test:list|tuple|numpy.ndarray, is_paired:str=None)\n\n*Computes Cohen‚Äôs d for test v.s. control. See here\nIf is_paired is None, returns:\n\\[\n\\frac{\\bar{X}_2 - \\bar{X}_1}{s_{pooled}}\n\\]\nwhere\n\\[\ns_{pooled} = \\sqrt{\\frac{(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2}{n_1 + n_2 - 2}}\n\\]\nIf is_paired is not None, returns:\n\\[\n\\frac{\\bar{X}_2 - \\bar{X}_1}{s_{avg}}\n\\]\nwhere\n\\[\ns_{avg} = \\sqrt{\\frac{s_1^2 + s_2^2}{2}}\n\\]\nNotes:\n\nThe sample variance (and standard deviation) uses N-1 degrees of freedoms. This is an application of Bessel‚Äôs correction, and yields the unbiased sample variance.\n\nReferences:\n- https://en.wikipedia.org/wiki/Bessel%27s_correction\n- https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncontrol\nlist | tuple | numpy.ndarray\n\n\n\n\ntest\nlist | tuple | numpy.ndarray\n\n\n\n\nis_paired\nstr\nNone\nIf not None, the paired Cohen‚Äôs d is returned.\n\n\nReturns\nfloat\n\n\n\n\n\n\nsource\n\n\ncohens_h\n\n cohens_h (control:list|tuple|numpy.ndarray,\n           test:list|tuple|numpy.ndarray)\n\n*Computes Cohen‚Äôs h for test v.s. control. See here for reference.\nNotes:\n\nAssuming the input data type is binary, i.e.¬†a series of 0s and 1s, and a dict for mapping the 0s and 1s to the actual labels, e.g.{1: ‚ÄúSmoker‚Äù, 0: ‚ÄúNon-smoker‚Äù}*\n\n\nsource\n\n\nhedges_g\n\n hedges_g (control:list|tuple|numpy.ndarray,\n           test:list|tuple|numpy.ndarray, is_paired:str=None)\n\n*Computes Hedges‚Äô g for for test v.s. control. It first computes Cohen‚Äôs d, then calulates a correction factor based on the total degress of freedom using the gamma function.\nSee here*\n\nsource\n\n\ncliffs_delta\n\n cliffs_delta (control:list|tuple|numpy.ndarray,\n               test:list|tuple|numpy.ndarray)\n\nComputes Cliff‚Äôs delta for 2 samples. See here\n\nsource\n\n\nweighted_delta\n\n weighted_delta (difference, bootstrap_dist_var)\n\nCompute the weighted deltas where the weight is the inverse of the pooled group difference.",
    "crumbs": [
      "Get Started",
      "API",
      "effsize"
    ]
  },
  {
    "objectID": "API/confint_1group.html",
    "href": "API/confint_1group.html",
    "title": "confint_1group",
    "section": "",
    "text": "source\n\nsummary_ci_1group\n\n summary_ci_1group (x:&lt;built-infunctionarray&gt;, func, resamples:int=5000,\n                    alpha:float=0.05, random_seed:int=12345,\n                    sort_bootstraps:bool=True, *args, **kwargs)\n\nGiven an array-like x, returns func(x), and a bootstrap confidence interval of func(x).\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\narray\n\nAn numerical iterable.\n\n\nfunc\n\n\nThe function to be applied to x.\n\n\nresamples\nint\n5000\nThe number of bootstrap resamples to be taken of func(x).\n\n\nalpha\nfloat\n0.05\nDenotes the likelihood that the confidence interval produced does not include the true summary statistic. When alpha = 0.05, a 95% confidence interval is produced.\n\n\nrandom_seed\nint\n12345\nrandom_seed is used to seed the random number generator during bootstrap resampling. This ensures that the confidence intervals reported are replicable.\n\n\nsort_bootstraps\nbool\nTrue\n\n\n\nargs\nVAR_POSITIONAL\n\n\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\nReturns\nA dictionary with the following five keys:\n\nsummary: float. The outcome of func(x).func: function. The function applied to x.bca_ci_low: floatbca_ci_high: float. The bias-corrected and accelerated confidence interval, for the given alpha.bootstraps: array. The bootstraps used to generate the confidence interval. These will be sorted in ascending order if sort_bootstraps was True.\n\n\n\n\nsource\n\n\ncompute_1group_bias_correction\n\n compute_1group_bias_correction (x, bootstraps, func, *args, **kwargs)\n\n\nsource\n\n\ncompute_1group_bootstraps\n\n compute_1group_bootstraps (x, func, resamples=5000, random_seed=12345,\n                            *args, **kwargs)\n\nBootstraps func(x), with the number of specified resamples.\n\nsource\n\n\ncompute_1group_acceleration\n\n compute_1group_acceleration (jack_dist)\n\nReturns the accaleration value based on the jackknife distribution.\n\nsource\n\n\ncompute_1group_jackknife\n\n compute_1group_jackknife (x, func, *args, **kwargs)\n\nReturns the jackknife bootstraps for func(x).\n\nsource\n\n\ncreate_bootstrap_indexes\n\n create_bootstrap_indexes (array, resamples=5000, random_seed=12345)\n\nGiven an array-like, returns a generator of bootstrap indexes to be used for resampling.",
    "crumbs": [
      "Get Started",
      "API",
      "confint_1group"
    ]
  },
  {
    "objectID": "API/confint_2group_diff.html",
    "href": "API/confint_2group_diff.html",
    "title": "confint_2group_diff",
    "section": "",
    "text": "source\n\ncalculate_weighted_delta\n\n calculate_weighted_delta (bootstrap_dist_var, differences)\n\nCompute the weighted deltas.\n\nsource\n\n\ncalculate_bootstraps_var\n\n calculate_bootstraps_var (bootstraps)\n\n\nsource\n\n\ncalculate_group_var\n\n calculate_group_var (control_var, control_N, test_var, test_N)\n\n\nsource\n\n\ncompute_interval_limits\n\n compute_interval_limits (bias, acceleration, n_boots, ci=95)\n\n*Returns the indexes of the interval limits for a given bootstrap.\nSupply the bias, acceleration factor, and number of bootstraps.*\n\nsource\n\n\ncompute_meandiff_bias_correction\n\n compute_meandiff_bias_correction (bootstraps, effsize)\n\nComputes the bias correction required for the BCa method of confidence interval construction.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nbootstraps\n\nAn numerical iterable, comprising bootstrap resamples of the effect size.\n\n\neffsize\n\nThe effect size for the original sample.\n\n\nReturns\nbias: numeric\nThe bias correction value for the given bootstrapsand effect size.\n\n\n\n\nsource\n\n\ncompute_delta2_bootstrapped_diff\n\n compute_delta2_bootstrapped_diff (x1:numpy.ndarray, x2:numpy.ndarray,\n                                   x3:numpy.ndarray, x4:numpy.ndarray,\n                                   is_paired:str=None, resamples:int=5000,\n                                   random_seed:int=12345,\n                                   proportional:bool=False)\n\nBootstraps the effect size deltas‚Äô g or proportional delta-delta\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx1\nndarray\n\nControl group 1\n\n\nx2\nndarray\n\nTest group 1\n\n\nx3\nndarray\n\nControl group 2\n\n\nx4\nndarray\n\nTest group 2\n\n\nis_paired\nstr\nNone\n\n\n\nresamples\nint\n5000\n\n\n\nrandom_seed\nint\n12345\n\n\n\nproportional\nbool\nFalse\n\n\n\nReturns\ntuple\n\n\n\n\n\n\nsource\n\n\ndelta2_bootstrap_loop\n\n delta2_bootstrap_loop (x1, x2, x3, x4, resamples, pooled_sd, rng_seed,\n                        is_paired, proportional=False)\n\nCompute bootstrapped differences for delta-delta, handling both regular and proportional data\n\nsource\n\n\ncompute_bootstrapped_diff\n\n compute_bootstrapped_diff (x0, x1, is_paired, effect_size,\n                            resamples=5000, random_seed=12345)\n\nBootstraps the effect_size for 2 groups.\n\nsource\n\n\nbootstrap_indices\n\n bootstrap_indices (is_paired, x0_len, x1_len, resamples, random_seed)\n\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\nis_paired\n\n\n\nx0_len\n\n\n\nx1_len\n\n\n\nresamples\n\n\n\nrandom_seed\nparallelization must be turned off for random number generation\n\n\n\n\nsource\n\n\ncompute_meandiff_jackknife\n\n compute_meandiff_jackknife (x0, x1, is_paired, effect_size)\n\nGiven two arrays, returns the jackknife for their effect size.\n\nsource\n\n\ncreate_repeated_indexes\n\n create_repeated_indexes (data)\n\nConvenience function. Given an array-like with length N, returns a generator that yields N indexes [0, 1, ‚Ä¶, N].\n/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Keywords\n  else: warn(msg)\n\nsource\n\n\ncreate_jackknife_indexes\n\n create_jackknife_indexes (data)\n\n*Given an array-like, creates a jackknife bootstrap.\nFor a given set of data Y, the jackknife bootstrap sample J[i] is defined as the data set Y with the ith data point deleted.*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndata\n\n\n\n\nReturns\nGenerator that yields all jackknife bootstrap samples.",
    "crumbs": [
      "Get Started",
      "API",
      "confint_2group_diff"
    ]
  },
  {
    "objectID": "API/multi.html",
    "href": "API/multi.html",
    "title": "multi",
    "section": "",
    "text": "The MultiContrast class enables visualization of multiple contrast objects in grid-based layouts.\n\nsource\n\n\n\n MultiContrast (dabest_objs:Union[List,List[List]],\n                labels:Optional[List[str]]=None,\n                row_labels:Optional[List[str]]=None,\n                effect_size:str='mean_diff', ci_type:str='bca')\n\n*Unified multiple contrast object for forest plots and whorlmaps.\nTakes raw dabest objects and provides validated, processed data for downstream visualizations.*",
    "crumbs": [
      "Get Started",
      "API",
      "multi"
    ]
  },
  {
    "objectID": "API/multi.html#multicontrast-class",
    "href": "API/multi.html#multicontrast-class",
    "title": "multi",
    "section": "",
    "text": "The MultiContrast class enables visualization of multiple contrast objects in grid-based layouts.\n\nsource\n\n\n\n MultiContrast (dabest_objs:Union[List,List[List]],\n                labels:Optional[List[str]]=None,\n                row_labels:Optional[List[str]]=None,\n                effect_size:str='mean_diff', ci_type:str='bca')\n\n*Unified multiple contrast object for forest plots and whorlmaps.\nTakes raw dabest objects and provides validated, processed data for downstream visualizations.*",
    "crumbs": [
      "Get Started",
      "API",
      "multi"
    ]
  },
  {
    "objectID": "API/multi.html#loading-function",
    "href": "API/multi.html#loading-function",
    "title": "multi",
    "section": "Loading Function",
    "text": "Loading Function\n\nsource\n\ncombine\n\n combine (dabest_objs:Union[List,List[List]],\n          labels:Optional[List[str]]=None,\n          row_labels:Optional[List[str]]=None,\n          effect_size:str='mean_diff', ci_type:str='bca',\n          allow_mixed_types:bool=False)\n\n*Create a MultiContrast object from raw dabest objects.\nThis is the main entry point that users should use to create multi-contrast visualizations.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndabest_objs\nUnion\n\nRaw dabest objects in 1D or 2D structure\n\n\nlabels\nOptional\nNone\nLabels for dabest_objs\n\n\nrow_labels\nOptional\nNone\n\n\n\neffect_size\nstr\nmean_diff\nEffect size to extract\n\n\nci_type\nstr\nbca\nConfidence interval type\n\n\nallow_mixed_types\nbool\nFalse\nIf True, allows different contrast types in different rows (whorlmap only)If False, enforces homogeneous types (forest_plot compatible)\n\n\nReturns\nMultiContrast\n\nValidated multi-contrast object ready for visualization",
    "crumbs": [
      "Get Started",
      "API",
      "multi"
    ]
  },
  {
    "objectID": "API/multi.html#whorlmap-visualization",
    "href": "API/multi.html#whorlmap-visualization",
    "title": "multi",
    "section": "Whorlmap Visualization",
    "text": "Whorlmap Visualization\nThe whorlmap creates spiral heatmaps showing the distribution of bootstrap samples for each contrast.\n\nsource\n\nwhorlmap\n\n whorlmap (multi_contrast, n=21, sort_by=None, cmap='vlag', vmax=None,\n           vmin=None, reverse_neg=True, abs_rank=False, chop_tail=0,\n           ax=None, fig_size=None, title=None, heatmap_kwargs=None,\n           plot_kwargs=None)\n\nCreate a whorlmap visualization of multiple contrasts.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmulti_contrast\nMultiContrast\n\nObject containing multiple dabest objects\n\n\nn\nint\n21\nSize of each spiral (n x n grid per contrast)\n\n\nsort_by\nNoneType\nNone\nOrder to sort contrasts by\n\n\ncmap\nstr\nvlag\n\n\n\nvmax\nNoneType\nNone\n\n\n\nvmin\nNoneType\nNone\n\n\n\nreverse_neg\nbool\nTrue\nWhether to reverse negative values\n\n\nabs_rank\nbool\nFalse\nWhether to rank by absolute value\n\n\nchop_tail\nint\n0\nPercentage of extreme values to exclude\n\n\nax\nNoneType\nNone\nExisting axes to plot on\n\n\nfig_size\nNoneType\nNone\nFigure size (width, height) in inches\n\n\ntitle\nNoneType\nNone\nPlot title\n\n\nheatmap_kwargs\nNoneType\nNone\nAdditional keyword arguments passed to sns.heatmap().Common options include:- ‚Äòcmap‚Äô: colormap (overrides direct cmap parameter)- ‚Äòvmin‚Äô, ‚Äòvmax‚Äô: color scale limits (override direct parameters)- ‚Äòcenter‚Äô: center value for colormap- ‚Äòannot‚Äô: whether to annotate cells with values- ‚Äòfmt‚Äô: format string for annotations- ‚Äòlinewidths‚Äô: width of lines between cells- ‚Äòlinecolor‚Äô: color of lines between cells- ‚Äòcbar‚Äô: whether to show colorbar- ‚Äòcbar_kws‚Äô: colorbar customization dict- ‚Äòsquare‚Äô: whether to make cells square- ‚Äòxticklabels‚Äô, ‚Äòyticklabels‚Äô: tick label control- ‚Äòmask‚Äô: boolean array to mask cells\n\n\nplot_kwargs\nNoneType\nNone\nAdditional keyword arguments for plot styling and layout.Available options (WIP):- ‚Äòtitle‚Äô: plot title- ‚Äòxlabel‚Äô, ‚Äòylabel‚Äô: axis labels- ‚Äòxticklabels‚Äô, ‚Äòyticklabels‚Äô: tick labels- ‚Äòxticklabels_rotation‚Äô, ‚Äòyticklabels_rotation‚Äô: tick label rotation angles- ‚Äòxticklabels_ha‚Äô, ‚Äòyticklabels_ha‚Äô: horizontal alignment",
    "crumbs": [
      "Get Started",
      "API",
      "multi"
    ]
  },
  {
    "objectID": "API/plotter.html",
    "href": "API/plotter.html",
    "title": "Plot",
    "section": "",
    "text": "source\n\neffectsize_df_plotter\n\n effectsize_df_plotter (effectsize_df:object, **plot_kwargs)\n\n*Custom function that creates an estimation plot from an EffectSizeDataFrame. Keywords ‚Äî‚Äî‚Äì Parameters ‚Äî‚Äî‚Äî- effectsize_df A dabest EffectSizeDataFrame object. plot_kwargs color_col=None raw_marker_size=6, contrast_marker_kwargs=9, raw_label=None, contrast_label=None, delta2_label=None, raw_ylim=None, contrast_ylim=None, delta2_ylim=None, custom_palette=None, swarm_side=None, empty_circle=False, face_color=None, raw_desat=0.5, contrast_desat=1, raw_alpha=None, contrast_alpha=0.8, bar_width = 0.5, ci_type=‚Äòbca‚Äô, float_contrast=True, show_pairs=True, show_sample_size=True, show_delta2=True, show_mini_meta=True, group_summaries=‚Äúmean_sd‚Äù, fig_size=None, dpi=100, ax=None, swarmplot_kwargs=None, slopegraph_kwargs=None, barplot_kwargs=None, sankey_kwargs=None, contrast_kwargs=None, reflines_kwargs=None, group_summaries_kwargs=None, legend_kwargs=None, title=None, fontsize_title=16, fontsize_rawxlabel=12, fontsize_rawylabel=12, fontsize_contrastxlabel=12, fontsize_contrastylabel=12, fontsize_delta2label=12,\nraw_bars=True, raw_bars_kwargs=None, contrast_bars=True, contrast_bars_kwargs=None, reference_band=None, reference_band_kwargs=None, delta_text=True, delta_text_kwargs=None, delta_dot=True, delta_dot_kwargs=None,\nhorizontal=False, horizontal_table_kwargs=None, gridkey=None, gridkey_merge_pairs=False, gridkey_show_Ns=True, gridkey_show_es=True, gridkey_delimiters=[‚Äò;‚Äô, ‚Äò&gt;‚Äô, ‚Äô_‚Äô], gridkey_kwargs=None, contrast_marker_kwargs=None, contrast_errorbar_kwargs=None, prop_sample_counts=False, prop_sample_counts_kwargs=None, contrast_paired_lines=True, contrast_paired_lines show_baseline_ec=False,*\nFor details on how to control the aesthetic of the generated estimation plot by modifying the plot_kwargs, please refer to Controlling Plot Aesthetics\n\neffectsize_df: A dabest EffectSizeDataFrame object.\nplot_kwargs:\n\ncolor_col=None\nraw_marker_size=6, contrast_marker_size=9,\nraw_label=None, contrast_label=None, delta2_label=None,\nraw_ylim=None, contrast_ylim=None, delta2_ylim=None,\ncustom_palette=None, swarm_side=None, empty_circle=False,\nface_color = None,\nraw_desat=0.5, contrast_desat=1,\nraw_alpha=None, contrast_alpha=0.8,\nbar_width=0.5,\nci_type=‚Äòbca‚Äô,\nfloat_contrast=True,\nshow_pairs=True,\nshow_sample_size=True\nshow_delta2=True, show_mini_meta=True,\ngroup_summaries=‚Äúmean_sd‚Äù,\nfig_size=None, dpi=100,\nax=None,\nswarmplot_kwargs=None,\nslopegraph_kwargs=None,\nbarplot_kwargs=None,\nsankey_kwargs=None,\ncontrast_kwargs=None,\nreflines_kwargs=None,\ngroup_summaries_kwargs=None,\nlegend_kwargs=None,\ntitle=None, fontsize_title=16,\nfontsize_rawxlabel=12, fontsize_rawylabel=12,\nfontsize_contrastxlabel=12, fontsize_contrastylabel=12,\nfontsize_delta2label=12,\nraw_bars=True, raw_bars_kwargs=None,\ncontrast_bars=True, contrast_bars_kwargs=None,\nreference_band=None, reference_band_kwargs=None,\ndelta_text=True, delta_text_kwargs=None,\ndelta_dot=True, delta_dot_kwargs=None,\nhorizontal=False, horizontal_table_kwargs=None,\ngridkey=None, gridkey_merge_pairs=False,\ngridkey_show_Ns=True, gridkey_show_es=True,\ngridkey_delimiters=[‚Äò;‚Äô, ‚Äò&gt;‚Äô, ‚Äô_‚Äô],\ngridkey_kwargs=None,\ncontrast_marker_kwargs=None, contrast_errorbar_kwargs=None\nprop_sample_counts=False, prop_sample_counts_kwargs=None\ncontrast_paired_lines=True, contrast_paired_lines_kwargs=None,\nshow_baseline_ec=False",
    "crumbs": [
      "Get Started",
      "API",
      "Plot"
    ]
  },
  {
    "objectID": "API/dabest_object.html",
    "href": "API/dabest_object.html",
    "title": "Dabest object",
    "section": "",
    "text": "Dabest\n\n Dabest (data, idx, x, y, paired, id_col, ci, resamples, random_seed,\n         proportional, delta2, experiment, experiment_label, x1_level,\n         mini_meta, ps_adjust)\n\nClass for estimation statistics and plots.\n\nExample: mean_diff\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest    = norm.rvs(loc=0.5, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.mean_diff\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:38 2025.\n\nThe unpaired mean difference between control and test is 0.5 [95%CI 0.00172, 1.04].\nThe p-value of the two-sided permutation t-test is 0.0758, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.mean_diff.statistical_tests`\n\n\nThis is simply the mean of the control group subtracted from the mean of the test group.\n\\[\\text{Mean difference} = \\overline{x}_{Test} - \\overline{x}_{Control}\\]\nwhere \\(\\overline{x}\\) is the mean for the group \\(x\\).\n\n\nExample: median_diff\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest    = norm.rvs(loc=0.5, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.median_diff\n\n/Users/jonathananns/GitHub/DABEST-python/dabest/_stats_tools/effsize.py:82: UserWarning: Using median as the statistic in bootstrapping may result in a biased estimate and cause problems with BCa confidence intervals. Consider using a different statistic, such as the mean.\nWhen plotting, please consider using percetile confidence intervals by specifying `ci_type='pct'`. For detailed information, refer to https://github.com/ACCLAB/DABEST-python/issues/129 \n\n  warnings.warn(message=mes1+mes2, category=UserWarning)\n\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:39 2025.\n\nThe unpaired median difference between control and test is 0.5 [95%CI -0.0401, 1.04].\nThe p-value of the two-sided permutation t-test is 0.103, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.median_diff.statistical_tests`\n\n\nThis is the median difference between the control group and the test group.\nIf the comparison(s) are unpaired, median_diff is computed with the following equation:\n\\[\\text{Median difference} = \\widetilde{x}_{Test} - \\widetilde{x}_{Control}\\]\nwhere \\(\\widetilde{x}\\) is the median for the group \\(x\\).\nIf the comparison(s) are paired, median_diff is computed with the following equation:\n\\[\\text{Median difference} = \\widetilde{x}_{Test - Control}\\]\n\nThings to note\nUsing median difference as the statistic in bootstrapping may result in a biased estimate and cause problems with BCa confidence intervals. Consider using mean difference instead.\nWhen plotting, consider using percentile confidence intervals instead of BCa confidence intervals by specifying ci_type = 'percentile' in .plot().\nFor detailed information, please refer to Issue 129.\n\n\n\nExample: cohens_d\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest    = norm.rvs(loc=0.5, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.cohens_d\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:39 2025.\n\nThe unpaired Cohen's d between control and test is 0.471 [95%CI -0.0405, 0.973].\nThe p-value of the two-sided permutation t-test is 0.0758, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.cohens_d.statistical_tests`\n\n\nCohen‚Äôs d is simply the mean of the control group subtracted from the mean of the test group.\nIf paired is None, then the comparison(s) are unpaired; otherwise the comparison(s) are paired.\nIf the comparison(s) are unpaired, Cohen‚Äôs d is computed with the following equation:\n\\[d = \\frac{\\overline{x}_{Test} - \\overline{x}_{Control}} {\\text{pooled standard deviation}}\\]\nFor paired comparisons, Cohen‚Äôs d is given by\n\\[d = \\frac{\\overline{x}_{Test} - \\overline{x}_{Control}} {\\text{average standard deviation}}\\]\nwhere \\(\\overline{x}\\) is the mean of the respective group of observations, \\({Var}_{x}\\) denotes the variance of that group,\n\\[\\text{pooled standard deviation} = \\sqrt{ \\frac{(n_{control} - 1) * {Var}_{control} + (n_{test} - 1) * {Var}_{test} } {n_{control} + n_{test} - 2} }\\]\nand\n\\[\\text{average standard deviation} = \\sqrt{ \\frac{{Var}_{control} + {Var}_{test}} {2}}\\]\nThe sample variance (and standard deviation) uses N-1 degrees of freedoms. This is an application of Bessel‚Äôs correction, and yields the unbiased sample variance.\nReferences:\nhttps://en.wikipedia.org/wiki/Effect_size#Cohen's_d\nhttps://en.wikipedia.org/wiki/Bessel%27s_correction\nhttps://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n\n\nExample: cohens_h\n\ncontrol = randint.rvs(0, 2, size=30, random_state=12345)\ntest    = randint.rvs(0, 2, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.cohens_h\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:41 2025.\n\nThe unpaired Cohen's h between control and test is 0.0 [95%CI -0.563, 0.474].\nThe p-value of the two-sided permutation t-test is 0.799, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.cohens_h.statistical_tests`\n\n\nCohen‚Äôs h uses the information of proportion in the control and test groups to calculate the distance between two proportions.\nIt can be used to describe the difference between two proportions as ‚Äúsmall‚Äù, ‚Äúmedium‚Äù, or ‚Äúlarge‚Äù.\nIt can be used to determine if the difference between two proportions is ‚Äúmeaningful‚Äù.\nA directional Cohen‚Äôs h is computed with the following equation:\n\\[h = 2 * \\arcsin{\\sqrt{proportion_{Test}}} - 2 * \\arcsin{\\sqrt{proportion_{Control}}}\\]\nFor a non-directional Cohen‚Äôs h, the equation is:\n\\[h = |2 * \\arcsin{\\sqrt{proportion_{Test}}} - 2 * \\arcsin{\\sqrt{proportion_{Control}}}|\\]\nReferences:\nhttps://en.wikipedia.org/wiki/Cohen%27s_h\n\n\nExample: hedges_g\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest    = norm.rvs(loc=0.5, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.hedges_g\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:41 2025.\n\nThe unpaired Hedges' g between control and test is 0.465 [95%CI -0.04, 0.96].\nThe p-value of the two-sided permutation t-test is 0.0758, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.hedges_g.statistical_tests`\n\n\nHedges‚Äô g is cohens_d corrected for bias via multiplication with the following correction factor:\n\\[\\frac{ \\Gamma( \\frac{a} {2} )} {\\sqrt{ \\frac{a} {2} } \\times \\Gamma( \\frac{a - 1} {2} )}\\]\nwhere\n\\[a = {n}_{control} + {n}_{test} - 2\\]\nand \\(\\Gamma(x)\\) is the Gamma function.\nReferences:\nhttps://en.wikipedia.org/wiki/Effect_size#Hedges'_g\nhttps://journals.sagepub.com/doi/10.3102/10769986006002107\n\n\nExample: cliffs_delta\n\ncontrol = norm.rvs(loc=0, size=30, random_state=12345)\ntest    = norm.rvs(loc=0.5, size=30, random_state=12345)\nmy_df   = pd.DataFrame({\"control\": control,\n                            \"test\": test})\nmy_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\nmy_dabest_object.cliffs_delta\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:41 2025.\n\nThe unpaired Cliff's delta between control and test is 0.28 [95%CI -0.0111, 0.544].\nThe p-value of the two-sided permutation t-test is 0.061, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing theeffect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.cliffs_delta.statistical_tests`\n\n\nCliff‚Äôs delta is a measure of ordinal dominance, ie. how often the values from the test sample are larger than values from the control sample.\n\\[\\text{Cliff's delta} = \\frac{\\#({x}_{test} &gt; {x}_{control}) - \\#({x}_{test} &lt; {x}_{control})} {{n}_{Test} \\times {n}_{Control}}\\]\nwhere \\(\\#\\) denotes the number of times a value from the test sample exceeds (or is lesser than) values in the control sample.\nCliff‚Äôs delta ranges from -1 to 1; it can also be thought of as a measure of the degree of overlap between the two samples. An attractive aspect of this effect size is that it does not make an assumptions about the underlying distributions that the samples were drawn from.\nReferences:\nhttps://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data\nhttps://psycnet.apa.org/record/1994-08169-001\n\n\nExample: delta_g via hedges_g\n\nrandom.seed(12345) # Fix the seed so the results are replicable.\nN=20\ny = norm.rvs(loc=3, scale=0.4, size=N*4)\ny[N:2*N] = y[N:2*N]+1\ny[2*N:3*N] = y[2*N:3*N]-0.5\nt1 = repeat('Placebo', N*2).tolist()\nt2 = repeat('Drug', N*2).tolist()\ntreatment = t1 + t2\nrep = []\nfor i in range(N*2):\n    rep.append('Rep1')\n    rep.append('Rep2')\nwt = repeat('W', N).tolist()\nmt = repeat('M', N).tolist()\nwt2 = repeat('W', N).tolist()\nmt2 = repeat('M', N).tolist()\ngenotype = wt + mt + wt2 + mt2\nid = list(range(0, N*2))\nid_col = id + id\ndf_delta2 = pd.DataFrame({'ID'        : id_col,\n                          'Rep'      : rep,\n                          'Genotype'  : genotype,\n                          'Treatment': treatment,\n                          'Y'         : y})\nunpaired_delta2 = dabest.load(data = df_delta2, x = [\"Genotype\", \"Genotype\"], y = \"Y\", delta2 = True, experiment = \"Treatment\")\nunpaired_delta2.hedges_g\n\nDABEST v2025.03.27\n==================\n                  \nGood morning!\nThe current time is Tue Mar 25 10:08:42 2025.\n\nThe unpaired Hedges' g between W Placebo and M Placebo is 1.74 [95%CI 1.09, 2.33].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe unpaired Hedges' g between W Drug and M Drug is 1.33 [95%CI 0.632, 1.98].\nThe p-value of the two-sided permutation t-test is 0.0, calculated for legacy purposes only. \n\nThe delta g between Placebo and Drug is -0.651 [95%CI -1.53, 0.21].\nThe p-value of the two-sided permutation t-test is 0.0694, calculated for legacy purposes only. \n\n5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.\nAny p-value reported is the probability of observing the effect size (or greater),\nassuming the null hypothesis of zero difference is true.\nFor each p-value, 5000 reshuffles of the control and test labels were performed.\n\nTo get the results of all valid statistical tests, use `.hedges_g.statistical_tests`\n\n\nDelta g is an effect size that only applied on experiments with a 2-by-2 arrangement where two independent variables, A and B, each have two categorical values, 1 and 2, which calculates hedges_g for delta-delta statistics.\n\\[\\Delta_{1} = \\overline{X}_{A_{2}, B_{1}} - \\overline{X}_{A_{1}, B_{1}}\\]\n\\[\\Delta_{2} = \\overline{X}_{A_{2}, B_{2}} - \\overline{X}_{A_{1}, B_{2}}\\]\nwhere \\(\\overline{X}_{A_{i}, B_{j}}\\) is the mean of the sample with A = i and B = j, \\(\\Delta\\) is the mean difference between two samples.\nA delta-delta value is then calculated as the mean difference between the two primary deltas:\n\\[\\Delta_{\\Delta} = \\Delta_{2} - \\Delta_{1}\\]\nand the standard deviation of the delta-delta value is calculated from a pooled variance of the 4 samples:\n\\[s_{\\Delta_{\\Delta}} = \\sqrt{\\frac{(n_{A_{2}, B_{1}}-1)s_{A_{2}, B_{1}}^2+(n_{A_{1}, B_{1}}-1)s_{A_{1}, B_{1}}^2+(n_{A_{2}, B_{2}}-1)s_{A_{2}, B_{2}}^2+(n_{A_{1}, B_{2}}-1)s_{A_{1}, B_{2}}^2}{(n_{A_{2}, B_{1}} - 1) + (n_{A_{1}, B_{1}} - 1) + (n_{A_{2}, B_{2}} - 1) + (n_{A_{1}, B_{2}} - 1)}}\\]\nwhere \\(s\\) is the standard deviation and \\(n\\) is the sample size.\nA delta g value is then calculated as delta-delta value divided by pooled standard deviation \\(s_{\\Delta_{\\Delta}}\\):\n\\(\\Delta_{g} = \\frac{\\Delta_{\\Delta}}{s_{\\Delta_{\\Delta}}}\\)",
    "crumbs": [
      "Get Started",
      "API",
      "Dabest object"
    ]
  }
]