<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>dabest</title>
<link>https://acclab.github.io/DABEST-python/blog/</link>
<atom:link href="https://acclab.github.io/DABEST-python/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Data Analysis and Visualization using Bootstrap-Coupled Estimation.</description>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Mon, 20 Oct 2025 08:29:10 GMT</lastBuildDate>
<item>
  <title>Robust and Beautiful Statistical Visualization</title>
  <link>https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust-beautiful.html</link>
  <description><![CDATA[ 




<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="current-plots-do-not-work" class="level2">
<h2 class="anchored" data-anchor-id="current-plots-do-not-work">Current plots do not work</h2>
<p>What is data visualization? Battle-Baptiste and Rusert (2018) give a cogent and compelling definition:</p>
<p><code>Data visualization</code>[1] is the rendering of information in a visual format to help communicate data while also generating new patterns and knowledge through the act of visualization itself.</p>
<p>Sadly, too many figures and visualizations in modern academic publications seemingly fail to “generate new patterns and knowledge through the act of visualization itself”. Here, we propose a solution: <em>the estimation plot</em>.</p>
<section id="the-barplot-conceals-the-underlying-shape" class="level3">
<h3 class="anchored" data-anchor-id="the-barplot-conceals-the-underlying-shape">The barplot conceals the underlying shape</h3>
<p>By only displaying the mean and standard deviation, barplots do not accurately represent the underlying distribution of the data.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_5_1.png" class="img-fluid"></p>
<p>In the above figure, four different samples with wildly different distributions–as seen in the swarmplot on the left panel–look exactly the same when visualized with a barplot on the right panel. (You can download the <a href="four_samples.csv">dataset</a> to see for yourself.)</p>
<p>We’re not the first ones (see these articles: <a href="https://www.nature.com/articles/nmeth.2837">article 1</a>, <a href="http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002128">article 2</a>, or <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/ejn.13400">article 3</a>) to point out the barplot’s fatal flaws. Indeed, it is both sobering and fascinating to realise that the barplot is a <a href="https://en.wikipedia.org/wiki/Bar_chart#History">17th century invention</a> initially used to compare single values, not to compare summarized and aggregated data.</p>
</section>
<section id="the-boxplot-does-not-convey-sample-size" class="level3">
<h3 class="anchored" data-anchor-id="the-boxplot-does-not-convey-sample-size">The boxplot does not convey sample size</h3>
<p>Boxplots are another widely used visualization tool. They arguably do include more information for each sample (medians, quartiles, maxima, minima, and outliers), but they do not convey to the viewer the size of each sample.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_7_1.png" class="img-fluid"></p>
<p>The figure above visualizes the same four samples as a swarmplot (left panel) and as a boxplot. If we did not label the x-axis with the sample size, it would be impossible to definitively distinguish the sample with 5 observations from the sample with 50.</p>
<p>Even if the world gets rid of barplots and boxplots, the problems plaguing statistical practices will remain unsolved. Null-hypothesis significance testing–the dominant statistical paradigm in basic research–does not indicate the <strong>effect size</strong>, or its <strong>confidence interval</strong>.</p>
</section>
</section>
<section id="introducing-the-estimation-plot" class="level2">
<h2 class="anchored" data-anchor-id="introducing-the-estimation-plot">Introducing the Estimation Plot</h2>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_9_0.png" class="img-fluid"></p>
<p>This is a <em>Gardner-Altman</em> estimation plot. The plot draws its name from <a href="https://www.independent.co.uk/news/people/obituary-professor-martin-gardner-1470261.html">Martin J. Gardner</a> and <a href="https://www.bmj.com/content/361/bmj.k2588">Douglas Altman</a>, who are credited with <a href="https://www.bmj.com/content/bmj/292/6522/746.full.pdf">creating the design</a> in 1986.</p>
<p>This plot has two key features:</p>
<ol type="1">
<li><p>It presents all data points as a swarmplot, ordering each point to display the underlying distribution.</p></li>
<li><p>It presents the effect size as a <em>bootstrap 95% confidence interval</em> (95% CI) on a separate but aligned axis. The effect size is displayed to the right of the raw data, and the mean of the test group is aligned with the effect size.”</p></li>
</ol>
<div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #31708f; background-color: #d9edf7; border-color: #bce8f1;">
Thus, estimation plots are robust, beautiful, and convey important statistical information elegantly and efficiently.
</div>
<p>An estimation plot obtains and displays the 95% CI through nonparametric bootstrap resampling. This enables visualization of the confidence interval as a graded sampling distribution.</p>
<p>This is one important difference between estimation plots created by DABEST, and the original Gardner-Altman design. Here, the 95% CI is computed through parametric methods, and displayed as a vertical error bar.</p>
<p>Read more about this technique at <a href="../../../blog/posts/bootstraps/bootstraps.html">bootstraps</a>.</p>
<section id="introducing-estimation-statistics" class="level3">
<h3 class="anchored" data-anchor-id="introducing-estimation-statistics">Introducing Estimation Statistics</h3>
<p>Estimation plots emerge from <em>estimation statistics</em>, a simple <a href="https://thenewstatistics.com/itns/">framework</a> that avoids the <a href="https://www.nature.com/articles/nmeth.3288">pitfalls of significance testing</a>. It focuses on the effect sizes of one’s experiment/interventions, and uses familiar statistical concepts: means, mean differences, and error bars.</p>
<p>Significance testing calculates the probability (the <em>P</em> value) that the experimental data would be observed, if the intervention did not produce a change in the metric measured (i.e.&nbsp;the null hypothesis). This leads analysts to apply a false dichotomy on the experimental intervention.</p>
<p>Estimation statistics, on the other hand, focuses on the magnitude of the effect (the effect size) and its precision. This encourages analysts to gain a deeper understanding of the metrics used, and how they relate to the natural processes being studied.</p>
</section>
</section>
<section id="an-estimation-plot-for-every-experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="an-estimation-plot-for-every-experimental-design">An Estimation Plot For Every Experimental Design</h2>
<p>For each of the most routine significance tests, there is an estimation replacement:</p>
<section id="unpaired-students-t-test-two-group-estimation-plot" class="level3">
<h3 class="anchored" data-anchor-id="unpaired-students-t-test-two-group-estimation-plot">Unpaired Student’s t-test –&gt; Two-group estimation plot</h3>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_12_0.png" class="img-fluid"></p>
</section>
<section id="paired-students-t-test-paired-estimation-plot" class="level3">
<h3 class="anchored" data-anchor-id="paired-students-t-test-paired-estimation-plot">Paired Student’s t-test –&gt; Paired estimation plot</h3>
<p>The Gardner-Altman estimation plot can also display effect sizes for repeated measures (aka a paired experimental design) using a <a href="http://charliepark.org/slopegraphs/">Tufte slopegraph</a> instead of a swarmplot.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_14_0.png" class="img-fluid"></p>
</section>
<section id="one-way-anova-multiple-comparisons-multi-two-group-estimation-plot" class="level3">
<h3 class="anchored" data-anchor-id="one-way-anova-multiple-comparisons-multi-two-group-estimation-plot">One-way ANOVA + multiple comparisons –&gt; Multi two-group estimation plot</h3>
<p>For comparisons between three or more groups that typically employ analysis of variance (ANOVA) methods, one can use the <a href="https://en.wikipedia.org/wiki/Estimation_statistics#Cumming_plot">Cumming estimation plot</a>, named after <a href="https://www.youtube.com/watch?v=nDN-hcKR7j8">Geoff Cumming</a>, and draws its design heavily from his 2012 textbook <a href="https://www.routledge.com/Understanding-The-New-Statistics-Effect-Sizes-Confidence-Intervals-and/Cumming/p/book/9780415879682">“Understanding the New Statistics”</a>. This estimation plot design can be considered a variant of the Gardner-Altman plot.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_16_0.png" class="img-fluid"></p>
<p>The effect size and 95% CIs are still plotted on a separate axis, but unlike the Gardner-Altman plot, this axis is positioned beneath the raw data.</p>
<p>Such a design frees up visual space in the upper panel, allowing the display of summary measurements (mean ± standard deviation) for each group. These are shown as gapped lines to the right of each group. The mean of each group is indicated as a gap in the line, adhering to Edward Tufte’s dictum to <a href="https://medium.com/@plotlygraphs/maximizing-the-data-ink-ratio-in-dashboards-and-slide-deck-7887f7c1fab">keep the data-ink ratio low</a>.</p>
</section>
<section id="repeated-measures-anova-multi-paired-estimation-plot" class="level3">
<h3 class="anchored" data-anchor-id="repeated-measures-anova-multi-paired-estimation-plot">Repeated measures ANOVA –&gt; Multi paired estimation plot</h3>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_19_0.png" class="img-fluid"></p>
</section>
<section id="ordered-groups-anova-shared-control-estimation-plot" class="level3">
<h3 class="anchored" data-anchor-id="ordered-groups-anova-shared-control-estimation-plot">Ordered groups ANOVA –&gt; Shared-control estimation plot</h3>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust_21_0.png" class="img-fluid"></p>
</section>
<section id="estimation-plots-the-way-forward" class="level3">
<h3 class="anchored" data-anchor-id="estimation-plots-the-way-forward">Estimation Plots: The Way Forward</h3>
<p>In summary, estimation plots offer five key benefits relative to conventional plots:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Barplot</th>
<th>Boxplot</th>
<th>Estimation Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Displays all observed values</td>
<td>NO</td>
<td>NO</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Avoids false dichotomy</td>
<td>NO</td>
<td>NO</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Focusses on effect size</td>
<td>NO</td>
<td>NO</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>Visualizes effect size precision</td>
<td>NO</td>
<td>NO</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>Shows mean difference distribution</td>
<td>NO</td>
<td>NO</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p>You can create estimation plots using the DABEST (Data Analysis with Bootstrap Estimation) packages, which are available in <a href="https://github.com/ACCLAB/DABEST-Matlab">Matlab</a>, <a href="https://github.com/ACCLAB/DABEST-python">Python</a>, and <a href="https://github.com/ACCLAB/dabestr">R</a>.</p>
<p><a id="1"></a> <code>[1]</code>:<a href="https://www.papress.com/html/product.details.dna?isbn=9781616897062">W. E. B. Du Bois’s Data Portraits: Visualizing Black America</a>. Edited by Whitney Battle-Baptiste and Britt Rusert, Princeton Architectural Press, 2018</p>


</section>
</section>

 ]]></description>
  <guid>https://acclab.github.io/DABEST-python/blog/posts/robust-beautiful/robust-beautiful.html</guid>
  <pubDate>Mon, 20 Oct 2025 08:29:10 GMT</pubDate>
</item>
<item>
  <title>Bootstrap Confidence Intervals</title>
  <link>https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstraps.html</link>
  <description><![CDATA[ 




<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="sampling-from-populations" class="level2">
<h2 class="anchored" data-anchor-id="sampling-from-populations">Sampling from populations</h2>
<p>In a typical scientific experiment, we are interested in two populations (Control and Test), and whether there is a difference between their means <img src="https://latex.codecogs.com/png.latex?(%5Cmu_%7BTest%7D-%5Cmu_%7BControl%7D)">.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstrap-1.png" class="img-fluid"></p>
<p>We go about this by collecting observations from the control population and from the test population.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstrap-2.png" class="img-fluid"></p>
<p>We can easily compute the mean difference in our observed samples. This is our estimate of the population effect size that we are interested in.</p>
<p><strong>But how do we obtain a measure of the precision and confidence about our estimate? Can we get a sense of how it relates to the population mean difference?</strong></p>
</section>
<section id="the-bootstrap-confidence-interval" class="level2">
<h2 class="anchored" data-anchor-id="the-bootstrap-confidence-interval">The bootstrap confidence interval</h2>
<p>We want to obtain a 95% confidence interval (95% CI) around our estimate of the mean difference. The 95% indicates that any such confidence interval will capture the population mean difference 95% of the time.</p>
<p>In other words, if we were to repeat our experiment 100 times, gathering 100 independent sets of observations and computing a 95% confidence interval for the mean difference each time, 95 of these intervals would capture the population mean difference. That is to say, we can be 95% confident the interval contains the true mean of the population.</p>
<p>We can calculate the 95% CI of the mean difference with <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap resampling</a>.</p>
<section id="the-bootstrap-in-action" class="level3">
<h3 class="anchored" data-anchor-id="the-bootstrap-in-action">The bootstrap in action</h3>
<p>The <code>bootstrap</code>[1] is a simple but powerful technique. It was <a href="https://projecteuclid.org/euclid.aos/1176344552">first described</a> by <a href="https://statistics.stanford.edu/people/bradley-efron">Bradley Efron</a>.</p>
<p>It creates multiple <em>resamples</em> (with replacement) from a single set of observations, and computes the effect size of interest on each of these resamples. The bootstrap resamples of the effect size can then be used to determine the 95% CI.</p>
<p>With computers, we can perform 5000 resamples very easily.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstrap-3.png" class="img-fluid"></p>
<p>The resampling distribution of the difference in means approaches a normal distribution. This is due to the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a>: a large number of independent random samples will approach a normal distribution even if the underlying population is not normally distributed.</p>
<p>Bootstrap resampling gives us two important benefits:</p>
<ol type="1">
<li><p><em>Non-parametric statistical analysis.</em> There is no need to assume that our observations, or the underlying populations, are normally distributed. Thanks to the Central Limit Theorem, the resampling distribution of the effect size will approach a normality.</p></li>
<li><p><em>Easy construction of the 95% CI from the resampling distribution.</em> In the context of bootstrap resampling or other non-parametric methods, the 2.5th and 97.5th percentiles are often used to define the lower and upper limits, respectively. The use of these percentiles ensures that the resulting interval contains the central 95% of the resampled distribution. Such an interval construction is known as a <em>percentile interval</em>.</p></li>
</ol>
</section>
</section>
<section id="adjusting-for-asymmetrical-resampling-distributions" class="level2">
<h2 class="anchored" data-anchor-id="adjusting-for-asymmetrical-resampling-distributions">Adjusting for asymmetrical resampling distributions</h2>
<p>While resampling distributions of the difference in means often have a normal distribution, it is not uncommon to encounter a skewed distribution. Thus, Efron developed the <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#History">bias-corrected and accelerated bootstrap</a> (BCa bootstrap) to account for the skew, and still obtain the central 95% of the distribution.</p>
<p><strong>DABEST</strong> applies the BCa correction to the resampling bootstrap distributions of the effect size.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstrap-4.png" class="img-fluid"></p>
</section>
<section id="estimation-plots-incorporate-bootstrap-resampling" class="level2">
<h2 class="anchored" data-anchor-id="estimation-plots-incorporate-bootstrap-resampling">Estimation plots incorporate bootstrap resampling</h2>
<p>The estimation plot produced by DABEST presents the raw data and the bootstrap confidence interval of the effect size (the difference in means) side-by-side as a single integrated plot.</p>
<p><img src="https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstrap-5.png" class="img-fluid"></p>
<p>Thus, it tightly couples a visual presentation of the raw data with an indication of the population mean difference plus its confidence interval.</p>
<p><a id="1"></a> <code>[1]</code>: The name is derived from the saying “<a href="https://en.wiktionary.org/wiki/pull_oneself_up_by_one%27s_bootstraps">pull oneself by one’s bootstraps</a>”, often used as an exhortation to achieve success without external help.</p>


</section>

 ]]></description>
  <guid>https://acclab.github.io/DABEST-python/blog/posts/bootstraps/bootstraps.html</guid>
  <pubDate>Mon, 20 Oct 2025 08:29:10 GMT</pubDate>
</item>
</channel>
</rss>
