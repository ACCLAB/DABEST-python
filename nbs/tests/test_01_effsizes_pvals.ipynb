{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import lqrt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9abde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dabest._stats_tools import effsize\n",
    "from dabest import Dabest, TwoGroupsEffectSize, PermutationTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.mocked_data_test_01 import wellbeing, paired_wellbeing, smoke, likert_control, likert_treatment, a_scores, b_scores, dabest_default_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443abc1",
   "metadata": {},
   "source": [
    "test_mean_diff_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = effsize.func_difference(wellbeing.control, wellbeing.expt,\n",
    "                                    np.mean, is_paired=False)\n",
    "assert mean_diff == pytest.approx(5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34f114",
   "metadata": {},
   "source": [
    "test_median_diff_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_diff = effsize.func_difference(wellbeing.control, wellbeing.expt,\n",
    "                                    np.median, is_paired=False)\n",
    "assert median_diff == pytest.approx(3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a8f2f",
   "metadata": {},
   "source": [
    "test_mean_diff_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = effsize.func_difference(paired_wellbeing.pre,\n",
    "                                    paired_wellbeing.post,\n",
    "                                    np.mean, is_paired=\"baseline\")\n",
    "assert mean_diff == pytest.approx(4.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c9402",
   "metadata": {},
   "source": [
    "test_median_diff_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_diff = effsize.func_difference(paired_wellbeing.pre,\n",
    "                                      paired_wellbeing.post,\n",
    "                                      np.median, is_paired=\"baseline\")\n",
    "assert median_diff == pytest.approx(4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246036ea",
   "metadata": {},
   "source": [
    "test_cohens_d_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d = effsize.cohens_d(wellbeing.control, wellbeing.expt,\n",
    "                            is_paired=False)\n",
    "assert np.round(cohens_d, 2) == pytest.approx(0.47)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc37dbc",
   "metadata": {},
   "source": [
    "test_hedges_g_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d33c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hedges_g = effsize.hedges_g(wellbeing.control, wellbeing.expt,\n",
    "                                is_paired=False)\n",
    "assert np.round(hedges_g, 2) == pytest.approx(0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd38d44",
   "metadata": {},
   "source": [
    "test_cohens_d_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d = effsize.cohens_d(paired_wellbeing.pre, paired_wellbeing.post,\n",
    "                                is_paired=\"baseline\")\n",
    "assert np.round(cohens_d, 2) == pytest.approx(0.34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a772b30",
   "metadata": {},
   "source": [
    "test_hedges_g_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hedges_g = effsize.hedges_g(paired_wellbeing.pre, paired_wellbeing.post,\n",
    "                            is_paired=\"baseline\")\n",
    "assert np.round(hedges_g, 2) == pytest.approx(0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d5415",
   "metadata": {},
   "source": [
    "test_cohens_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_h = effsize.cohens_h(smoke.low, smoke.high)\n",
    "assert np.round(cohens_h, 2) == pytest.approx(0.17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85935481",
   "metadata": {},
   "source": [
    "test_cliffs_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "likert_delta = effsize.cliffs_delta(likert_treatment, likert_control)\n",
    "assert likert_delta == pytest.approx(-0.25)\n",
    "\n",
    "scores_delta = effsize.cliffs_delta(b_scores, a_scores)\n",
    "assert scores_delta == pytest.approx(0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a50c5",
   "metadata": {},
   "source": [
    "test_unpaired_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16884a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = wellbeing.control\n",
    "t = wellbeing.expt\n",
    "\n",
    "unpaired_es = TwoGroupsEffectSize(c, t, \"mean_diff\", is_paired=False, proportional=False)\n",
    "\n",
    "p1 = sp.stats.mannwhitneyu(c, t, alternative=\"two-sided\").pvalue\n",
    "assert unpaired_es.pvalue_mann_whitney == pytest.approx(p1)\n",
    "\n",
    "p2 = sp.stats.ttest_ind(c, t, nan_policy='omit').pvalue\n",
    "assert unpaired_es.pvalue_students_t == pytest.approx(p2)\n",
    "\n",
    "p3 = sp.stats.ttest_ind(c, t, equal_var=False, nan_policy='omit').pvalue\n",
    "assert unpaired_es.pvalue_welch == pytest.approx(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced5798",
   "metadata": {},
   "source": [
    "test_paired_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be74408",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = paired_wellbeing.pre\n",
    "after = paired_wellbeing.post\n",
    "\n",
    "paired_es = TwoGroupsEffectSize(before, after, \"mean_diff\", is_paired=\"baseline\", proportional=False)\n",
    "\n",
    "p1 = sp.stats.ttest_rel(before, after, nan_policy='omit').pvalue\n",
    "assert paired_es.pvalue_paired_students_t == pytest.approx(p1)\n",
    "\n",
    "p2 = sp.stats.wilcoxon(before, after).pvalue\n",
    "assert paired_es.pvalue_wilcoxon == pytest.approx(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9fb80",
   "metadata": {},
   "source": [
    "test_median_diff_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = wellbeing.control\n",
    "t = wellbeing.expt\n",
    "\n",
    "es = TwoGroupsEffectSize(c, t, \"median_diff\", is_paired=False, proportional=False)\n",
    "\n",
    "p1 = sp.stats.kruskal(c, t, nan_policy='omit').pvalue\n",
    "assert es.pvalue_kruskal == pytest.approx(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5962b",
   "metadata": {},
   "source": [
    "test_ordinal_dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = TwoGroupsEffectSize(likert_control, likert_treatment, \n",
    "                             \"cliffs_delta\", is_paired=False, proportional=False)\n",
    "                             \n",
    "p1 = sp.stats.brunnermunzel(likert_control, likert_treatment).pvalue\n",
    "assert es.pvalue_brunner_munzel == pytest.approx(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34885930",
   "metadata": {},
   "source": [
    "test_unpaired_permutation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_test = PermutationTest(wellbeing.control, wellbeing.expt, \n",
    "                                effect_size=\"mean_diff\", \n",
    "                                is_paired=False)\n",
    "assert perm_test.pvalue == pytest.approx(0.2976)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36603ed",
   "metadata": {},
   "source": [
    "test_paired_permutation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45477ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_test = PermutationTest(paired_wellbeing.pre, \n",
    "                                paired_wellbeing.post, \n",
    "                                effect_size=\"mean_diff\", \n",
    "                                is_paired=\"baseline\")\n",
    "assert perm_test.pvalue == pytest.approx(0.0124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279e7c7",
   "metadata": {},
   "source": [
    "test_lqrt_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a98593",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaired_dabest = Dabest(wellbeing, idx=(\"control\", \"expt\"), \n",
    "                             paired=None, id_col=None, \n",
    "                             **dabest_default_kwargs)\n",
    "lqrt_result = unpaired_dabest.mean_diff.lqrt\n",
    "\n",
    "p1 = lqrt.lqrtest_ind(wellbeing.control, wellbeing.expt,\n",
    "                      equal_var=True,\n",
    "                      random_state=12345)\n",
    "\n",
    "p2 = lqrt.lqrtest_ind(wellbeing.control, wellbeing.expt,\n",
    "                      equal_var=False,\n",
    "                      random_state=12345)\n",
    "\n",
    "assert lqrt_result.pvalue_lqrt_equal_var[0] == pytest.approx(p1.pvalue)\n",
    "assert lqrt_result.pvalue_lqrt_unequal_var[0] == pytest.approx(p2.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63ddff",
   "metadata": {},
   "source": [
    "test_lqrt_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_dabest = Dabest(paired_wellbeing, idx=(\"pre\", \"post\"),\n",
    "                           paired=\"baseline\", id_col=\"ID\",\n",
    "                           **dabest_default_kwargs)\n",
    "lqrt_result = paired_dabest.mean_diff.lqrt\n",
    "\n",
    "p1 = lqrt.lqrtest_rel(paired_wellbeing.pre, paired_wellbeing.post, \n",
    "             random_state=12345)\n",
    "\n",
    "assert lqrt_result.pvalue_paired_lqrt[0] == pytest.approx(p1.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
