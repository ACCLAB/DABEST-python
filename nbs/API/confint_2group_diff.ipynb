{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebadf154",
   "metadata": {},
   "source": [
    "# confint_2group_diff\n",
    "\n",
    "> A range of functions to compute bootstraps for the mean difference \n",
    "between two groups.\n",
    "\n",
    "- order: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77004140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _stats_tools/confint_2group_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f96815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa733643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def create_jackknife_indexes(data):\n",
    "    \"\"\"\n",
    "    Given an array-like, creates a jackknife bootstrap.\n",
    "\n",
    "    For a given set of data Y, the jackknife bootstrap sample J[i]\n",
    "    is defined as the data set Y with the ith data point deleted.\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    data: array-like\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Generator that yields all jackknife bootstrap samples.\n",
    "    \"\"\"\n",
    "    from numpy import arange, delete\n",
    "\n",
    "    index_range = arange(0, len(data))\n",
    "    return (delete(index_range, i) for i in index_range)\n",
    "\n",
    "\n",
    "\n",
    "def create_repeated_indexes(data):\n",
    "    \"\"\"\n",
    "    Convenience function. Given an array-like with length N,\n",
    "    returns a generator that yields N indexes [0, 1, ..., N].\n",
    "    \"\"\"\n",
    "    from numpy import arange\n",
    "\n",
    "    index_range = arange(0, len(data))\n",
    "    return (index_range for i in index_range)\n",
    "\n",
    "\n",
    "\n",
    "def _create_two_group_jackknife_indexes(x0, x1, is_paired):\n",
    "    \"\"\"Creates the jackknife bootstrap for 2 groups.\"\"\"\n",
    "\n",
    "    if is_paired and len(x0) == len(x1):\n",
    "        out = list(zip([j for j in create_jackknife_indexes(x0)],\n",
    "                       [i for i in create_jackknife_indexes(x1)]\n",
    "                       )\n",
    "                   )\n",
    "    else:\n",
    "        jackknife_c = list(zip([j for j in create_jackknife_indexes(x0)],\n",
    "                               [i for i in create_repeated_indexes(x1)]\n",
    "                              )\n",
    "                          )\n",
    "\n",
    "        jackknife_t = list(zip([i for i in create_repeated_indexes(x0)],\n",
    "                               [j for j in create_jackknife_indexes(x1)]\n",
    "                              )\n",
    "                          )\n",
    "        out = jackknife_c + jackknife_t\n",
    "        del jackknife_c\n",
    "        del jackknife_t\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def compute_meandiff_jackknife(x0, x1, is_paired, effect_size):\n",
    "    \"\"\"\n",
    "    Given two arrays, returns the jackknife for their effect size.\n",
    "    \"\"\"\n",
    "    from . import effsize as __es\n",
    "\n",
    "    jackknives = _create_two_group_jackknife_indexes(x0, x1, is_paired)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for j in jackknives:\n",
    "        x0_shuffled = x0[j[0]]\n",
    "        x1_shuffled = x1[j[1]]\n",
    "\n",
    "        es = __es.two_group_difference(x0_shuffled, x1_shuffled,\n",
    "                                       is_paired, effect_size)\n",
    "        out.append(es)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def _calc_accel(jack_dist):\n",
    "    from numpy import mean as npmean\n",
    "    from numpy import sum as npsum\n",
    "    from numpy import errstate\n",
    "\n",
    "    jack_mean = npmean(jack_dist)\n",
    "\n",
    "    numer = npsum((jack_mean - jack_dist)**3)\n",
    "    denom = 6.0 * (npsum((jack_mean - jack_dist)**2) ** 1.5)\n",
    "\n",
    "    with errstate(invalid='ignore'):\n",
    "        # does not raise warning if invalid division encountered.\n",
    "        return numer / denom\n",
    "\n",
    "\n",
    "def compute_bootstrapped_diff(x0, x1, is_paired, effect_size,\n",
    "                              resamples=5000, random_seed=12345):\n",
    "    \"\"\"Bootstraps the effect_size for 2 groups.\"\"\"\n",
    "    \n",
    "    from . import effsize as __es\n",
    "    import numpy as np\n",
    "    from numpy.random import PCG64, RandomState\n",
    "    \n",
    "    # rng = RandomState(default_rng(random_seed))\n",
    "    rng = RandomState(PCG64(random_seed))\n",
    "\n",
    "    out = np.repeat(np.nan, resamples)\n",
    "    x0_len = len(x0)\n",
    "    x1_len = len(x1)\n",
    "    \n",
    "    for i in range(int(resamples)):\n",
    "        \n",
    "        if is_paired:\n",
    "            if x0_len != x1_len:\n",
    "                raise ValueError(\"The two arrays do not have the same length.\")\n",
    "            random_idx = rng.choice(x0_len, x0_len, replace=True)\n",
    "            x0_sample = x0[random_idx]\n",
    "            x1_sample = x1[random_idx]\n",
    "        else:\n",
    "            x0_sample = rng.choice(x0, x0_len, replace=True)\n",
    "            x1_sample = rng.choice(x1, x1_len, replace=True)\n",
    "            \n",
    "        out[i] = __es.two_group_difference(x0_sample, x1_sample,\n",
    "                                          is_paired, effect_size)\n",
    "    \n",
    "    # check whether there are any infinities in the bootstrap,\n",
    "    # which likely indicates the sample sizes are too small as\n",
    "    # the computation of Cohen's d and Hedges' g necessitated \n",
    "    # a division by zero.\n",
    "    # Added in v0.2.6.\n",
    "    \n",
    "    # num_infinities = len(out[np.isinf(out)])\n",
    "    # print(num_infinities)\n",
    "    # if num_infinities > 0:\n",
    "    #     warn_msg = \"There are {} bootstraps that are not defined. \"\\\n",
    "    #     \"This is likely due to smaple sample sizes. \"\\\n",
    "    #     \"The values in a bootstrap for a group will be more likely \"\\\n",
    "    #     \"to be all equal, with a resulting variance of zero. \"\\\n",
    "    #     \"The computation of Cohen's d and Hedges' g will therefore \"\\\n",
    "    #     \"involved a division by zero. \"\n",
    "    #     warnings.warn(warn_msg.format(num_infinities), category=\"UserWarning\")\n",
    "        \n",
    "    return out\n",
    "\n",
    "def compute_delta2_bootstrapped_diff(x1:np.ndarray,# Control group 1\n",
    "                                     x2:np.ndarray,# Test group 1\n",
    "                                     x3:np.ndarray,# Control group 2\n",
    "                                     x4:np.ndarray,# Test group 2\n",
    "                                     is_paired:str=None,\n",
    "                                     resamples:int=5000, # The number of bootstrap resamples to be taken for the calculation of the confidence interval limits.\n",
    "                                     random_seed:int=12345# `random_seed` is used to seed the random number generator during bootstrap resampling. This ensures that the confidence intervals reported are replicable.\n",
    "                                    )->tuple: # bootstraped result and empirical result of deltas' g, and the bootstraped result of delta-delta\n",
    "    \"\"\"\n",
    "    Bootstraps the effect size deltas' g.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from numpy.random import PCG64, RandomState\n",
    "\n",
    "    rng = RandomState(PCG64(random_seed))\n",
    "    x1_len = len(x1)\n",
    "    x2_len = len(x2)\n",
    "    x3_len = len(x3)\n",
    "    x4_len = len(x4)\n",
    "    out_delta_g = np.repeat(np.nan, resamples)\n",
    "    deltadelta = np.repeat(np.nan, resamples)\n",
    "\n",
    "    n_a1_b1, n_a2_b1, n_a1_b2, n_a2_b2= x1_len, x2_len, x3_len, x4_len\n",
    "    s_a1_b1, s_a2_b1, s_a1_b2, s_a2_b2 = np.std(x1), np.std(x2), np.std(x3), np.std(x4)\n",
    "\n",
    "    sd_numerator = ((n_a2_b1 - 1) * s_a2_b1 ** 2 + (n_a1_b1 - 1) * s_a1_b1 ** 2 + (n_a2_b2 - 1) * s_a2_b2 ** 2 + (\n",
    "            n_a1_b2 - 1) * s_a1_b2 ** 2)\n",
    "    sd_denominator = (n_a2_b1 - 1) + (n_a1_b1 - 1) + (n_a2_b2 - 1) + (n_a1_b2 - 1)\n",
    "    pooled_sample_sd = np.sqrt(sd_numerator / sd_denominator)\n",
    "\n",
    "    for i in range(int(resamples)):\n",
    "        if is_paired:\n",
    "            if (x1_len != x2_len) or (x3_len != x4_len):\n",
    "                raise ValueError(\"The two arrays do not have the same length.\")\n",
    "            df_paired_1 = pd.DataFrame({\n",
    "                'value': np.concatenate([x1, x3]),\n",
    "                'array_id': np.repeat(['x1','x3'], [x1_len, x3_len])\n",
    "            })\n",
    "            df_paired_2 = pd.DataFrame({\n",
    "                'value': np.concatenate([x2, x4]),\n",
    "                'array_id': np.repeat(['x2','x4'], [x1_len, x3_len])\n",
    "            })\n",
    "            x_sample_index = rng.choice(len(df_paired_1), len(df_paired_1), replace=True)\n",
    "            x_sample_1 = df_paired_1.loc[x_sample_index]\n",
    "            x_sample_2 = df_paired_2.loc[x_sample_index]\n",
    "            x1_sample = x_sample_1[x_sample_1['array_id'] == 'x1']['value']\n",
    "            x2_sample = x_sample_2[x_sample_2['array_id'] == 'x2']['value']\n",
    "            x3_sample = x_sample_1[x_sample_1['array_id'] == 'x3']['value']\n",
    "            x4_sample = x_sample_2[x_sample_2['array_id'] == 'x4']['value']\n",
    "        else:\n",
    "            df = pd.DataFrame({\n",
    "                'value': np.concatenate([x1, x2, x3, x4]),\n",
    "                'array_id': np.repeat(['x1', 'x2', 'x3', 'x4'], [x1_len, x2_len, x3_len, x4_len])\n",
    "            })\n",
    "            x_sample_index = rng.choice(len(df),len(df), replace=True)\n",
    "            x_sample = df.loc[x_sample_index]\n",
    "            x1_sample = x_sample[x_sample['array_id'] == 'x1']['value']\n",
    "            x2_sample = x_sample[x_sample['array_id'] == 'x2']['value']\n",
    "            x3_sample = x_sample[x_sample['array_id'] == 'x3']['value']\n",
    "            x4_sample = x_sample[x_sample['array_id'] == 'x4']['value']\n",
    "\n",
    "        delta_1 = np.mean(x2_sample)-np.mean(x1_sample)\n",
    "        delta_2 = np.mean(x4_sample)-np.mean(x3_sample)\n",
    "        delta_delta = delta_2 - delta_1\n",
    "        deltadelta[i] = delta_delta\n",
    "        out_delta_g[i] = delta_delta/pooled_sample_sd\n",
    "    delta_g = ((np.mean(x4)-np.mean(x3)) - (np.mean(x2)-np.mean(x1))) / pooled_sample_sd\n",
    "    return out_delta_g, delta_g, deltadelta\n",
    "\n",
    "\n",
    "\n",
    "def compute_meandiff_bias_correction(bootstraps, #An numerical iterable, comprising bootstrap resamples of the effect size.\n",
    "                                     effsize # The effect size for the original sample.\n",
    "                                    ): #The bias correction value for the given bootstraps and effect size.\n",
    "    \"\"\"\n",
    "    Computes the bias correction required for the BCa method\n",
    "    of confidence interval construction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bias: numeric\n",
    "        The bias correction value for the given bootstraps\n",
    "        and effect size.\n",
    "\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    from numpy import array\n",
    "\n",
    "    B = array(bootstraps)\n",
    "    prop_less_than_es = sum(B < effsize) / len(B)\n",
    "\n",
    "    return norm.ppf(prop_less_than_es)\n",
    "\n",
    "\n",
    "\n",
    "def _compute_alpha_from_ci(ci):\n",
    "    if ci < 0 or ci > 100:\n",
    "        raise ValueError(\"`ci` must be a number between 0 and 100.\")\n",
    "\n",
    "    return (100. - ci) / 100.\n",
    "\n",
    "\n",
    "\n",
    "def _compute_quantile(z, bias, acceleration):\n",
    "    numer = bias + z\n",
    "    denom = 1 - (acceleration * numer)\n",
    "\n",
    "    return bias + (numer / denom)\n",
    "\n",
    "\n",
    "\n",
    "def compute_interval_limits(bias, acceleration, n_boots, ci=95):\n",
    "    \"\"\"\n",
    "    Returns the indexes of the interval limits for a given bootstrap.\n",
    "\n",
    "    Supply the bias, acceleration factor, and number of bootstraps.\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    from numpy import isnan, nan\n",
    "\n",
    "    alpha = _compute_alpha_from_ci(ci)\n",
    "\n",
    "    alpha_low = alpha / 2\n",
    "    alpha_high = 1 - (alpha / 2)\n",
    "\n",
    "    z_low = norm.ppf(alpha_low)\n",
    "    z_high = norm.ppf(alpha_high)\n",
    "\n",
    "    kws = {'bias': bias, 'acceleration': acceleration}\n",
    "    low = _compute_quantile(z_low, **kws)\n",
    "    high = _compute_quantile(z_high, **kws)\n",
    "\n",
    "    if isnan(low) or isnan(high):\n",
    "        return low, high\n",
    "\n",
    "    else:\n",
    "        low = int(norm.cdf(low) * n_boots)\n",
    "        high = int(norm.cdf(high) * n_boots)\n",
    "        return low, high\n",
    "\n",
    "\n",
    "def calculate_group_var(control_var, control_N,test_var, test_N):\n",
    "    return control_var/control_N + test_var/test_N\n",
    "\n",
    "\n",
    "def calculate_weighted_delta(group_var, differences, resamples):\n",
    "    '''\n",
    "    Compute the weighted deltas.\n",
    "    '''\n",
    "    import numpy as np\n",
    "\n",
    "    weight = 1/group_var\n",
    "    denom = np.sum(weight)\n",
    "    num = np.sum(weight[i] * differences[i] for i in range(0, len(weight)))\n",
    "\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0c164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
