{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebadf154",
   "metadata": {},
   "source": [
    "# confint_2group_diff\n",
    "\n",
    "> A range of functions to compute bootstraps for the mean difference \n",
    "between two groups.\n",
    "\n",
    "- order: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77004140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _stats_tools/confint_2group_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f96815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa733643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from numpy import arange, delete, errstate\n",
    "from numpy import mean as npmean\n",
    "from numpy import sum as npsum\n",
    "from numpy.random import PCG64, RandomState\n",
    "from numba import njit, prange\n",
    "from scipy.stats import norm\n",
    "from numpy import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit(cache=True, parallel=True)\n",
    "def create_jackknife_indexes(data):\n",
    "    \"\"\"\n",
    "    Given an array-like, creates a jackknife bootstrap.\n",
    "\n",
    "    For a given set of data Y, the jackknife bootstrap sample J[i]\n",
    "    is defined as the data set Y with the ith data point deleted.\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    data: array-like\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Generator that yields all jackknife bootstrap samples.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(data)\n",
    "    indexes = np.empty((n, n - 1), dtype=np.int64)\n",
    "    for i in prange(n):\n",
    "        indexes[i] = np.concatenate((np.arange(i), np.arange(i + 1, n)))\n",
    "    return indexes\n",
    "\n",
    "\n",
    "@njit(cache=True, parallel=True)\n",
    "def create_repeated_indexes(data):\n",
    "    \"\"\"\n",
    "    Convenience function. Given an array-like with length N,\n",
    "    returns a generator that yields N indexes [0, 1, ..., N].\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(data)\n",
    "    indexes = np.empty((n, n), dtype=np.int64)  # Pre-allocate the output array\n",
    "    for i in prange(n):\n",
    "        indexes[i, :] = np.arange(n)  # Fill each row with the full index range\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def _create_two_group_jackknife_indexes(x0, x1, is_paired):\n",
    "    \"\"\"Creates the jackknife bootstrap for 2 groups.\"\"\"\n",
    "\n",
    "    if is_paired and len(x0) == len(x1):\n",
    "        out = list(\n",
    "            zip(\n",
    "                [j for j in create_jackknife_indexes(x0)],\n",
    "                [i for i in create_jackknife_indexes(x1)],\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        jackknife_c = list(\n",
    "            zip(\n",
    "                [j for j in create_jackknife_indexes(x0)],\n",
    "                [i for i in create_repeated_indexes(x1)],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        jackknife_t = list(\n",
    "            zip(\n",
    "                [i for i in create_repeated_indexes(x0)],\n",
    "                [j for j in create_jackknife_indexes(x1)],\n",
    "            )\n",
    "        )\n",
    "        out = jackknife_c + jackknife_t\n",
    "        del jackknife_c\n",
    "        del jackknife_t\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_meandiff_jackknife(x0, x1, is_paired, effect_size):\n",
    "    \"\"\"\n",
    "    Given two arrays, returns the jackknife for their effect size.\n",
    "    \"\"\"\n",
    "    from . import effsize as __es\n",
    "\n",
    "    jackknives = _create_two_group_jackknife_indexes(x0, x1, is_paired)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for j in jackknives:\n",
    "        x0_shuffled = x0[j[0]]\n",
    "        x1_shuffled = x1[j[1]]\n",
    "\n",
    "        es = __es.two_group_difference(x0_shuffled, x1_shuffled, is_paired, effect_size)\n",
    "        out.append(es)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _calc_accel(jack_dist):\n",
    "    \"\"\"\n",
    "    Given the Jackknife distribution, calculates the acceleration factor.\n",
    "    \"\"\"\n",
    "    jack_mean = npmean(jack_dist)\n",
    "\n",
    "    numer = npsum((jack_mean - jack_dist) ** 3)\n",
    "    denom = 6.0 * (npsum((jack_mean - jack_dist) ** 2) ** 1.5)\n",
    "\n",
    "    with errstate(invalid=\"ignore\"):\n",
    "        # does not raise warning if invalid division encountered.\n",
    "        return numer / denom\n",
    "\n",
    "\n",
    "@njit(cache=True, parallel=True)\n",
    "def bootstrap_indices(is_paired, x0_len, x1_len, resamples, random_seed):\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.empty((resamples, x0_len if is_paired else x0_len + x1_len), dtype=np.int64)\n",
    "    \n",
    "    for i in prange(resamples):\n",
    "        if is_paired:\n",
    "            indices[i, :x0_len] = np.random.choice(x0_len, x0_len)\n",
    "        else:  \n",
    "            indices[i, :x0_len] = np.random.choice(x0_len, x0_len)\n",
    "            indices[i, x0_len:x0_len+x1_len] = np.random.choice(x1_len, x1_len)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def compute_bootstrapped_diff(\n",
    "    x0, x1, is_paired, effect_size, resamples=5000, random_seed=12345\n",
    "):\n",
    "    \"\"\"Bootstraps the effect_size for 2 groups.\"\"\"\n",
    "\n",
    "    from . import effsize as __es\n",
    "\n",
    "    x0_len, x1_len = len(x0), len(x1)\n",
    "    indices = bootstrap_indices(is_paired, x0_len, x1_len, resamples, random_seed)\n",
    "    out = np.empty(resamples, dtype=np.float64)\n",
    "\n",
    "    for i in range(resamples):\n",
    "        if is_paired:\n",
    "            x0_sample = x0[indices[i, :x0_len]]\n",
    "            x1_sample = x1[indices[i, :x0_len]]\n",
    "        else:\n",
    "            x0_sample = x0[indices[i, :x0_len]]\n",
    "            x1_sample = x1[indices[i, x0_len:x0_len+x1_len]]\n",
    "\n",
    "        out[i] = __es.two_group_difference(x0_sample, x1_sample, is_paired, effect_size)\n",
    "\n",
    "    return out\n",
    "\n",
    "@njit(cache=True, parallel=True)\n",
    "def delta2_bootstrap_loop(x1, x2, x3, x4, resamples, pooled_sd, rng_seed, is_paired):\n",
    "    np.random.seed(rng_seed)\n",
    "    out_delta_g = np.empty(resamples)\n",
    "    deltadelta = np.empty(resamples)\n",
    "    \n",
    "    n1, n2, n3, n4 = len(x1), len(x2), len(x3), len(x4)\n",
    "    if is_paired:\n",
    "        if n1 != n2 or n3 != n4:\n",
    "            raise ValueError(\"Each control group must have the same length as its corresponding test group in paired analysis.\")\n",
    "    \n",
    "\n",
    "    # Bootstrapping\n",
    "    for i in prange(resamples):\n",
    "        # Paired or unpaired resampling\n",
    "        if is_paired:\n",
    "            indices_1 = np.random.choice(len(x1),len(x1))\n",
    "            indices_2 = np.random.choice(len(x3),len(x3))\n",
    "            x1_sample, x2_sample = x1[indices_1], x2[indices_1]\n",
    "            x3_sample, x4_sample = x3[indices_2], x4[indices_2]\n",
    "        else:\n",
    "            indices_1 = np.random.randint(0, len(x1), len(x1))\n",
    "            indices_2 = np.random.randint(0, len(x2), len(x2))\n",
    "            indices_3 = np.random.randint(0, len(x3), len(x3))\n",
    "            indices_4 = np.random.randint(0, len(x4), len(x4))\n",
    "            x1_sample, x2_sample = x1[indices_1], x2[indices_2]\n",
    "            x3_sample, x4_sample = x3[indices_3], x4[indices_4]\n",
    "\n",
    "        # Calculating deltas\n",
    "        delta_1 = np.mean(x2_sample) - np.mean(x1_sample)\n",
    "        delta_2 = np.mean(x4_sample) - np.mean(x3_sample)\n",
    "        delta_delta = delta_2 - delta_1\n",
    "\n",
    "        deltadelta[i] = delta_delta\n",
    "        out_delta_g[i] = delta_delta / pooled_sd\n",
    "\n",
    "    return out_delta_g, deltadelta\n",
    "\n",
    "\n",
    "def compute_delta2_bootstrapped_diff(\n",
    "    x1: np.ndarray,  # Control group 1\n",
    "    x2: np.ndarray,  # Test group 1\n",
    "    x3: np.ndarray,  # Control group 2\n",
    "    x4: np.ndarray,  # Test group 2\n",
    "    is_paired: str = None,\n",
    "    resamples: int = 5000,  # The number of bootstrap resamples to be taken for the calculation of the confidence interval limits.\n",
    "    random_seed: int = 12345,  # `random_seed` is used to seed the random number generator during bootstrap resampling. This ensures that the confidence intervals reported are replicable.\n",
    ") -> (\n",
    "    tuple\n",
    "):  # bootstraped result and empirical result of deltas' g, and the bootstraped result of delta-delta\n",
    "    \"\"\"\n",
    "    Bootstraps the effect size deltas' g.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x1, x2, x3, x4 = map(np.asarray, [x1, x2, x3, x4])\n",
    "\n",
    "    # Calculating pooled sample standard deviation\n",
    "    stds = [np.std(x) for x in [x1, x2, x3, x4]]\n",
    "    ns = [len(x) for x in [x1, x2, x3, x4]]\n",
    "\n",
    "    sd_numerator = sum((n - 1) * s**2 for n, s in zip(ns, stds))\n",
    "    sd_denominator = sum(n - 1 for n in ns)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if sd_denominator == 0:\n",
    "        raise ValueError(\"Insufficient data to compute pooled standard deviation.\")\n",
    "\n",
    "    pooled_sample_sd = np.sqrt(sd_numerator / sd_denominator)\n",
    "\n",
    "    # Ensure pooled_sample_sd is not NaN or zero (to avoid division by zero later)\n",
    "    if np.isnan(pooled_sample_sd) or pooled_sample_sd == 0:\n",
    "        raise ValueError(\"Pooled sample standard deviation is NaN or zero.\")\n",
    "\n",
    "    out_delta_g, deltadelta = delta2_bootstrap_loop(x1, x2, x3, x4, resamples, pooled_sample_sd, random_seed, is_paired)\n",
    "\n",
    "    # Empirical delta_g calculation\n",
    "    delta_g = ((np.mean(x4) - np.mean(x3)) - (np.mean(x2) - np.mean(x1))) / pooled_sample_sd\n",
    "\n",
    "    return out_delta_g, delta_g, deltadelta\n",
    "\n",
    "\n",
    "def compute_meandiff_bias_correction(\n",
    "    bootstraps,  # An numerical iterable, comprising bootstrap resamples of the effect size.\n",
    "    effsize,  # The effect size for the original sample.\n",
    "):  # The bias correction value for the given bootstraps and effect size.\n",
    "    \"\"\"\n",
    "    Computes the bias correction required for the BCa method\n",
    "    of confidence interval construction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bias: numeric\n",
    "        The bias correction value for the given bootstraps\n",
    "        and effect size.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    B = np.array(bootstraps)\n",
    "    prop_less_than_es = sum(B < effsize) / len(B)\n",
    "\n",
    "    return norm.ppf(prop_less_than_es)\n",
    "\n",
    "\n",
    "def _compute_alpha_from_ci(ci):\n",
    "    if ci < 0 or ci > 100:\n",
    "        raise ValueError(\"`ci` must be a number between 0 and 100.\")\n",
    "\n",
    "    return (100.0 - ci) / 100.0\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def _compute_quantile(z, bias, acceleration):\n",
    "    numer = bias + z\n",
    "    denom = 1 - (acceleration * numer)\n",
    "\n",
    "    return bias + (numer / denom)\n",
    "\n",
    "\n",
    "def compute_interval_limits(bias, acceleration, n_boots, ci=95):\n",
    "    \"\"\"\n",
    "    Returns the indexes of the interval limits for a given bootstrap.\n",
    "\n",
    "    Supply the bias, acceleration factor, and number of bootstraps.\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = _compute_alpha_from_ci(ci)\n",
    "\n",
    "    alpha_low = alpha / 2\n",
    "    alpha_high = 1 - (alpha / 2)\n",
    "\n",
    "    z_low = norm.ppf(alpha_low)\n",
    "    z_high = norm.ppf(alpha_high)\n",
    "\n",
    "    kws = {\"bias\": bias, \"acceleration\": acceleration}\n",
    "    low = _compute_quantile(z_low, **kws)\n",
    "    high = _compute_quantile(z_high, **kws)\n",
    "\n",
    "    if isnan(low) or isnan(high):\n",
    "        return low, high\n",
    "\n",
    "    \n",
    "    low = int(norm.cdf(low) * n_boots)\n",
    "    high = int(norm.cdf(high) * n_boots)\n",
    "    return low, high\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_group_var(control_var, control_N, test_var, test_N):\n",
    "    return control_var / control_N + test_var / test_N\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_weighted_delta(group_var, differences):\n",
    "    \"\"\"\n",
    "    Compute the weighted deltas.\n",
    "    \"\"\"\n",
    "\n",
    "    weight = 1 / group_var\n",
    "    denom = np.sum(weight)\n",
    "    num = np.sum(weight[i] * differences[i] for i in range(0, len(weight)))\n",
    "\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0c164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
