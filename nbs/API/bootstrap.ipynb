{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b391aa10",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "\n",
    "- order: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _bootstrap_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class bootstrap:\n",
    "    '''Computes the summary statistic and a bootstrapped confidence interval.\n",
    "\n",
    "    Keywords:\n",
    "        x1, x2: array-like\n",
    "            The data in a one-dimensional array form. Only x1 is required.\n",
    "            If x2 is given, the bootstrapped summary difference between\n",
    "            the two groups (x2-x1) is computed.\n",
    "            NaNs are automatically discarded.\n",
    "\n",
    "        paired: boolean, default False\n",
    "            Whether or not x1 and x2 are paired samples.\n",
    "\n",
    "        statfunction: callable, default np.mean\n",
    "            The summary statistic called on data.\n",
    "\n",
    "        smoothboot: boolean, default False\n",
    "            Taken from seaborn.algorithms.bootstrap.\n",
    "            If True, performs a smoothed bootstrap (draws samples from a kernel\n",
    "            destiny estimate).\n",
    "\n",
    "        alpha: float, default 0.05\n",
    "            Denotes the likelihood that the confidence interval produced\n",
    "            does not include the true summary statistic. When alpha = 0.05,\n",
    "            a 95% confidence interval is produced.\n",
    "\n",
    "        reps: int, default 5000\n",
    "            Number of bootstrap iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        An `bootstrap` object reporting the summary statistics, percentile CIs,\n",
    "        bias-corrected and accelerated (BCa) CIs, and the settings used.\n",
    "\n",
    "        summary: float\n",
    "            The summary statistic.\n",
    "\n",
    "        is_difference: boolean\n",
    "            Whether or not the summary is the difference between two groups.\n",
    "            If False, only x1 was supplied.\n",
    "\n",
    "        is_paired: boolean\n",
    "            Whether or not the difference reported is between 2 paired groups.\n",
    "\n",
    "        statistic: callable\n",
    "            The function used to compute the summary.\n",
    "\n",
    "        reps: int\n",
    "            The number of bootstrap iterations performed.\n",
    "\n",
    "        stat_array: array.\n",
    "            A sorted array of values obtained by bootstrapping the input arrays.\n",
    "\n",
    "        ci: float\n",
    "            The size of the confidence interval reported (in percentage).\n",
    "\n",
    "        pct_ci_low, pct_ci_high: floats\n",
    "            The upper and lower bounds of the confidence interval as computed\n",
    "            by taking the percentage bounds.\n",
    "\n",
    "        pct_low_high_indices: array\n",
    "            An array with the indices in `stat_array` corresponding to the\n",
    "            percentage confidence interval bounds.\n",
    "\n",
    "        bca_ci_low, bca_ci_high: floats\n",
    "            The upper and lower bounds of the bias-corrected and accelerated\n",
    "            (BCa) confidence interval. See Efron 1977.\n",
    "\n",
    "        bca_low_high_indices: array\n",
    "            An array with the indices in `stat_array` corresponding to the BCa\n",
    "            confidence interval bounds.\n",
    "\n",
    "        pvalue_1samp_ttest: float\n",
    "            P-value obtained from scipy.stats.ttest_1samp. If 2 arrays were\n",
    "            passed (x1 and x2), returns 'NIL'.\n",
    "            See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_1samp.html\n",
    "\n",
    "        pvalue_2samp_ind_ttest: float\n",
    "            P-value obtained from scipy.stats.ttest_ind.\n",
    "            If a single array was given (x1 only), or if `paired` is True,\n",
    "            returns 'NIL'.\n",
    "            See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "        pvalue_2samp_related_ttest: float\n",
    "            P-value obtained from scipy.stats.ttest_rel.\n",
    "            If a single array was given (x1 only), or if `paired` is False,\n",
    "            returns 'NIL'.\n",
    "            See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_rel.html\n",
    "\n",
    "        pvalue_wilcoxon: float\n",
    "            P-value obtained from scipy.stats.wilcoxon.\n",
    "            If a single array was given (x1 only), or if `paired` is False,\n",
    "            returns 'NIL'.\n",
    "            The Wilcoxons signed-rank test is a nonparametric paired test of\n",
    "            the null hypothesis that the related samples x1 and x2 are from\n",
    "            the same distribution.\n",
    "            See https://docs.scipy.org/doc/scipy-1.0.0/reference/scipy.stats.wilcoxon.html\n",
    "\n",
    "        pvalue_mann_whitney: float\n",
    "            Two-sided p-value obtained from scipy.stats.mannwhitneyu.\n",
    "            If a single array was given (x1 only), returns 'NIL'.\n",
    "            The Mann-Whitney U-test is a nonparametric unpaired test of the null\n",
    "            hypothesis that x1 and x2 are from the same distribution.\n",
    "            See https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "\n",
    "    '''\n",
    "    def __init__(self, x1, x2=None,\n",
    "        paired=False,\n",
    "        statfunction=None,\n",
    "        smoothboot=False,\n",
    "        alpha_level=0.05,\n",
    "        reps=5000):\n",
    "\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import seaborn as sns\n",
    "\n",
    "        from scipy.stats import norm\n",
    "        from numpy.random import randint\n",
    "        from scipy.stats import ttest_1samp, ttest_ind, ttest_rel\n",
    "        from scipy.stats import mannwhitneyu, wilcoxon, norm\n",
    "        import warnings\n",
    "\n",
    "        # Turn to pandas series.\n",
    "        x1 = pd.Series(x1).dropna()\n",
    "        diff = False\n",
    "\n",
    "        # Initialise statfunction\n",
    "        if statfunction == None:\n",
    "            statfunction = np.mean\n",
    "\n",
    "        # Compute two-sided alphas.\n",
    "        if alpha_level > 1. or alpha_level < 0.:\n",
    "            raise ValueError(\"alpha_level must be between 0 and 1.\")\n",
    "        alphas = np.array([alpha_level/2., 1-alpha_level/2.])\n",
    "\n",
    "        sns_bootstrap_kwargs = {'func': statfunction,\n",
    "            'n_boot': reps,\n",
    "            'smooth': smoothboot}\n",
    "\n",
    "        if paired:\n",
    "            # check x2 is not None:\n",
    "            if x2 is None:\n",
    "                raise ValueError('Please specify x2.')\n",
    "            else:\n",
    "                x2 = pd.Series(x2).dropna()\n",
    "                if len(x1) != len(x2):\n",
    "                    raise ValueError('x1 and x2 are not the same length.')\n",
    "\n",
    "        if (x2 is None) or (paired is True) :\n",
    "\n",
    "            if x2 is None:\n",
    "                tx = x1\n",
    "                paired = False\n",
    "                ttest_single = ttest_1samp(x1, 0)[1]\n",
    "                ttest_2_ind = 'NIL'\n",
    "                ttest_2_paired = 'NIL'\n",
    "                wilcoxonresult = 'NIL'\n",
    "\n",
    "            elif paired is True:\n",
    "                diff = True\n",
    "                tx = x2 - x1\n",
    "                ttest_single = 'NIL'\n",
    "                ttest_2_ind = 'NIL'\n",
    "                ttest_2_paired = ttest_rel(x1, x2)[1]\n",
    "                wilcoxonresult = wilcoxon(x1, x2)[1]\n",
    "            mannwhitneyresult = 'NIL'\n",
    "\n",
    "            # Turns data into array, then tuple.\n",
    "            tdata = (tx,)\n",
    "\n",
    "            # The value of the statistic function applied\n",
    "            # just to the actual data.\n",
    "            summ_stat = statfunction(*tdata)\n",
    "            statarray = sns.algorithms.bootstrap(tx, **sns_bootstrap_kwargs)\n",
    "            statarray.sort()\n",
    "\n",
    "            # Get Percentile indices\n",
    "            pct_low_high = np.round((reps-1) * alphas)\n",
    "            pct_low_high = np.nan_to_num(pct_low_high).astype('int')\n",
    "\n",
    "\n",
    "        elif x2 is not None and paired is False:\n",
    "            diff = True\n",
    "            x2 = pd.Series(x2).dropna()\n",
    "            # Generate statarrays for both arrays.\n",
    "            ref_statarray = sns.algorithms.bootstrap(x1, **sns_bootstrap_kwargs)\n",
    "            exp_statarray = sns.algorithms.bootstrap(x2, **sns_bootstrap_kwargs)\n",
    "\n",
    "            tdata = exp_statarray - ref_statarray\n",
    "            statarray = tdata.copy()\n",
    "            statarray.sort()\n",
    "            tdata = (tdata, ) # Note tuple form.\n",
    "\n",
    "            # The difference as one would calculate it.\n",
    "            summ_stat = statfunction(x2) - statfunction(x1)\n",
    "\n",
    "            # Get Percentile indices\n",
    "            pct_low_high = np.round((reps-1) * alphas)\n",
    "            pct_low_high = np.nan_to_num(pct_low_high).astype('int')\n",
    "\n",
    "            # Statistical tests.\n",
    "            ttest_single='NIL'\n",
    "            ttest_2_ind = ttest_ind(x1,x2)[1]\n",
    "            ttest_2_paired='NIL'\n",
    "            mannwhitneyresult = mannwhitneyu(x1, x2, alternative='two-sided')[1]\n",
    "            wilcoxonresult = 'NIL'\n",
    "\n",
    "        # Get Bias-Corrected Accelerated indices convenience function invoked.\n",
    "        bca_low_high = bca(tdata, alphas, statarray,\n",
    "                           statfunction, summ_stat, reps)\n",
    "\n",
    "        # Warnings for unstable or extreme indices.\n",
    "        for ind in [pct_low_high, bca_low_high]:\n",
    "            if np.any(ind == 0) or np.any(ind == reps-1):\n",
    "                warnings.warn(\"Some values used extremal samples;\"\n",
    "                \" results are probably unstable.\")\n",
    "            elif np.any(ind<10) or np.any(ind>=reps-10):\n",
    "                warnings.warn(\"Some values used top 10 low/high samples;\"\n",
    "                \" results may be unstable.\")\n",
    "\n",
    "        self.summary = summ_stat\n",
    "        self.is_paired = paired\n",
    "        self.is_difference = diff\n",
    "        self.statistic = str(statfunction)\n",
    "        self.n_reps = reps\n",
    "\n",
    "        self.ci = (1-alpha_level)*100\n",
    "        self.stat_array = np.array(statarray)\n",
    "\n",
    "        self.pct_ci_low = statarray[pct_low_high[0]]\n",
    "        self.pct_ci_high = statarray[pct_low_high[1]]\n",
    "        self.pct_low_high_indices = pct_low_high\n",
    "\n",
    "        self.bca_ci_low = statarray[bca_low_high[0]]\n",
    "        self.bca_ci_high = statarray[bca_low_high[1]]\n",
    "        self.bca_low_high_indices = bca_low_high\n",
    "\n",
    "        self.pvalue_1samp_ttest = ttest_single\n",
    "        self.pvalue_2samp_ind_ttest = ttest_2_ind\n",
    "        self.pvalue_2samp_paired_ttest = ttest_2_paired\n",
    "        self.pvalue_wilcoxon = wilcoxonresult\n",
    "        self.pvalue_mann_whitney = mannwhitneyresult\n",
    "\n",
    "        self.results = {'stat_summary': self.summary,\n",
    "                        'is_difference': diff,\n",
    "                        'is_paired': paired,\n",
    "                        'bca_ci_low': self.bca_ci_low,\n",
    "                        'bca_ci_high': self.bca_ci_high,\n",
    "                        'ci': self.ci\n",
    "                        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        import numpy as np\n",
    "\n",
    "        if 'mean' in self.statistic:\n",
    "            stat = 'mean'\n",
    "        elif 'median' in self.statistic:\n",
    "            stat = 'median'\n",
    "        else:\n",
    "            stat = self.statistic\n",
    "\n",
    "        diff_types = {True: 'paired', False: 'unpaired'}\n",
    "        if self.is_difference:\n",
    "            a = 'The {} {} difference is {}.'.format(diff_types[self.is_paired],\n",
    "                    stat, self.summary)\n",
    "        else:\n",
    "            a = 'The {} is {}.'.format(stat, self.summary)\n",
    "\n",
    "        b = '[{} CI: {}, {}]'.format(self.ci, self.bca_ci_low, self.bca_ci_high)\n",
    "        return '\\n'.join([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def jackknife_indexes(data):\n",
    "    # Taken without modification from scikits.bootstrap package.\n",
    "    \"\"\"\n",
    "    From the scikits.bootstrap package.\n",
    "    Given an array, returns a list of arrays where each array is a set of\n",
    "    jackknife indexes.\n",
    "\n",
    "    For a given set of data Y, the jackknife sample J[i] is defined as the\n",
    "    data set Y with the ith data point deleted.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    base = np.arange(0,len(data))\n",
    "    return (np.delete(base,i) for i in base)\n",
    "\n",
    "def bca(data, alphas, statarray, statfunction, ostat, reps):\n",
    "    '''\n",
    "    Subroutine called to calculate the BCa statistics.\n",
    "    Borrowed heavily from scikits.bootstrap code.\n",
    "    '''\n",
    "    import warnings\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "\n",
    "    from scipy.stats import norm\n",
    "    from numpy.random import randint\n",
    "\n",
    "    # The bias correction value.\n",
    "    z0 = norm.ppf( ( 1.0*np.sum(statarray < ostat, axis = 0)  ) / reps )\n",
    "\n",
    "    # Statistics of the jackknife distribution\n",
    "    jackindexes = jackknife_indexes(data[0])\n",
    "    jstat = [statfunction(*(x[indexes] for x in data))\n",
    "            for indexes in jackindexes]\n",
    "    jmean = np.mean(jstat,axis = 0)\n",
    "\n",
    "    # Acceleration value\n",
    "    a = np.divide(np.sum( (jmean - jstat)**3, axis = 0 ),\n",
    "        ( 6.0 * np.sum( (jmean - jstat)**2, axis = 0)**1.5 )\n",
    "        )\n",
    "    if np.any(np.isnan(a)):\n",
    "        nanind = np.nonzero(np.isnan(a))\n",
    "        warnings.warn(\"Some acceleration values were undefined.\"\n",
    "        \"This is almost certainly because all values\"\n",
    "        \"for the statistic were equal. Affected\"\n",
    "        \"confidence intervals will have zero width and\"\n",
    "        \"may be inaccurate (indexes: {})\".format(nanind))\n",
    "    zs = z0 + norm.ppf(alphas).reshape(alphas.shape+(1,)*z0.ndim)\n",
    "    avals = norm.cdf(z0 + zs/(1-a*zs))\n",
    "    nvals = np.round((reps-1)*avals)\n",
    "    nvals = np.nan_to_num(nvals).astype('int')\n",
    "\n",
    "    return nvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091c0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
