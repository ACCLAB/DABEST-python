{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b391aa10",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "\n",
    "- order: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _bootstrap_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import division\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_1samp, ttest_ind, ttest_rel\n",
    "from scipy.stats import mannwhitneyu, wilcoxon, norm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class bootstrap:\n",
    "    \"\"\"\n",
    "    Computes the summary statistic and a bootstrapped confidence interval.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An `bootstrap` object reporting the summary statistics, percentile CIs, bias-corrected and accelerated (BCa) CIs, and the settings used:\n",
    "        `summary`: float.\n",
    "            The summary statistic.\n",
    "        `is_difference`: boolean.\n",
    "             Whether or not the summary is the difference between two groups. If False, only x1 was supplied.\n",
    "        `is_paired`:  string, default None\n",
    "            The type of the experiment under which the data are obtained\n",
    "        `statistic`: callable\n",
    "            The function used to compute the summary.\n",
    "        `reps`: int\n",
    "            The number of bootstrap iterations performed.\n",
    "        `stat_array`:array\n",
    "            A sorted array of values obtained by bootstrapping the input arrays.\n",
    "        `ci`:float\n",
    "            The size of the confidence interval reported (in percentage).\n",
    "        `pct_ci_low,pct_ci_high`:floats\n",
    "            The upper and lower bounds of the confidence interval as computed by taking the percentage bounds.\n",
    "        `pct_low_high_indices`:array\n",
    "            An array with the indices in `stat_array` corresponding to the percentage confidence interval bounds.\n",
    "        `bca_ci_low, bca_ci_high`: floats\n",
    "            The upper and lower bounds of the bias-corrected and accelerated(BCa) confidence interval. See Efron 1977.\n",
    "        `bca_low_high_indices`: array\n",
    "            An array with the indices in `stat_array` corresponding to the BCa confidence interval bounds.\n",
    "        `pvalue_1samp_ttest`: float\n",
    "            P-value obtained from scipy.stats.ttest_1samp. If 2 arrays were passed (x1 and x2), returns 'NIL'. See <https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_1samp.html>\n",
    "        `pvalue_2samp_ind_ttest`: float\n",
    "            P-value obtained from scipy.stats.ttest_ind. If a single array was given (x1 only), or if `paired` is not None, returns 'NIL'. See <https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_ind.html>\n",
    "        `pvalue_2samp_related_ttest`: float\n",
    "            P-value obtained from scipy.stats.ttest_rel. If a single array was given (x1 only), or if `paired` is None, returns 'NIL'. See <https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.ttest_rel.html>\n",
    "        `pvalue_wilcoxon`: float\n",
    "            P-value obtained from scipy.stats.wilcoxon. If a single array was given (x1 only), or if `paired` is None, returns 'NIL'. The Wilcoxons signed-rank test is a nonparametric paired test of the null hypothesis that the related samples x1 and x2 are from the same distribution. See <https://docs.scipy.org/doc/scipy-1.0.0/reference/scipy.stats.wilcoxon.html>\n",
    "        `pvalue_mann_whitney`: float\n",
    "            Two-sided p-value obtained from scipy.stats.mannwhitneyu. If a single array was given (x1 only), returns 'NIL'. The Mann-Whitney U-test is a nonparametric unpaired test of the null hypothesis that x1 and x2 are from the same distribution. See <https://docs.scipy.org/doc/scipy-1.0.0/reference/generated/scipy.stats.mannwhitneyu.html>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x1: np.array,  # The data in a one-dimensional array form. Only x1 is required. If x2 is given, the bootstrapped summary difference between the two groups (x2-x1) is computed. NaNs are automatically discarded.\n",
    "        x2: np.array = None,  # The data in a one-dimensional array form. Only x1 is required. If x2 is given, the bootstrapped summary difference between the two groups (x2-x1) is computed. NaNs are automatically discarded.\n",
    "        paired: bool = False,  # Whether or not x1 and x2 are paired samples. If 'paired' is None then the data will not be treated as paired data in the subsequent calculations. If 'paired' is 'baseline', then in each tuple of x, other groups will be paired up with the first group (as control). If 'paired' is 'sequential', then in each tuple of x, each group will be paired up with the previous group (as control).\n",
    "        stat_function: callable = np.mean,  # The summary statistic called on data.\n",
    "        smoothboot: bool = False,  # Taken from seaborn.algorithms.bootstrap. If True, performs a smoothed bootstrap (draws samples from a kernel destiny estimate).\n",
    "        alpha_level: float = 0.05,  # Denotes the likelihood that the confidence interval produced does not include the true summary statistic. When alpha = 0.05, a 95% confidence interval is produced.\n",
    "        reps: int = 5000,  # Number of bootstrap iterations to perform.\n",
    "    ):\n",
    "        # Turn to pandas series.\n",
    "        x1 = pd.Series(x1).dropna()\n",
    "        diff = False\n",
    "\n",
    "        # Initialise stat_function\n",
    "        if stat_function is None:\n",
    "            stat_function = np.mean\n",
    "\n",
    "        # Compute two-sided alphas.\n",
    "        if alpha_level > 1.0 or alpha_level < 0.0:\n",
    "            raise ValueError(\"alpha_level must be between 0 and 1.\")\n",
    "        alphas = np.array([alpha_level / 2.0, 1 - alpha_level / 2.0])\n",
    "\n",
    "        sns_bootstrap_kwargs = {\n",
    "            \"func\": stat_function,\n",
    "            \"n_boot\": reps,\n",
    "            \"smooth\": smoothboot,\n",
    "        }\n",
    "\n",
    "        if paired:\n",
    "            # check x2 is not None:\n",
    "            if x2 is None:\n",
    "                raise ValueError(\"Please specify x2.\")\n",
    "            \n",
    "            x2 = pd.Series(x2).dropna()\n",
    "            if len(x1) != len(x2):\n",
    "                raise ValueError(\"x1 and x2 are not the same length.\")\n",
    "\n",
    "        if (x2 is None) or (paired is not None):\n",
    "            if x2 is None:\n",
    "                tx = x1\n",
    "                paired = False\n",
    "                ttest_single = ttest_1samp(x1, 0)[1]\n",
    "                ttest_2_ind = \"NIL\"\n",
    "                ttest_2_paired = \"NIL\"\n",
    "                wilcoxonresult = \"NIL\"\n",
    "\n",
    "            else:  # only two options to enter here\n",
    "                diff = True\n",
    "                tx = x2 - x1\n",
    "                ttest_single = \"NIL\"\n",
    "                ttest_2_ind = \"NIL\"\n",
    "                ttest_2_paired = ttest_rel(x1, x2)[1]\n",
    "                wilcoxonresult = wilcoxon(x1, x2)[1]\n",
    "            mannwhitneyresult = \"NIL\"\n",
    "\n",
    "            # Turns data into array, then tuple.\n",
    "            tdata = (tx,)\n",
    "\n",
    "            # The value of the statistic function applied\n",
    "            # just to the actual data.\n",
    "            summ_stat = stat_function(*tdata)\n",
    "            statarray = sns.algorithms.bootstrap(tx, **sns_bootstrap_kwargs)\n",
    "            statarray.sort()\n",
    "\n",
    "            # Get Percentile indices\n",
    "            pct_low_high = np.round((reps - 1) * alphas)\n",
    "            pct_low_high = np.nan_to_num(pct_low_high).astype(\"int\")\n",
    "\n",
    "        elif x2 is not None and paired is None:\n",
    "            diff = True\n",
    "            x2 = pd.Series(x2).dropna()\n",
    "            # Generate statarrays for both arrays.\n",
    "            ref_statarray = sns.algorithms.bootstrap(x1, **sns_bootstrap_kwargs)\n",
    "            exp_statarray = sns.algorithms.bootstrap(x2, **sns_bootstrap_kwargs)\n",
    "\n",
    "            tdata = exp_statarray - ref_statarray\n",
    "            statarray = tdata.copy()\n",
    "            statarray.sort()\n",
    "            tdata = (tdata,)  # Note tuple form.\n",
    "\n",
    "            # The difference as one would calculate it.\n",
    "            summ_stat = stat_function(x2) - stat_function(x1)\n",
    "\n",
    "            # Get Percentile indices\n",
    "            pct_low_high = np.round((reps - 1) * alphas)\n",
    "            pct_low_high = np.nan_to_num(pct_low_high).astype(\"int\")\n",
    "\n",
    "            # Statistical tests.\n",
    "            ttest_single = \"NIL\"\n",
    "            ttest_2_ind = ttest_ind(x1, x2)[1]\n",
    "            ttest_2_paired = \"NIL\"\n",
    "            mannwhitneyresult = mannwhitneyu(x1, x2, alternative=\"two-sided\")[1]\n",
    "            wilcoxonresult = \"NIL\"\n",
    "\n",
    "        # Get Bias-Corrected Accelerated indices convenience function invoked.\n",
    "        bca_low_high = bca(tdata, alphas, statarray, stat_function, summ_stat, reps)\n",
    "\n",
    "        # Warnings for unstable or extreme indices.\n",
    "        for ind in [pct_low_high, bca_low_high]:\n",
    "            if np.any(ind == 0) or np.any(ind == reps - 1):\n",
    "                warnings.warn(\n",
    "                    \"Some values used extremal samples;\"\n",
    "                    \" results are probably unstable.\"\n",
    "                )\n",
    "            elif np.any(ind < 10) or np.any(ind >= reps - 10):\n",
    "                warnings.warn(\n",
    "                    \"Some values used top 10 low/high samples;\"\n",
    "                    \" results may be unstable.\"\n",
    "                )\n",
    "\n",
    "        self.summary = summ_stat\n",
    "        self.is_paired = paired\n",
    "        self.is_difference = diff\n",
    "        self.statistic = str(stat_function)\n",
    "        self.n_reps = reps\n",
    "\n",
    "        self.ci = (1 - alpha_level) * 100\n",
    "        self.stat_array = np.array(statarray)\n",
    "\n",
    "        self.pct_ci_low = statarray[pct_low_high[0]]\n",
    "        self.pct_ci_high = statarray[pct_low_high[1]]\n",
    "        self.pct_low_high_indices = pct_low_high\n",
    "\n",
    "        self.bca_ci_low = statarray[bca_low_high[0]]\n",
    "        self.bca_ci_high = statarray[bca_low_high[1]]\n",
    "        self.bca_low_high_indices = bca_low_high\n",
    "\n",
    "        self.pvalue_1samp_ttest = ttest_single\n",
    "        self.pvalue_2samp_ind_ttest = ttest_2_ind\n",
    "        self.pvalue_2samp_paired_ttest = ttest_2_paired\n",
    "        self.pvalue_wilcoxon = wilcoxonresult\n",
    "        self.pvalue_mann_whitney = mannwhitneyresult\n",
    "\n",
    "        self.results = {\n",
    "            \"stat_summary\": self.summary,\n",
    "            \"is_difference\": diff,\n",
    "            \"is_paired\": paired,\n",
    "            \"bca_ci_low\": self.bca_ci_low,\n",
    "            \"bca_ci_high\": self.bca_ci_high,\n",
    "            \"ci\": self.ci,\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        if \"mean\" in self.statistic:\n",
    "            stat = \"mean\"\n",
    "        elif \"median\" in self.statistic:\n",
    "            stat = \"median\"\n",
    "        else:\n",
    "            stat = self.statistic\n",
    "\n",
    "        diff_types = {\"sequential\": \"paired\", \"baseline\": \"paired\", None: \"unpaired\"}\n",
    "        if self.is_difference:\n",
    "            a = \"The {} {} difference is {}.\".format(\n",
    "                diff_types[self.is_paired], stat, self.summary\n",
    "            )\n",
    "        else:\n",
    "            a = \"The {} is {}.\".format(stat, self.summary)\n",
    "\n",
    "        b = \"[{} CI: {}, {}]\".format(self.ci, self.bca_ci_low, self.bca_ci_high)\n",
    "        return \"\\n\".join([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def jackknife_indexes(data):\n",
    "    # Taken without modification from scikits.bootstrap package.\n",
    "    \"\"\"\n",
    "    From the scikits.bootstrap package.\n",
    "    Given an array, returns a list of arrays where each array is a set of\n",
    "    jackknife indexes.\n",
    "\n",
    "    For a given set of data Y, the jackknife sample J[i] is defined as the\n",
    "    data set Y with the ith data point deleted.\n",
    "    \"\"\"\n",
    "\n",
    "    base = np.arange(0, len(data))\n",
    "    return (np.delete(base, i) for i in base)\n",
    "\n",
    "\n",
    "def bca(data, alphas, stat_array, stat_function, ostat, reps):\n",
    "    \"\"\"\n",
    "    Subroutine called to calculate the BCa statistics.\n",
    "    Borrowed heavily from scikits.bootstrap code.\n",
    "    \"\"\"\n",
    "\n",
    "    # The bias correction value.\n",
    "    z0 = norm.ppf((1.0 * np.sum(stat_array < ostat, axis=0)) / reps)\n",
    "\n",
    "    # Statistics of the jackknife distribution\n",
    "    jack_indexes = jackknife_indexes(data[0])\n",
    "    jstat = [stat_function(*(x[indexes] for x in data)) for indexes in jack_indexes]\n",
    "    jmean = np.mean(jstat, axis=0)\n",
    "\n",
    "    # Acceleration value\n",
    "    a = np.divide(\n",
    "        np.sum((jmean - jstat) ** 3, axis=0),\n",
    "        (6.0 * np.sum((jmean - jstat) ** 2, axis=0) ** 1.5),\n",
    "    )\n",
    "    if np.any(np.isnan(a)):\n",
    "        nanind = np.nonzero(np.isnan(a))\n",
    "        warnings.warn(\n",
    "            \"Some acceleration values were undefined.\"\n",
    "            \"This is almost certainly because all values\"\n",
    "            \"for the statistic were equal. Affected\"\n",
    "            \"confidence intervals will have zero width and\"\n",
    "            \"may be inaccurate (indexes: {})\".format(nanind)\n",
    "        )\n",
    "    zs = z0 + norm.ppf(alphas).reshape(alphas.shape + (1,) * z0.ndim)\n",
    "    avals = norm.cdf(z0 + zs / (1 - a * zs))\n",
    "    nvals = np.round((reps - 1) * avals)\n",
    "    nvals = np.nan_to_num(nvals).astype(\"int\")\n",
    "\n",
    "    return nvals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
