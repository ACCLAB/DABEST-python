{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a807e60",
   "metadata": {},
   "source": [
    "# effsize\n",
    "\n",
    "> A range of functions to compute various effect sizes.\n",
    "\n",
    "- order: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _stats_tools/effsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6673b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def two_group_difference(control:list|tuple|np.ndarray, #Accepts lists, tuples, or numpy ndarrays of numeric types.\n",
    "                         test:list|tuple|np.ndarray, #Accepts lists, tuples, or numpy ndarrays of numeric types.\n",
    "                         is_paired=None, #If not None, returns the paired Cohen's d\n",
    "                         effect_size:str=\"mean_diff\" # Any one of the following effect sizes: [\"mean_diff\", \"median_diff\", \"cohens_d\", \"hedges_g\", \"cliffs_delta\"]\n",
    "                        )->float: #  The desired effect size.\n",
    "    \"\"\"\n",
    "    Computes the following metrics for control and test:\n",
    "    \n",
    "        - Unstandardized mean difference\n",
    "        - Standardized mean differences (paired or unpaired)\n",
    "            * Cohen's d\n",
    "            * Hedges' g\n",
    "        - Median difference\n",
    "        - Cliff's Delta\n",
    "        - Cohen's h (distance between two proportions)\n",
    "\n",
    "    See the Wikipedia entry [here](https://bit.ly/2LzWokf)\n",
    "    \n",
    "    `effect_size`:\n",
    "    \n",
    "        mean_diff:      This is simply the mean of `control` subtracted from\n",
    "                        the mean of `test`.\n",
    "\n",
    "        cohens_d:       This is the mean of control subtracted from the\n",
    "                        mean of test, divided by the pooled standard deviation\n",
    "                        of control and test. The pooled SD is the square as:\n",
    "\n",
    "\n",
    "                               (n1 - 1) * var(control) + (n2 - 1) * var(test)\n",
    "                        sqrt (   -------------------------------------------  )\n",
    "                                                 (n1 + n2 - 2)\n",
    "\n",
    "                        where n1 and n2 are the sizes of control and test\n",
    "                        respectively.\n",
    "\n",
    "        hedges_g:       This is Cohen's d corrected for bias via multiplication\n",
    "                         with the following correction factor:\n",
    "\n",
    "                                        gamma(n/2)\n",
    "                        J(n) = ------------------------------\n",
    "                               sqrt(n/2) * gamma((n - 1) / 2)\n",
    "\n",
    "                        where n = (n1 + n2 - 2).\n",
    "\n",
    "        median_diff:    This is the median of `control` subtracted from the\n",
    "                        median of `test`.\n",
    "\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "\n",
    "    if effect_size == \"mean_diff\":\n",
    "        return func_difference(control, test, np.mean, is_paired)\n",
    "\n",
    "    elif effect_size == \"median_diff\":\n",
    "        mes1 = \"Using median as the statistic in bootstrapping may \" + \\\n",
    "                \"result in a biased estimate and cause problems with \" + \\\n",
    "                \"BCa confidence intervals. Consider using a different statistic, such as the mean.\\n\"\n",
    "        mes2 = \"When plotting, please consider using percetile confidence intervals \" + \\\n",
    "                \"by specifying `ci_type='percentile'`. For detailed information, \" + \\\n",
    "                \"refer to https://github.com/ACCLAB/DABEST-python/issues/129 \\n\"\n",
    "        warnings.warn(message=mes1+mes2, category=UserWarning)\n",
    "        return func_difference(control, test, np.median, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_d\":\n",
    "        return cohens_d(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_h\":\n",
    "        return cohens_h(control, test)\n",
    "\n",
    "    elif effect_size == \"hedges_g\" or effect_size == \"delta_g\":\n",
    "        return hedges_g(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cliffs_delta\":\n",
    "        if is_paired:\n",
    "            err1 = \"`is_paired` is not None; therefore Cliff's delta is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "        else:\n",
    "            return cliffs_delta(control, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def func_difference(control:list|tuple|np.ndarray, # NaNs are automatically discarded.\n",
    "                    test:list|tuple|np.ndarray, # NaNs are automatically discarded.\n",
    "                    func, # Summary function to apply.\n",
    "                    is_paired:str # If not None, computes func(test - control). If None, computes func(test) - func(control).\n",
    "                   )->float:\n",
    "    \"\"\"\n",
    "    \n",
    "    Applies func to `control` and `test`, and then returns the difference.\n",
    "    \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    if is_paired:\n",
    "        if len(control) != len(test):\n",
    "            err = \"The two arrays supplied do not have the same length.\"\n",
    "            raise ValueError(err)\n",
    "\n",
    "        control_nan = np.where(np.isnan(control))[0]\n",
    "        test_nan    = np.where(np.isnan(test))[0]\n",
    "\n",
    "        indexes_to_drop = np.unique(np.concatenate([control_nan,\n",
    "                                                    test_nan]))\n",
    "\n",
    "        good_indexes = [i for i in range(0, len(control))\n",
    "                        if i not in indexes_to_drop]\n",
    "\n",
    "        control = control[good_indexes]\n",
    "        test    = test[good_indexes]\n",
    "\n",
    "        return func(test - control)\n",
    "\n",
    "    else:\n",
    "        control = control[~np.isnan(control)]\n",
    "        test    = test[~np.isnan(test)]\n",
    "        return func(test) - func(control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def cohens_d(control:list|tuple|np.ndarray,\n",
    "             test:list|tuple|np.ndarray,\n",
    "             is_paired:str=None # If not None, the paired Cohen's d is returned.\n",
    "            )->float:\n",
    "    \"\"\"\n",
    "    Computes Cohen's d for test v.s. control.\n",
    "    See [here](https://en.wikipedia.org/wiki/Effect_size#Cohen's_d)\n",
    "\n",
    "    If `is_paired` is None, returns:\n",
    "    \n",
    "    $$\n",
    "    \\\\frac{\\\\bar{X}_2 - \\\\bar{X}_1}{s_{pooled}}\n",
    "    $$\n",
    "    \n",
    "    where\n",
    "    \n",
    "    $$\n",
    "    s_{pooled} = \\\\sqrt{\\\\frac{(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2}{n_1 + n_2 - 2}}\n",
    "    $$\n",
    "    \n",
    "    If `is_paired` is not None, returns:\n",
    "    \n",
    "    $$\n",
    "    \\\\frac{\\\\bar{X}_2 - \\\\bar{X}_1}{s_{avg}}\n",
    "    $$\n",
    "    \n",
    "    where\n",
    "    \n",
    "    $$\n",
    "    s_{avg} = \\\\sqrt{\\\\frac{s_1^2 + s_2^2}{2}}\n",
    "    $$\n",
    "    \n",
    "    `Notes`:\n",
    "\n",
    "    - The sample variance (and standard deviation) uses N-1 degrees of freedoms.\n",
    "    This is an application of Bessel's correction, and yields the unbiased\n",
    "    sample variance.\n",
    "\n",
    "    `References`:\n",
    "    \n",
    "        - https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "        - https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test    = test[~np.isnan(test)]\n",
    "\n",
    "    pooled_sd, average_sd = _compute_standardizers(control, test)\n",
    "    # pooled SD is used for Cohen's d of two independant groups.\n",
    "    # average SD is used for Cohen's d of two paired groups\n",
    "    # (aka repeated measures).\n",
    "    # NOT IMPLEMENTED YET: Correlation adjusted SD is used for Cohen's d of\n",
    "    # two paired groups but accounting for the correlation between\n",
    "    # the two groups.\n",
    "\n",
    "    if is_paired:\n",
    "        # Check control and test are same length.\n",
    "        if len(control) != len(test):\n",
    "            raise ValueError(\"`control` and `test` are not the same length.\")\n",
    "        # assume the two arrays are ordered already.\n",
    "        delta = test - control\n",
    "        M = np.mean(delta)\n",
    "        divisor = average_sd\n",
    "\n",
    "    else:\n",
    "        M = np.mean(test) - np.mean(control)\n",
    "        divisor = pooled_sd\n",
    "        \n",
    "    return M / divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93688770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def cohens_h(control:list|tuple|np.ndarray, \n",
    "             test:list|tuple|np.ndarray\n",
    "            )->float:\n",
    "    '''\n",
    "    Computes Cohen's h for test v.s. control.\n",
    "    See [here](https://en.wikipedia.org/wiki/Cohen%27s_h for reference.)\n",
    "    \n",
    "    `Notes`:\n",
    "    \n",
    "    - Assuming the input data type is binary, i.e. a series of 0s and 1s,\n",
    "    and a dict for mapping the 0s and 1s to the actual labels, e.g.{1: \"Smoker\", 0: \"Non-smoker\"}\n",
    "    '''\n",
    "\n",
    "    import numpy as np\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    import pandas as pd\n",
    "\n",
    "    # Check whether dataframe contains only 0s and 1s.\n",
    "    if np.isin(control, [0, 1]).all() == False or np.isin(test, [0, 1]).all() == False:\n",
    "        raise ValueError(\"Input data must be binary.\")\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    # Aligned with cohens_d calculation.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test = test[~np.isnan(test)]\n",
    "\n",
    "    prop_control = sum(control)/len(control)\n",
    "    prop_test = sum(test)/len(test)\n",
    "\n",
    "    # Arcsine transformation\n",
    "    phi_control = 2 * np.arcsin(np.sqrt(prop_control))\n",
    "    phi_test = 2 * np.arcsin(np.sqrt(prop_test))\n",
    "\n",
    "    return phi_test - phi_control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd77c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def hedges_g(control:list|tuple|np.ndarray, \n",
    "             test:list|tuple|np.ndarray, \n",
    "             is_paired:str=None)->float:\n",
    "    \"\"\"\n",
    "    Computes Hedges' g for  for test v.s. control.\n",
    "    It first computes Cohen's d, then calulates a correction factor based on\n",
    "    the total degress of freedom using the gamma function.\n",
    "\n",
    "    See [here](https://en.wikipedia.org/wiki/Effect_size#Hedges'_g)\n",
    "\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test    = test[~np.isnan(test)]\n",
    "\n",
    "    d = cohens_d(control, test, is_paired)\n",
    "    len_c = len(control)\n",
    "    len_t = len(test)\n",
    "    correction_factor = _compute_hedges_correction_factor(len_c, len_t)\n",
    "    return correction_factor * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def cliffs_delta(control:list|tuple|np.ndarray, \n",
    "                 test:list|tuple|np.ndarray\n",
    "                )->float:\n",
    "    \"\"\"\n",
    "    Computes Cliff's delta for 2 samples.\n",
    "    See [here](https://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    c = control[~np.isnan(control)]\n",
    "    t = test[~np.isnan(test)]\n",
    "\n",
    "    control_n = len(c)\n",
    "    test_n = len(t)\n",
    "\n",
    "    # Note the order of the control and test arrays.\n",
    "    U, _ = mannwhitneyu(t, c, alternative='two-sided')\n",
    "    cliffs_delta = ((2 * U) / (control_n * test_n)) - 1\n",
    "\n",
    "    # more = 0\n",
    "    # less = 0\n",
    "    #\n",
    "    # for i, c in enumerate(control):\n",
    "    #     for j, t in enumerate(test):\n",
    "    #         if t > c:\n",
    "    #             more += 1\n",
    "    #         elif t < c:\n",
    "    #             less += 1\n",
    "    #\n",
    "    # cliffs_delta = (more - less) / (control_n * test_n)\n",
    "\n",
    "    return cliffs_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a772510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _compute_standardizers(control, test):\n",
    "    from numpy import mean, var, sqrt, nan\n",
    "    # For calculation of correlation; not currently used.\n",
    "    # from scipy.stats import pearsonr\n",
    "\n",
    "    control_n = len(control)\n",
    "    test_n = len(test)\n",
    "\n",
    "    control_mean = mean(control)\n",
    "    test_mean = mean(test)\n",
    "\n",
    "    control_var = var(control, ddof=1) # use N-1 to compute the variance.\n",
    "    test_var = var(test, ddof=1)\n",
    "\n",
    "    control_std = sqrt(control_var)\n",
    "    test_std = sqrt(test_var)\n",
    "\n",
    "    # For unpaired 2-groups standardized mean difference.\n",
    "    pooled = sqrt(((control_n - 1) * control_var + (test_n - 1) * test_var) /\n",
    "               (control_n + test_n - 2)\n",
    "               )\n",
    "\n",
    "    # For paired standardized mean difference.\n",
    "    average = sqrt((control_var + test_var) / 2)\n",
    "\n",
    "    # if len(control) == len(test):\n",
    "    #     corr = pearsonr(control, test)[0]\n",
    "    #     std_diff = sqrt(control_var + test_var - (2 * corr * control_std * test_std))\n",
    "    #     std_diff_corrected = std_diff / (sqrt(2 * (1 - corr)))\n",
    "    #     return pooled, average, std_diff_corrected\n",
    "    #\n",
    "    # else:\n",
    "    return pooled, average # indent if you implement above code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _compute_hedges_correction_factor(n1, \n",
    "                                      n2\n",
    "                                     )->float:\n",
    "    \"\"\"\n",
    "    Computes the bias correction factor for Hedges' g.\n",
    "\n",
    "    See [here](https://en.wikipedia.org/wiki/Effect_size#Hedges'_g)\n",
    "\n",
    "    `References`:\n",
    "    \n",
    "    - Larry V. Hedges & Ingram Olkin (1985).\n",
    "    Statistical Methods for Meta-Analysis. Orlando: Academic Press.\n",
    "    ISBN 0-12-336380-2.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.special import gamma\n",
    "    from numpy import sqrt, isinf\n",
    "    import warnings\n",
    "\n",
    "    df = n1 + n2 - 2\n",
    "    numer = gamma(df / 2)\n",
    "    denom0 = gamma((df - 1) / 2)\n",
    "    denom = sqrt(df / 2) * denom0\n",
    "\n",
    "    if isinf(numer) or isinf(denom):\n",
    "        # occurs when df is too large.\n",
    "        # Apply Hedges and Olkin's approximation.\n",
    "        df_sum = n1 + n2\n",
    "        denom = (4 * df_sum) - 9\n",
    "        out = 1 - (3 / denom)\n",
    "\n",
    "    else:\n",
    "        out = numer / denom\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def weighted_delta(difference, group_var):\n",
    "    '''\n",
    "    Compute the weighted deltas where the weight is the inverse of the\n",
    "    pooled group difference.\n",
    "    '''\n",
    "    import numpy as np\n",
    "\n",
    "    weight = np.true_divide(1, group_var)\n",
    "    return np.sum(difference*weight)/np.sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca3f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
