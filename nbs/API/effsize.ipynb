{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a807e60",
   "metadata": {},
   "source": [
    "# effsize\n",
    "\n",
    "- order: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp effsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6673b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def two_group_difference(control, test, is_paired=False,\n",
    "                        effect_size=\"mean_diff\"):\n",
    "    \"\"\"\n",
    "    Computes the following metrics for control and test:\n",
    "        - Unstandardized mean difference\n",
    "        - Standardized mean differences (paired or unpaired)\n",
    "            * Cohen's d\n",
    "            * Hedges' g\n",
    "        - Median difference\n",
    "        - Cliff's Delta\n",
    "        - Cohen's h (distance between two proportions)\n",
    "\n",
    "    See the Wikipedia entry here: https://bit.ly/2LzWokf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    control, test: list, tuple, or ndarray.\n",
    "        Accepts lists, tuples, or numpy ndarrays of numeric types.\n",
    "\n",
    "    is_paired: boolean, default False.\n",
    "        If True, returns the paired Cohen's d.\n",
    "\n",
    "    effect_size: string, default \"mean_diff\"\n",
    "        Any one of the following effect sizes:\n",
    "        [\"mean_diff\", \"median_diff\", \"cohens_d\", \"hedges_g\", \"cliffs_delta\"]\n",
    "\n",
    "        mean_diff:      This is simply the mean of `control` subtracted from\n",
    "                        the mean of `test`.\n",
    "\n",
    "        cohens_d:       This is the mean of control subtracted from the\n",
    "                        mean of test, divided by the pooled standard deviation\n",
    "                        of control and test. The pooled SD is the square as:\n",
    "\n",
    "\n",
    "                               (n1 - 1) * var(control) + (n2 - 1) * var(test)\n",
    "                        sqrt (   -------------------------------------------  )\n",
    "                                                 (n1 + n2 - 2)\n",
    "\n",
    "                        where n1 and n2 are the sizes of control and test\n",
    "                        respectively.\n",
    "\n",
    "        hedges_g:       This is Cohen's d corrected for bias via multiplication\n",
    "                         with the following correction factor:\n",
    "\n",
    "                                        gamma(n/2)\n",
    "                        J(n) = ------------------------------\n",
    "                               sqrt(n/2) * gamma((n - 1) / 2)\n",
    "\n",
    "                        where n = (n1 + n2 - 2).\n",
    "\n",
    "        median_diff:    This is the median of `control` subtracted from the\n",
    "                        median of `test`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        float: The desired effect size.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if effect_size == \"mean_diff\":\n",
    "        return func_difference(control, test, np.mean, is_paired)\n",
    "\n",
    "    elif effect_size == \"median_diff\":\n",
    "        return func_difference(control, test, np.median, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_d\":\n",
    "        return cohens_d(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_h\":\n",
    "        return cohens_h(control, test)\n",
    "\n",
    "    elif effect_size == \"hedges_g\":\n",
    "        return hedges_g(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cliffs_delta\":\n",
    "        if is_paired is True:\n",
    "            err1 = \"`is_paired` is True; therefore Cliff's delta is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "        else:\n",
    "            return cliffs_delta(control, test)\n",
    "\n",
    "\n",
    "\n",
    "def func_difference(control, test, func, is_paired):\n",
    "    \"\"\"\n",
    "    Applies func to `control` and `test`, and then returns the difference.\n",
    "\n",
    "    Keywords:\n",
    "    --------\n",
    "        control, test: List, tuple, or array.\n",
    "            NaNs are automatically discarded.\n",
    "\n",
    "        func: summary function to apply.\n",
    "\n",
    "        is_paired: boolean.\n",
    "            If True, computes func(test - control).\n",
    "            If False, computes func(test) - func(control).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        diff: float.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    if is_paired:\n",
    "        if len(control) != len(test):\n",
    "            err = \"The two arrays supplied do not have the same length.\"\n",
    "            raise ValueError(err)\n",
    "\n",
    "        control_nan = np.where(np.isnan(control))[0]\n",
    "        test_nan    = np.where(np.isnan(test))[0]\n",
    "\n",
    "        indexes_to_drop = np.unique(np.concatenate([control_nan,\n",
    "                                                    test_nan]))\n",
    "\n",
    "        good_indexes = [i for i in range(0, len(control))\n",
    "                        if i not in indexes_to_drop]\n",
    "\n",
    "        control = control[good_indexes]\n",
    "        test    = test[good_indexes]\n",
    "\n",
    "        return func(test - control)\n",
    "\n",
    "    else:\n",
    "        control = control[~np.isnan(control)]\n",
    "        test    = test[~np.isnan(test)]\n",
    "        return func(test) - func(control)\n",
    "\n",
    "\n",
    "\n",
    "def cohens_d(control, test, is_paired=False):\n",
    "    \"\"\"\n",
    "    Computes Cohen's d for test v.s. control.\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Cohen's_d\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: List, tuple, or array.\n",
    "\n",
    "    is_paired: boolean, default False\n",
    "        If True, the paired Cohen's d is returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        d: float.\n",
    "            If is_paired is False, this is equivalent to:\n",
    "            (numpy.mean(test) - numpy.mean(control))  / pooled StDev\n",
    "\n",
    "            If is_paired is True, returns\n",
    "            (numpy.mean(test) - numpy.mean(control))  / average StDev\n",
    "\n",
    "            The pooled standard deviation is equal to:\n",
    "\n",
    "                   (n1 - 1) * var(control) + (n2 - 1) * var (test)\n",
    "            sqrt(  ---------------------------------------------- )\n",
    "                           (n1 + n2 - 2)\n",
    "\n",
    "\n",
    "            The average standard deviation is equal to:\n",
    "\n",
    "\n",
    "                  var(control) + var(test)\n",
    "            sqrt( ------------------------- )\n",
    "                             2\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The sample variance (and standard deviation) uses N-1 degrees of freedoms.\n",
    "    This is an application of Bessel's correction, and yields the unbiased\n",
    "    sample variance.\n",
    "\n",
    "    References:\n",
    "        https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "        https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test    = test[~np.isnan(test)]\n",
    "\n",
    "    pooled_sd, average_sd = _compute_standardizers(control, test)\n",
    "    # pooled SD is used for Cohen's d of two independant groups.\n",
    "    # average SD is used for Cohen's d of two paired groups\n",
    "    # (aka repeated measures).\n",
    "    # NOT IMPLEMENTED YET: Correlation adjusted SD is used for Cohen's d of\n",
    "    # two paired groups but accounting for the correlation between\n",
    "    # the two groups.\n",
    "\n",
    "    if is_paired:\n",
    "        # Check control and test are same length.\n",
    "        if len(control) != len(test):\n",
    "            raise ValueError(\"`control` and `test` are not the same length.\")\n",
    "        # assume the two arrays are ordered already.\n",
    "        delta = test - control\n",
    "        M = np.mean(delta)\n",
    "        divisor = average_sd\n",
    "\n",
    "    else:\n",
    "        M = np.mean(test) - np.mean(control)\n",
    "        divisor = pooled_sd\n",
    "        \n",
    "    return M / divisor\n",
    "\n",
    "\n",
    "\n",
    "def cohens_h(control, test):\n",
    "    '''\n",
    "    Computes Cohen's h for test v.s. control.\n",
    "    See https://en.wikipedia.org/wiki/Cohen%27s_h for reference.\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: List, tuple, or array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        h: float.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "        Assuming the input data type is binary, i.e. a series of 0s and 1s,\n",
    "        and a dict for mapping the 0s and 1s to the actual labels, e.g.\n",
    "        {1: \"Smoker\", \n",
    "        0: \"Non-smoker\"}\n",
    "    '''\n",
    "\n",
    "    import numpy as np\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    import pandas as pd\n",
    "\n",
    "    # Check whether dataframe contains only 0s and 1s.\n",
    "    try:\n",
    "        pd.unique(control)==np.array([0,1]).all()==False and (pd.unique(test)==np.array([0,1])).all()==False\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    # Aligned with cohens_d calculation.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test = test[~np.isnan(test)]\n",
    "\n",
    "    prop_control = sum(control)/len(control)\n",
    "    prop_test = sum(test)/len(test)\n",
    "\n",
    "    # Arcsine transformation\n",
    "    phi_control = 2 * np.arcsin(np.sqrt(prop_control))\n",
    "    phi_test = 2 * np.arcsin(np.sqrt(prop_test))\n",
    "\n",
    "    return phi_test - phi_control\n",
    "\n",
    "    \n",
    "\n",
    "def hedges_g(control, test, is_paired=False):\n",
    "    \"\"\"\n",
    "    Computes Hedges' g for  for test v.s. control.\n",
    "    It first computes Cohen's d, then calulates a correction factor based on\n",
    "    the total degress of freedom using the gamma function.\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Hedges'_g\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: numeric iterables.\n",
    "        These can be lists, tuples, or arrays of numeric types.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        g: float.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test    = test[~np.isnan(test)]\n",
    "\n",
    "    d = cohens_d(control, test, is_paired)\n",
    "    len_c = len(control)\n",
    "    len_t = len(test)\n",
    "    correction_factor = _compute_hedges_correction_factor(len_c, len_t)\n",
    "    return correction_factor * d\n",
    "\n",
    "\n",
    "\n",
    "def cliffs_delta(control, test):\n",
    "    \"\"\"\n",
    "    Computes Cliff's delta for 2 samples.\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: numeric iterables.\n",
    "        These can be lists, tuples, or arrays of numeric types.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A single numeric float.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    c = control[~np.isnan(control)]\n",
    "    t = test[~np.isnan(test)]\n",
    "\n",
    "    control_n = len(c)\n",
    "    test_n = len(t)\n",
    "\n",
    "    # Note the order of the control and test arrays.\n",
    "    U, _ = mannwhitneyu(t, c, alternative='two-sided')\n",
    "    cliffs_delta = ((2 * U) / (control_n * test_n)) - 1\n",
    "\n",
    "    # more = 0\n",
    "    # less = 0\n",
    "    #\n",
    "    # for i, c in enumerate(control):\n",
    "    #     for j, t in enumerate(test):\n",
    "    #         if t > c:\n",
    "    #             more += 1\n",
    "    #         elif t < c:\n",
    "    #             less += 1\n",
    "    #\n",
    "    # cliffs_delta = (more - less) / (control_n * test_n)\n",
    "\n",
    "    return cliffs_delta\n",
    "\n",
    "\n",
    "\n",
    "def _compute_standardizers(control, test):\n",
    "    from numpy import mean, var, sqrt, nan\n",
    "    # For calculation of correlation; not currently used.\n",
    "    # from scipy.stats import pearsonr\n",
    "\n",
    "    control_n = len(control)\n",
    "    test_n = len(test)\n",
    "\n",
    "    control_mean = mean(control)\n",
    "    test_mean = mean(test)\n",
    "\n",
    "    control_var = var(control, ddof=1) # use N-1 to compute the variance.\n",
    "    test_var = var(test, ddof=1)\n",
    "\n",
    "    control_std = sqrt(control_var)\n",
    "    test_std = sqrt(test_var)\n",
    "\n",
    "    # For unpaired 2-groups standardized mean difference.\n",
    "    pooled = sqrt(((control_n - 1) * control_var + (test_n - 1) * test_var) /\n",
    "               (control_n + test_n - 2)\n",
    "               )\n",
    "\n",
    "    # For paired standardized mean difference.\n",
    "    average = sqrt((control_var + test_var) / 2)\n",
    "\n",
    "    # if len(control) == len(test):\n",
    "    #     corr = pearsonr(control, test)[0]\n",
    "    #     std_diff = sqrt(control_var + test_var - (2 * corr * control_std * test_std))\n",
    "    #     std_diff_corrected = std_diff / (sqrt(2 * (1 - corr)))\n",
    "    #     return pooled, average, std_diff_corrected\n",
    "    #\n",
    "    # else:\n",
    "    return pooled, average # indent if you implement above code chunk.\n",
    "\n",
    "\n",
    "\n",
    "def _compute_hedges_correction_factor(n1, n2):\n",
    "    \"\"\"\n",
    "    Computes the bias correction factor for Hedges' g.\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Hedges'_g\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        j: float\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Larry V. Hedges & Ingram Olkin (1985).\n",
    "    Statistical Methods for Meta-Analysis. Orlando: Academic Press.\n",
    "    ISBN 0-12-336380-2.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.special import gamma\n",
    "    from numpy import sqrt, isinf\n",
    "    import warnings\n",
    "\n",
    "    df = n1 + n2 - 2\n",
    "    numer = gamma(df / 2)\n",
    "    denom0 = gamma((df - 1) / 2)\n",
    "    denom = sqrt(df / 2) * denom0\n",
    "\n",
    "    if isinf(numer) or isinf(denom):\n",
    "        # occurs when df is too large.\n",
    "        # Apply Hedges and Olkin's approximation.\n",
    "        df_sum = n1 + n2\n",
    "        denom = (4 * df_sum) - 9\n",
    "        out = 1 - (3 / denom)\n",
    "\n",
    "    else:\n",
    "        out = numer / denom\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def weighted_delta(difference, group_var):\n",
    "    import numpy as np\n",
    "\n",
    "    weight = np.true_divide(1, group_var)\n",
    "    return np.sum(difference*weight)/np.sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd20e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
