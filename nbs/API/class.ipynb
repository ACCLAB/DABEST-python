{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed122c74",
   "metadata": {},
   "source": [
    "# Class\n",
    "\n",
    "> Several class for estimation statistics and plots.\n",
    "\n",
    "- order: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd32470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__version__ = \"2023.02.14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dabest(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Class for estimation statistics and plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, idx, x, y, paired, id_col, ci, \n",
    "                resamples, random_seed, proportional, delta2, \n",
    "                experiment, experiment_label, x1_level, mini_meta):\n",
    "\n",
    "        \"\"\"\n",
    "        Parses and stores pandas DataFrames in preparation for estimation\n",
    "        statistics. You should not be calling this class directly; instead,\n",
    "        use `dabest.load()` to parse your DataFrame prior to analysis.\n",
    "        \"\"\"\n",
    "\n",
    "        # Import standard data science libraries.\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import seaborn as sns\n",
    "\n",
    "        self.__delta2       = delta2\n",
    "        self.__experiment   = experiment\n",
    "        self.__ci           = ci\n",
    "        self.__data         = data\n",
    "        self.__id_col       = id_col\n",
    "        self.__is_paired    = paired\n",
    "        self.__resamples    = resamples\n",
    "        self.__random_seed  = random_seed\n",
    "        self.__proportional = proportional\n",
    "        self.__mini_meta    = mini_meta \n",
    "\n",
    "        # Make a copy of the data, so we don't make alterations to it.\n",
    "        data_in = data.copy()\n",
    "        # data_in.reset_index(inplace=True)\n",
    "        # data_in_index_name = data_in.index.name\n",
    "\n",
    "\n",
    "        # Check if it is a valid mini_meta case\n",
    "        if mini_meta is True:\n",
    "\n",
    "            # Only mini_meta calculation but not proportional and delta-delta function\n",
    "            if proportional is True:\n",
    "                err0 = '`proportional` and `mini_meta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            elif delta2 is True:\n",
    "                err0 = '`delta` and `mini_meta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            \n",
    "            # Check if the columns stated are valid\n",
    "            if all([isinstance(i, str) for i in idx]):\n",
    "                if len(pd.unique([t for t in idx]).tolist())!=2:\n",
    "                    err0 = '`mini_meta` is True, but `idx` ({})'.format(idx) \n",
    "                    err1 = 'does not contain exactly 2 columns.'\n",
    "                    raise ValueError(err0 + err1)\n",
    "            elif all([isinstance(i, (tuple, list)) for i in idx]):\n",
    "                all_idx_lengths = [len(t) for t in idx]\n",
    "                if (np.array(all_idx_lengths) != 2).any():\n",
    "                    err1 = \"`mini_meta` is True, but some idx \"\n",
    "                    err2 = \"in {} does not consist only of two groups.\".format(idx)\n",
    "                    raise ValueError(err1 + err2)\n",
    "            \n",
    "\n",
    "\n",
    "        # Check if this is a 2x2 ANOVA case and x & y are valid columns\n",
    "        # Create experiment_label and x1_level\n",
    "        if delta2 is True:\n",
    "            if proportional is True:\n",
    "                err0 = '`proportional` and `delta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            # idx should not be specified\n",
    "            if idx:\n",
    "                err0 = '`idx` should not be specified when `delta2` is True.'.format(len(x))\n",
    "                raise ValueError(err0)\n",
    "\n",
    "            # Check if x is valid\n",
    "            if len(x) != 2:\n",
    "                err0 = '`delta2` is True but the number of variables indicated by `x` is {}.'.format(len(x))\n",
    "                raise ValueError(err0)\n",
    "            else:\n",
    "                for i in x:\n",
    "                    if i not in data_in.columns:\n",
    "                        err = '{0} is not a column in `data`. Please check.'.format(i)\n",
    "                        raise IndexError(err)\n",
    "\n",
    "            # Check if y is valid\n",
    "            if not y:\n",
    "                err0 = '`delta2` is True but `y` is not indicated.'\n",
    "                raise ValueError(err0)\n",
    "            elif y not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(y)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # Check if experiment is valid\n",
    "            if experiment not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(experiment)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # Check if experiment_label is valid and create experiment when needed\n",
    "            if experiment_label:\n",
    "                if len(experiment_label) != 2:\n",
    "                    err0 = '`experiment_label` does not have a length of 2.'\n",
    "                    raise ValueError(err0)\n",
    "                else: \n",
    "                    for i in experiment_label:\n",
    "                        if i not in data_in[experiment].unique():\n",
    "                            err = '{0} is not an element in the column `{1}` of `data`. Please check.'.format(i, experiment)\n",
    "                            raise IndexError(err)\n",
    "            else:\n",
    "                experiment_label = data_in[experiment].unique()\n",
    "\n",
    "            # Check if x1_level is valid\n",
    "            if x1_level:\n",
    "                if len(x1_level) != 2:\n",
    "                    err0 = '`x1_level` does not have a length of 2.'\n",
    "                    raise ValueError(err0)\n",
    "                else: \n",
    "                    for i in x1_level:\n",
    "                        if i not in data_in[x[0]].unique():\n",
    "                            err = '{0} is not an element in the column `{1}` of `data`. Please check.'.format(i, experiment)\n",
    "                            raise IndexError(err)\n",
    "\n",
    "            else:\n",
    "                x1_level = data_in[x[0]].unique()    \n",
    "        self.__experiment_label = experiment_label\n",
    "        self.__x1_level         = x1_level\n",
    "\n",
    "\n",
    "        # Check if idx is specified\n",
    "        if delta2 is False and not idx:\n",
    "            err = '`idx` is not a column in `data`. Please check.'\n",
    "            raise IndexError(err)\n",
    "\n",
    "\n",
    "        # create new x & idx and record the second variable if this is a valid 2x2 ANOVA case\n",
    "        if delta2 is True:\n",
    "            # add a new column which is a combination of experiment and the first variable\n",
    "            new_col_name = experiment+x[0]\n",
    "            while new_col_name in data_in.columns:\n",
    "                new_col_name += \"_\"\n",
    "            data_in[new_col_name] = data_in[x[0]].astype(str) + \" \" + data_in[experiment].astype(str)\n",
    "\n",
    "            #create idx and record the first and second x variable            \n",
    "            idx = []\n",
    "            for i in list(map(lambda x: str(x), experiment_label)):\n",
    "                temp = []\n",
    "                for j in list(map(lambda x: str(x), x1_level)):\n",
    "                    temp.append(j + \" \" + i)\n",
    "                idx.append(temp)\n",
    "                     \n",
    "            self.__idx = idx\n",
    "            self.__x1  = x[0]\n",
    "            self.__x2  = x[1]\n",
    "            x = new_col_name\n",
    "        else:\n",
    "            self.__idx = idx\n",
    "            self.__x1  = None\n",
    "            self.__x2  = None\n",
    "\n",
    "\n",
    "\n",
    "        # Determine the kind of estimation plot we need to produce.\n",
    "        if all([isinstance(i, str) for i in idx]):\n",
    "            # flatten out idx.\n",
    "            all_plot_groups = pd.unique([t for t in idx]).tolist()\n",
    "            if len(idx) > len(all_plot_groups):\n",
    "                err0 = '`idx` contains duplicated groups. Please remove any duplicates and try again.'\n",
    "                raise ValueError(err0)\n",
    "                \n",
    "            # We need to re-wrap this idx inside another tuple so as to\n",
    "            # easily loop thru each pairwise group later on.\n",
    "            self.__idx = (idx,)\n",
    "\n",
    "        elif all([isinstance(i, (tuple, list)) for i in idx]):\n",
    "            all_plot_groups = pd.unique([tt for t in idx for tt in t]).tolist()\n",
    "            \n",
    "            actual_groups_given = sum([len(i) for i in idx])\n",
    "            \n",
    "            if actual_groups_given > len(all_plot_groups):\n",
    "                err0 = 'Groups are repeated across tuples,'\n",
    "                err1 = ' or a tuple has repeated groups in it.'\n",
    "                err2 = ' Please remove any duplicates and try again.'\n",
    "                raise ValueError(err0 + err1 + err2)\n",
    "\n",
    "        else: # mix of string and tuple?\n",
    "            err = 'There seems to be a problem with the idx you'\n",
    "            'entered--{}.'.format(idx)\n",
    "            raise ValueError(err)\n",
    "\n",
    "        # Having parsed the idx, check if it is a kosher paired plot,\n",
    "        # if so stated.\n",
    "        #if paired is True:\n",
    "        #    all_idx_lengths = [len(t) for t in self.__idx]\n",
    "        #    if (np.array(all_idx_lengths) != 2).any():\n",
    "        #        err1 = \"`is_paired` is True, but some idx \"\n",
    "        #        err2 = \"in {} does not consist only of two groups.\".format(idx)\n",
    "        #        raise ValueError(err1 + err2)\n",
    "\n",
    "        # Check if there is a typo on paired\n",
    "        if paired is not None:\n",
    "            if paired not in (\"baseline\", \"sequential\"):\n",
    "                err = '{} assigned for `paired` is not valid.'.format(paired)\n",
    "                raise ValueError(err)\n",
    "\n",
    "\n",
    "        # Determine the type of data: wide or long.\n",
    "        if x is None and y is not None:\n",
    "            err = 'You have only specified `y`. Please also specify `x`.'\n",
    "            raise ValueError(err)\n",
    "\n",
    "        elif y is None and x is not None:\n",
    "            err = 'You have only specified `x`. Please also specify `y`.'\n",
    "            raise ValueError(err)\n",
    "\n",
    "        # Identify the type of data that was passed in.\n",
    "        elif x is not None and y is not None:\n",
    "            # Assume we have a long dataset.\n",
    "            # check both x and y are column names in data.\n",
    "            if x not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(x)\n",
    "                raise IndexError(err)\n",
    "            if y not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(y)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # check y is numeric.\n",
    "            if not np.issubdtype(data_in[y].dtype, np.number):\n",
    "                err = '{0} is a column in `data`, but it is not numeric.'.format(y)\n",
    "                raise ValueError(err)\n",
    "\n",
    "            # check all the idx can be found in data_in[x]\n",
    "            for g in all_plot_groups:\n",
    "                if g not in data_in[x].unique():\n",
    "                    err0 = '\"{0}\" is not a group in the column `{1}`.'.format(g, x)\n",
    "                    err1 = \" Please check `idx` and try again.\"\n",
    "                    raise IndexError(err0 + err1)\n",
    "\n",
    "            # Select only rows where the value in the `x` column \n",
    "            # is found in `idx`.\n",
    "            plot_data = data_in[data_in.loc[:, x].isin(all_plot_groups)].copy()\n",
    "            \n",
    "            # plot_data.drop(\"index\", inplace=True, axis=1)\n",
    "\n",
    "            # Assign attributes\n",
    "            self.__x = x\n",
    "            self.__y = y\n",
    "            self.__xvar = x\n",
    "            self.__yvar = y\n",
    "\n",
    "        elif x is None and y is None:\n",
    "            # Assume we have a wide dataset.\n",
    "            # Assign attributes appropriately.\n",
    "            self.__x = None\n",
    "            self.__y = None\n",
    "            self.__xvar = \"group\"\n",
    "            self.__yvar = \"value\"\n",
    "\n",
    "            # First, check we have all columns in the dataset.\n",
    "            for g in all_plot_groups:\n",
    "                if g not in data_in.columns:\n",
    "                    err0 = '\"{0}\" is not a column in `data`.'.format(g)\n",
    "                    err1 = \" Please check `idx` and try again.\"\n",
    "                    raise IndexError(err0 + err1)\n",
    "                    \n",
    "            set_all_columns     = set(data_in.columns.tolist())\n",
    "            set_all_plot_groups = set(all_plot_groups)\n",
    "            id_vars = set_all_columns.difference(set_all_plot_groups)\n",
    "\n",
    "            plot_data = pd.melt(data_in,\n",
    "                                id_vars=id_vars,\n",
    "                                value_vars=all_plot_groups,\n",
    "                                value_name=self.__yvar,\n",
    "                                var_name=self.__xvar)\n",
    "                                \n",
    "        # Added in v0.2.7.\n",
    "        # remove any NA rows.\n",
    "        plot_data.dropna(axis=0, how='any', subset=[self.__yvar], inplace=True)\n",
    "\n",
    "        \n",
    "        # Lines 131 to 140 added in v0.2.3.\n",
    "        # Fixes a bug that jammed up when the xvar column was already \n",
    "        # a pandas Categorical. Now we check for this and act appropriately.\n",
    "        if isinstance(plot_data[self.__xvar].dtype, \n",
    "                      pd.CategoricalDtype) is True:\n",
    "            plot_data[self.__xvar].cat.remove_unused_categories(inplace=True)\n",
    "            plot_data[self.__xvar].cat.reorder_categories(all_plot_groups, \n",
    "                                                          ordered=True, \n",
    "                                                          inplace=True)\n",
    "        else:\n",
    "            plot_data.loc[:, self.__xvar] = pd.Categorical(plot_data[self.__xvar],\n",
    "                                               categories=all_plot_groups,\n",
    "                                               ordered=True)\n",
    "        \n",
    "        # # The line below was added in v0.2.4, removed in v0.2.5.\n",
    "        # plot_data.dropna(inplace=True)\n",
    "        \n",
    "        self.__plot_data = plot_data\n",
    "        \n",
    "        self.__all_plot_groups = all_plot_groups\n",
    "\n",
    "\n",
    "        # Sanity check that all idxs are paired, if so desired.\n",
    "        #if paired is True:\n",
    "        #    if id_col is None:\n",
    "        #        err = \"`id_col` must be specified if `is_paired` is set to True.\"\n",
    "        #        raise IndexError(err)\n",
    "        #    elif id_col not in plot_data.columns:\n",
    "        #        err = \"{} is not a column in `data`. \".format(id_col)\n",
    "        #        raise IndexError(err)\n",
    "\n",
    "        # Check if `id_col` is valid\n",
    "        if paired:\n",
    "            if id_col is None:\n",
    "                err = \"`id_col` must be specified if `paired` is assigned with a not NoneType value.\"\n",
    "                raise IndexError(err)\n",
    "            elif id_col not in plot_data.columns:\n",
    "                err = \"{} is not a column in `data`. \".format(id_col)\n",
    "                raise IndexError(err)\n",
    "\n",
    "        EffectSizeDataFrame_kwargs = dict(ci=ci, is_paired=paired,\n",
    "                                           random_seed=random_seed,\n",
    "                                           resamples=resamples,\n",
    "                                           proportional=proportional, \n",
    "                                           delta2=delta2, \n",
    "                                           experiment_label=self.__experiment_label,\n",
    "                                           x1_level=self.__x1_level,\n",
    "                                           x2=self.__x2,\n",
    "                                           mini_meta = mini_meta)\n",
    "\n",
    "        self.__mean_diff    = EffectSizeDataFrame(self, \"mean_diff\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__median_diff  = EffectSizeDataFrame(self, \"median_diff\",\n",
    "                                               **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__cohens_d     = EffectSizeDataFrame(self, \"cohens_d\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__cohens_h     = EffectSizeDataFrame(self, \"cohens_h\",\n",
    "                                                **EffectSizeDataFrame_kwargs)                                       \n",
    "\n",
    "        self.__hedges_g     = EffectSizeDataFrame(self, \"hedges_g\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        if not paired:\n",
    "            self.__cliffs_delta = EffectSizeDataFrame(self, \"cliffs_delta\",\n",
    "                                                    **EffectSizeDataFrame_kwargs)\n",
    "        else:\n",
    "            self.__cliffs_delta = \"The data is paired; Cliff's delta is therefore undefined.\"\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        from .__init__ import __version__\n",
    "        import datetime as dt\n",
    "        import numpy as np\n",
    "\n",
    "        from .misc_tools import print_greeting\n",
    "\n",
    "        # Removed due to the deprecation of is_paired\n",
    "        #if self.__is_paired:\n",
    "        #    es = \"Paired e\"\n",
    "        #else:\n",
    "        #    es = \"E\"\n",
    "\n",
    "        greeting_header = print_greeting()\n",
    "\n",
    "        RM_STATUS = {'baseline'  : 'for repeated measures against baseline \\n', \n",
    "                     'sequential': 'for the sequential design of repeated-measures experiment \\n',\n",
    "                     'None'      : ''\n",
    "                    }\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'Paired e', \n",
    "                         'sequential' : 'Paired e',\n",
    "                         'None'       : 'E'\n",
    "        }\n",
    "\n",
    "        first_line = {\"rm_status\"    : RM_STATUS[str(self.__is_paired)],\n",
    "                      \"paired_status\": PAIRED_STATUS[str(self.__is_paired)]}\n",
    "\n",
    "        s1 = \"{paired_status}ffect size(s) {rm_status}\".format(**first_line)\n",
    "        s2 = \"with {}% confidence intervals will be computed for:\".format(self.__ci)\n",
    "        desc_line = s1 + s2\n",
    "\n",
    "        out = [greeting_header + \"\\n\\n\" + desc_line]\n",
    "\n",
    "        comparisons = []\n",
    "\n",
    "        if self.__is_paired == 'sequential':\n",
    "            for j, current_tuple in enumerate(self.__idx):\n",
    "                for ix, test_name in enumerate(current_tuple[1:]):\n",
    "                    control_name = current_tuple[ix]\n",
    "                    comparisons.append(\"{} minus {}\".format(test_name, control_name))\n",
    "        else:\n",
    "            for j, current_tuple in enumerate(self.__idx):\n",
    "                control_name = current_tuple[0]\n",
    "\n",
    "                for ix, test_name in enumerate(current_tuple[1:]):\n",
    "                    comparisons.append(\"{} minus {}\".format(test_name, control_name))\n",
    "\n",
    "        if self.__delta2 is True:\n",
    "            comparisons.append(\"{} minus {} (only for mean difference)\".format(self.__experiment_label[1], self.__experiment_label[0]))\n",
    "        \n",
    "        if self.__mini_meta is True:\n",
    "            comparisons.append(\"weighted delta (only for mean difference)\")\n",
    "\n",
    "        for j, g in enumerate(comparisons):\n",
    "            out.append(\"{}. {}\".format(j+1, g))\n",
    "\n",
    "        resamples_line1 = \"\\n{} resamples \".format(self.__resamples)\n",
    "        resamples_line2 = \"will be used to generate the effect size bootstraps.\"\n",
    "        out.append(resamples_line1 + resamples_line2)\n",
    "\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "\n",
    "    # def __variable_name(self):\n",
    "    #     return [k for k,v in locals().items() if v is self]\n",
    "    #\n",
    "    # @property\n",
    "    # def variable_name(self):\n",
    "    #     return self.__variable_name()\n",
    "    \n",
    "    @property\n",
    "    def mean_diff(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the mean difference, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.mean_diff\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This is simply the mean of the control group subtracted from\n",
    "        the mean of the test group.\n",
    "        \n",
    "        .. math::\n",
    "            \\\\text{Mean difference} = \\\\overline{x}_{Test} - \\\\overline{x}_{Control}\n",
    "            \n",
    "        where :math:`\\\\overline{x}` is the mean for the group :math:`x`.\n",
    "        \"\"\"\n",
    "        return self.__mean_diff\n",
    "        \n",
    "        \n",
    "    @property    \n",
    "    def median_diff(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the median difference, its confidence interval, and relevant statistics, for all comparisons  as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.median_diff\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This is the median difference between the control group and the test group.\n",
    "        \n",
    "        If the comparison(s) are unpaired, median_diff is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            \\\\text{Median difference} = \\\\widetilde{x}_{Test} - \\\\widetilde{x}_{Control}\n",
    "            \n",
    "        where :math:`\\\\widetilde{x}` is the median for the group :math:`x`.\n",
    "\n",
    "        If the comparison(s) are paired, median_diff is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            \\\\text{Median difference} = \\\\widetilde{x}_{Test - Control}\n",
    "\n",
    "        \"\"\"\n",
    "        return self.__median_diff\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def cohens_d(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Cohen's `d`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.cohens_d\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        Cohen's `d` is simply the mean of the control group subtracted from\n",
    "        the mean of the test group.\n",
    "        \n",
    "        If `paired` is None, then the comparison(s) are unpaired; \n",
    "        otherwise the comparison(s) are paired.\n",
    "\n",
    "        If the comparison(s) are unpaired, Cohen's `d` is computed with the following equation:\n",
    "        \n",
    "        .. math::\n",
    "            \n",
    "            d = \\\\frac{\\\\overline{x}_{Test} - \\\\overline{x}_{Control}} {\\\\text{pooled standard deviation}}\n",
    "                \n",
    "        \n",
    "        For paired comparisons, Cohen's d is given by\n",
    "        \n",
    "        .. math::\n",
    "            d = \\\\frac{\\\\overline{x}_{Test} - \\\\overline{x}_{Control}} {\\\\text{average standard deviation}}\n",
    "            \n",
    "        where :math:`\\\\overline{x}` is the mean of the respective group of observations, :math:`{Var}_{x}` denotes the variance of that group,\n",
    "        \n",
    "        .. math::\n",
    "        \n",
    "            \\\\text{pooled standard deviation} = \\\\sqrt{ \\\\frac{(n_{control} - 1) * {Var}_{control} + (n_{test} - 1) * {Var}_{test} } {n_{control} + n_{test} - 2} }\n",
    "        \n",
    "        and\n",
    "        \n",
    "        .. math::\n",
    "        \n",
    "            \\\\text{average standard deviation} = \\\\sqrt{ \\\\frac{{Var}_{control} + {Var}_{test}} {2}}\n",
    "            \n",
    "        The sample variance (and standard deviation) uses N-1 degrees of freedoms.\n",
    "        This is an application of `Bessel's correction <https://en.wikipedia.org/wiki/Bessel%27s_correction>`_, and yields the unbiased\n",
    "        sample variance.\n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Cohen's_d\n",
    "            https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "            https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n",
    "        \"\"\"\n",
    "        return self.__cohens_d\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def cohens_h(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Cohen's `h`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `directional` argument in `dabest.load()`.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import randint\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = randint.rvs(0, 2, size=30, random_state=12345)\n",
    "        >>> test    = randint.rvs(0, 2, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\")\n",
    "        >>> my_dabest_object.cohens_h\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Cohen's *h* uses the information of proportion in the control and test groups to calculate the distance between two proportions.\n",
    "        It can be used to describe the difference between two proportions as \"small\", \"medium\", or \"large\".\n",
    "        It can be used to determine if the difference between two proportions is \"meaningful\".\n",
    "\n",
    "        A directional Cohen's *h* is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            h = 2 * \\\\arcsin{\\\\sqrt{proportion_{Test}}} - 2 * \\\\arcsin{\\\\sqrt{proportion_{Control}}}\n",
    "\n",
    "        For a non-directional Cohen's *h*, the equation is:\n",
    "\n",
    "        .. math::\n",
    "            h = |2 * \\\\arcsin{\\\\sqrt{proportion_{Test}}} - 2 * \\\\arcsin{\\\\sqrt{proportion_{Control}}}|\n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Cohen%27s_h\n",
    "        \"\"\"\n",
    "        return self.__cohens_h\n",
    "\n",
    "\n",
    "    @property  \n",
    "    def hedges_g(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Hedges' `g`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.hedges_g\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        \n",
    "        Hedges' `g` is :py:attr:`cohens_d` corrected for bias via multiplication with the following correction factor:\n",
    "        \n",
    "        .. math::\n",
    "            \\\\frac{ \\\\Gamma( \\\\frac{a} {2} )} {\\\\sqrt{ \\\\frac{a} {2} } \\\\times \\\\Gamma( \\\\frac{a - 1} {2} )}\n",
    "            \n",
    "        where\n",
    "        \n",
    "        .. math::\n",
    "            a = {n}_{control} + {n}_{test} - 2\n",
    "            \n",
    "        and :math:`\\\\Gamma(x)` is the `Gamma function <https://en.wikipedia.org/wiki/Gamma_function>`_.\n",
    "            \n",
    "        \n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Hedges'_g\n",
    "            https://journals.sagepub.com/doi/10.3102/10769986006002107\n",
    "        \"\"\"\n",
    "        return self.__hedges_g\n",
    "        \n",
    "        \n",
    "    @property    \n",
    "    def cliffs_delta(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for Cliff's delta, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.cliffs_delta\n",
    "        \n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        \n",
    "        Cliff's delta is a measure of ordinal dominance, ie. how often the values from the test sample are larger than values from the control sample.\n",
    "        \n",
    "        .. math::\n",
    "            \\\\text{Cliff's delta} = \\\\frac{\\\\#({x}_{test} > {x}_{control}) - \\\\#({x}_{test} < {x}_{control})} {{n}_{Test} \\\\times {n}_{Control}}\n",
    "            \n",
    "            \n",
    "        where :math:`\\\\#` denotes the number of times a value from the test sample exceeds (or is lesser than) values in the control sample. \n",
    "         \n",
    "        Cliff's delta ranges from -1 to 1; it can also be thought of as a measure of the degree of overlap between the two samples. An attractive aspect of this effect size is that it does not make an assumptions about the underlying distributions that the samples were drawn from. \n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data\n",
    "            https://psycnet.apa.org/record/1994-08169-001\n",
    "        \"\"\"\n",
    "        return self.__cliffs_delta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"\n",
    "        Returns the pandas DataFrame that was passed to `dabest.load()`.\n",
    "        When `delta2` is True, a new column is added to support the \n",
    "        function. The name of this new column is indicated by `x`.\n",
    "        \"\"\"\n",
    "        return self.__data\n",
    "\n",
    "\n",
    "    @property\n",
    "    def idx(self):\n",
    "        \"\"\"\n",
    "        Returns the order of categories that was passed to `dabest.load()`.\n",
    "        \"\"\"\n",
    "        return self.__idx\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def x1(self):\n",
    "        \"\"\"\n",
    "        Returns the first variable declared in x when it is a delta-delta\n",
    "        case; returns None otherwise.\n",
    "        \"\"\"\n",
    "        return self.__x1\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x1_level(self):\n",
    "        \"\"\"\n",
    "        Returns the levels of first variable declared in x when it is a \n",
    "        delta-delta case; returns None otherwise.\n",
    "        \"\"\"\n",
    "        return self.__x1_level\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x2(self):\n",
    "        \"\"\"\n",
    "        Returns the second variable declared in x when it is a delta-delta\n",
    "        case; returns None otherwise.\n",
    "        \"\"\"\n",
    "        return self.__x2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def experiment(self):\n",
    "        \"\"\"\n",
    "        Returns the column name of experiment labels that was passed to \n",
    "        `dabest.load()` when it is a delta-delta case; returns None otherwise.\n",
    "        \"\"\"\n",
    "        return self.__experiment\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def experiment_label(self):\n",
    "        \"\"\"\n",
    "        Returns the experiment labels in order that was passed to `dabest.load()`\n",
    "        when it is a delta-delta case; returns None otherwise.\n",
    "        \"\"\"\n",
    "        return self.__experiment_label\n",
    "\n",
    "\n",
    "    @property\n",
    "    def delta2(self):\n",
    "        \"\"\"\n",
    "        Returns the boolean parameter indicating if this is a delta-delta \n",
    "        situation.\n",
    "        \"\"\"\n",
    "        return self.__delta2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        \"\"\"\n",
    "        Returns the type of repeated-measures experiment.\n",
    "        \"\"\"\n",
    "        return self.__is_paired\n",
    "\n",
    "\n",
    "    @property\n",
    "    def id_col(self):\n",
    "        \"\"\"\n",
    "        Returns the id column declared to `dabest.load()`.\n",
    "        \"\"\"\n",
    "        return self.__id_col\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        The width of the desired confidence interval.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples used to generate the bootstrap.\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The number used to initialise the numpy random seed generator, ie.\n",
    "        `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"\n",
    "        Returns the x column that was passed to `dabest.load()`, if any.\n",
    "        When `delta2` is True, `x` returns the name of the new column created \n",
    "        for the delta-delta situation. To retrieve the 2 variables passed into \n",
    "        `x` when `delta2` is True, please call `x1` and `x2` instead.\n",
    "        \"\"\"\n",
    "        return self.__x\n",
    "\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\"\n",
    "        Returns the y column that was passed to `dabest.load()`, if any.\n",
    "        \"\"\"\n",
    "        return self.__y\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _xvar(self):\n",
    "        \"\"\"\n",
    "        Returns the xvar in dabest.plot_data.\n",
    "        \"\"\"\n",
    "        return self.__xvar\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _yvar(self):\n",
    "        \"\"\"\n",
    "        Returns the yvar in dabest.plot_data.\n",
    "        \"\"\"\n",
    "        return self.__yvar\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _plot_data(self):\n",
    "        \"\"\"\n",
    "        Returns the pandas DataFrame used to produce the estimation stats/plots.\n",
    "        \"\"\"\n",
    "        return self.__plot_data\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def mini_meta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta boolean parameter.\n",
    "        \"\"\"\n",
    "        return self.__mini_meta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _all_plot_groups(self):\n",
    "        \"\"\"\n",
    "        Returns the all plot groups, as indicated via the `idx` keyword.\n",
    "        \"\"\"\n",
    "        return self.__all_plot_groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeltaDelta(object):\n",
    "    \"\"\"\n",
    "    A class to compute and store the delta-delta statistics. In a 2-by-2 arrangement where two independent variables, A and B, each have two categorical values, two primary deltas are first calculated with one independent variable and a delta-delta effect size is calculated as a difference between the two primary deltas.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\hat{\\\\theta}_{B1} = \\\\overline{X}_{A2, B1} - \\\\overline{X}_{A1, B1}\n",
    "\n",
    "        \\\\hat{\\\\theta}_{B2} = \\\\overline{X}_{A2, B2} - \\\\overline{X}_{A1, B2}\n",
    "    \n",
    "    .. math::\n",
    "\n",
    "        \\\\hat{\\\\theta}_{\\\\theta} = \\\\hat{\\\\theta}_{B2} - \\\\hat{\\\\theta}_{B1}\n",
    "    \n",
    "    and:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        s_{\\\\theta} = \\\\frac{(n_{A2, B1}-1)s_{A2, B1}^2+(n_{A1, B1}-1)s_{A1, B1}^2+(n_{A2, B2}-1)s_{A2, B2}^2+(n_{A1, B2}-1)s_{A1, B2}^2}{(n_{A2, B1} - 1) + (n_{A1, B1} - 1) + (n_{A2, B2} - 1) + (n_{A1, B2} - 1)}\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> import pandas as pd\n",
    "    >>> from scipy.stats import norm # Used in generation of populations.\n",
    "    >>> np.random.seed(9999) # Fix the seed so the results are replicable.\n",
    "    >>> from scipy.stats import norm # Used in generation of populations.\n",
    "    >>> N = 20\n",
    "    >>> # Create samples\n",
    "    >>> y = norm.rvs(loc=3, scale=0.4, size=N*4)\n",
    "    >>> y[N:2*N] = y[N:2*N]+1\n",
    "    >>> y[2*N:3*N] = y[2*N:3*N]-0.5\n",
    "    >>> # Add drug column\n",
    "    >>> t1 = np.repeat('Placebo', N*2).tolist()\n",
    "    >>> t2 = np.repeat('Drug', N*2).tolist()\n",
    "    >>> treatment = t1 + t2 \n",
    "    >>> # Add a `rep` column as the first variable for the 2 replicates of experiments done\n",
    "    >>> rep = []\n",
    "    >>> for i in range(N*2):\n",
    "    >>>     rep.append('Rep1')\n",
    "    >>>     rep.append('Rep2')\n",
    "    >>> # Add a `genotype` column as the second variable\n",
    "    >>> wt = np.repeat('W', N).tolist()\n",
    "    >>> mt = np.repeat('M', N).tolist()\n",
    "    >>> wt2 = np.repeat('W', N).tolist()\n",
    "    >>> mt2 = np.repeat('M', N).tolist()\n",
    "    >>> genotype = wt + mt + wt2 + mt2\n",
    "    >>> # Add an `id` column for paired data plotting.\n",
    "    >>> id = list(range(0, N*2))\n",
    "    >>> id_col = id + id \n",
    "    >>> # Combine all columns into a DataFrame.\n",
    "    >>> df_delta2 = pd.DataFrame({'ID'        : id_col,\n",
    "    >>>                   'Rep'      : rep,\n",
    "    >>>                    'Genotype'  : genotype, \n",
    "    >>>                    'Drug': treatment,\n",
    "    >>>                    'Y'         : y\n",
    "    >>>                 })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, effectsizedataframe, permutation_count,\n",
    "                ci=95):\n",
    "\n",
    "        import numpy as np\n",
    "        from numpy import sort as npsort\n",
    "        from numpy import sqrt, isinf, isnan\n",
    "        from . import effsize as es\n",
    "        from . import confint_1group as ci1g\n",
    "        from . import confint_2group_diff as ci2g\n",
    "\n",
    "        from string import Template\n",
    "        import warnings\n",
    "        \n",
    "        self.__effsizedf         = effectsizedataframe.results\n",
    "        self.__dabest_obj        = effectsizedataframe.dabest_obj\n",
    "        self.__ci                = ci\n",
    "        self.__resamples         = effectsizedataframe.resamples\n",
    "        self.__alpha             = ci2g._compute_alpha_from_ci(ci)\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__bootstraps        = np.array(self.__effsizedf[\"bootstraps\"])\n",
    "        self.__control           = self.__dabest_obj.experiment_label[0]\n",
    "        self.__test              = self.__dabest_obj.experiment_label[1]\n",
    "\n",
    "\n",
    "        # Compute the bootstrap delta-delta and the true dela-delta based on \n",
    "        # the raw data \n",
    "        self.__bootstraps_delta_delta = self.__bootstraps[1] - self.__bootstraps[0]\n",
    "\n",
    "        self.__difference = self.__effsizedf[\"difference\"][1] - self.__effsizedf[\"difference\"][0]\n",
    "\n",
    "\n",
    "\n",
    "        sorted_delta_delta = npsort(self.__bootstraps_delta_delta)\n",
    "\n",
    "        self.__bias_correction = ci2g.compute_meandiff_bias_correction(\n",
    "                                    self.__bootstraps_delta_delta, self.__difference)\n",
    "        \n",
    "        self.__jackknives = np.array(ci1g.compute_1group_jackknife(\n",
    "                                                self.__bootstraps_delta_delta, \n",
    "                                                np.mean))\n",
    "\n",
    "        self.__acceleration_value = ci2g._calc_accel(self.__jackknives)\n",
    "\n",
    "        # Compute BCa intervals.\n",
    "        bca_idx_low, bca_idx_high = ci2g.compute_interval_limits(\n",
    "            self.__bias_correction, self.__acceleration_value,\n",
    "            self.__resamples, ci)\n",
    "        \n",
    "        self.__bca_interval_idx = (bca_idx_low, bca_idx_high)\n",
    "\n",
    "        if ~isnan(bca_idx_low) and ~isnan(bca_idx_high):\n",
    "            self.__bca_low  = sorted_delta_delta[bca_idx_low]\n",
    "            self.__bca_high = sorted_delta_delta[bca_idx_high]\n",
    "\n",
    "            err1 = \"The $lim_type limit of the interval\"\n",
    "            err2 = \"was in the $loc 10 values.\"\n",
    "            err3 = \"The result should be considered unstable.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if bca_idx_low <= 10:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\",\n",
    "                                                  loc=\"bottom\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "            if bca_idx_high >= self.__resamples-9:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\",\n",
    "                                                  loc=\"top\"),\n",
    "                                                  stacklevel=1)\n",
    "\n",
    "        else:\n",
    "            err1 = \"The $lim_type limit of the BCa interval cannot be computed.\"\n",
    "            err2 = \"It is set to the effect size itself.\"\n",
    "            err3 = \"All bootstrap values were likely all the same.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if isnan(bca_idx_low):\n",
    "                self.__bca_low  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "            if isnan(bca_idx_high):\n",
    "                self.__bca_high  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "        # Compute percentile intervals.\n",
    "        pct_idx_low  = int((self.__alpha/2)     * self.__resamples)\n",
    "        pct_idx_high = int((1-(self.__alpha/2)) * self.__resamples)\n",
    "\n",
    "        self.__pct_interval_idx = (pct_idx_low, pct_idx_high)\n",
    "        self.__pct_low          = sorted_delta_delta[pct_idx_low]\n",
    "        self.__pct_high         = sorted_delta_delta[pct_idx_high]\n",
    "        \n",
    "    \n",
    "\n",
    "    def __permutation_test(self):\n",
    "        \"\"\"\n",
    "        Perform a permutation test and obtain the permutation p-value\n",
    "        based on the permutation data.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        self.__permutations     = np.array(self.__effsizedf[\"permutations\"])\n",
    "\n",
    "        THRESHOLD = np.abs(self.__difference)\n",
    "\n",
    "        self.__permutations_delta_delta = np.array(self.__permutations[1]-self.__permutations[0])\n",
    "\n",
    "        count = sum(np.abs(self.__permutations_delta_delta)>THRESHOLD)\n",
    "        self.__pvalue_permutation = count/self.__permutation_count\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self, header=True, sigfig=3):\n",
    "        from .__init__ import __version__\n",
    "        import datetime as dt\n",
    "        import numpy as np\n",
    "\n",
    "        from .misc_tools import print_greeting\n",
    "\n",
    "        first_line = {\"control\"      : self.__control,\n",
    "                      \"test\"         : self.__test}\n",
    "        \n",
    "        out1 = \"The delta-delta between {control} and {test} \".format(**first_line)\n",
    "        \n",
    "        base_string_fmt = \"{:.\" + str(sigfig) + \"}\"\n",
    "        if \".\" in str(self.__ci):\n",
    "            ci_width = base_string_fmt.format(self.__ci)\n",
    "        else:\n",
    "            ci_width = str(self.__ci)\n",
    "        \n",
    "        ci_out = {\"es\"       : base_string_fmt.format(self.__difference),\n",
    "                  \"ci\"       : ci_width,\n",
    "                  \"bca_low\"  : base_string_fmt.format(self.__bca_low),\n",
    "                  \"bca_high\" : base_string_fmt.format(self.__bca_high)}\n",
    "        \n",
    "        out2 = \"is {es} [{ci}%CI {bca_low}, {bca_high}].\".format(**ci_out)\n",
    "        out = out1 + out2\n",
    "\n",
    "        if header is True:\n",
    "            out = print_greeting() + \"\\n\" + \"\\n\" + out\n",
    "\n",
    "\n",
    "        pval_rounded = base_string_fmt.format(self.pvalue_permutation)\n",
    "\n",
    "        \n",
    "        p1 = \"The p-value of the two-sided permutation t-test is {}, \".format(pval_rounded)\n",
    "        p2 = \"calculated for legacy purposes only. \"\n",
    "        pvalue = p1 + p2\n",
    "\n",
    "\n",
    "        bs1 = \"{} bootstrap samples were taken; \".format(self.__resamples)\n",
    "        bs2 = \"the confidence interval is bias-corrected and accelerated.\"\n",
    "        bs = bs1 + bs2\n",
    "\n",
    "        pval_def1 = \"Any p-value reported is the probability of observing the \" + \\\n",
    "                    \"effect size (or greater),\\nassuming the null hypothesis of \" + \\\n",
    "                    \"zero difference is true.\"\n",
    "        pval_def2 = \"\\nFor each p-value, 5000 reshuffles of the \" + \\\n",
    "                    \"control and test labels were performed.\"\n",
    "        pval_def = pval_def1 + pval_def2\n",
    "\n",
    "\n",
    "        return \"{}\\n{}\\n\\n{}\\n{}\".format(out, pvalue, bs, pval_def)\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Returns the attributes of the `DeltaDelta` object as a\n",
    "        dictionary.\n",
    "        \"\"\"\n",
    "        # Only get public (user-facing) attributes.\n",
    "        attrs = [a for a in dir(self)\n",
    "                 if not a.startswith((\"_\", \"to_dict\"))]\n",
    "        out = {}\n",
    "        for a in attrs:\n",
    "            out[a] = getattr(self, a)\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        Returns the width of the confidence interval, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"\n",
    "        Returns the significance level of the statistical test as a float\n",
    "        between 0 and 1.\n",
    "        \"\"\"\n",
    "        return self.__alpha\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bias_correction(self):\n",
    "        return self.__bias_correction\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps(self):\n",
    "        '''\n",
    "        Return the bootstrapped deltas from all the experiment groups.\n",
    "        '''\n",
    "        return self.__bootstraps\n",
    "\n",
    "\n",
    "    @property\n",
    "    def jackknives(self):\n",
    "        return self.__jackknives\n",
    "\n",
    "\n",
    "    @property\n",
    "    def acceleration_value(self):\n",
    "        return self.__acceleration_value\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_low(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_high(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval upper limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_interval_idx(self):\n",
    "        return self.__bca_interval_idx\n",
    "\n",
    "\n",
    "    @property\n",
    "    def control(self):\n",
    "        '''\n",
    "        Return the name of the control experiment group.\n",
    "        '''\n",
    "        return self.__control\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        '''\n",
    "        Return the name of the test experiment group.\n",
    "        '''\n",
    "        return self.__test\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps_delta_delta(self):\n",
    "        '''\n",
    "        Return the delta-delta values calculated from the bootstrapped \n",
    "        deltas.\n",
    "        '''\n",
    "        return self.__bootstraps_delta_delta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def difference(self):\n",
    "        '''\n",
    "        Return the delta-delta value calculated based on the raw data.\n",
    "        '''\n",
    "        return self.__difference\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_interval_idx (self):\n",
    "        return self.__pct_interval_idx \n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_low(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_high(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_permutation(self):\n",
    "        try:\n",
    "            return self.__pvalue_permutation\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__pvalue_permutation\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        \"\"\"\n",
    "        The number of permuations taken.\n",
    "        \"\"\"\n",
    "        return self.__permutation_count\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations(self):\n",
    "        '''\n",
    "        Return the mean differences of permutations obtained during\n",
    "        the permutation test for each experiment group.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_delta_delta(self):\n",
    "        '''\n",
    "        Return the delta-delta values of permutations obtained \n",
    "        during the permutation test.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations_delta_delta\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations_delta_delta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MiniMetaDelta(object):\n",
    "    \"\"\"\n",
    "    A class to compute and store the weighted delta.\n",
    "    A weighted delta is calculated if the argument ``mini_meta=True`` is passed during ``dabest.load()``.\n",
    "\n",
    "    The weighted delta is calcuated as follows:\n",
    "\n",
    "    .. math::\n",
    "\t\\\\theta_{\\\\text{weighted}} = \\\\frac{\\\\Sigma\\\\hat{\\\\theta_{i}}w_{i}}{{\\\\Sigma}w_{i}}\n",
    "    \n",
    "    where:\n",
    "\n",
    "    .. math::\n",
    "\t\\\\hat{\\\\theta_{i}} = \\\\text{Mean difference for replicate }i\n",
    "\n",
    "    .. math::\n",
    "\tw_{i} = \\\\text{Weight for replicate }i = \\\\frac{1}{s_{i}^2} \n",
    "\n",
    "    .. math::\n",
    "\ts_{i}^2 = \\\\text{Pooled variance for replicate }i = \\\\frac{(n_{test}-1)s_{test}^2+(n_{control}-1)s_{control}^2}{n_{test}+n_{control}-2}\n",
    "\n",
    "    .. math::\n",
    "\tn = \\\\text{sample size and }s^2 = \\\\text{variance for control/test.}\n",
    "\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> from scipy.stats import norm\n",
    "    >>> import pandas as pd\n",
    "    >>> import dabest\n",
    "    >>> c1 = norm.rvs(loc=3, scale=0.4, size=Ns)\n",
    "    >>> c2 = norm.rvs(loc=3.5, scale=0.75, size=Ns)\n",
    "    >>> c3 = norm.rvs(loc=3.25, scale=0.4, size=Ns)\n",
    "\n",
    "    >>> t1 = norm.rvs(loc=3.5, scale=0.5, size=Ns)\n",
    "    >>> t2 = norm.rvs(loc=2.5, scale=0.6, size=Ns)\n",
    "    >>> t3 = norm.rvs(loc=3, scale=0.75, size=Ns)\n",
    "    >>> my_df   = pd.DataFrame({'Control 1' : c1,     'Test 1' : t1,\n",
    "                       'Control 2' : c2,     'Test 2' : t2,\n",
    "                       'Control 3' : c3,     'Test 3' : t3})\n",
    "    >>> my_dabest_object = dabest.load(df, idx=((\"Control 1\", \"Test 1\"), (\"Control 2\", \"Test 2\"), (\"Control 3\", \"Test 3\")), mini_meta=True)\n",
    "    >>> my_dabest_object.mean_diff.mini_meta_delta\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    As of version 2023.02.14, weighted delta can only be calculated for mean difference, and not for standardized measures such as Cohen's *d*.\n",
    "\n",
    "    Details about the calculated weighted delta are accessed as attributes of the ``mini_meta_delta`` class. See the :doc:`minimetadelta` for details on usage.\n",
    "\n",
    "    Refer to Chapter 10 of the Cochrane handbook for further information on meta-analysis: https://training.cochrane.org/handbook/current/chapter-10\n",
    "\t\t\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, effectsizedataframe, permutation_count,\n",
    "                ci=95):\n",
    "\n",
    "        import numpy as np\n",
    "        from numpy import sort as npsort\n",
    "        from numpy import sqrt, isinf, isnan\n",
    "        from . import effsize as es\n",
    "        from . import confint_1group as ci1g\n",
    "        from . import confint_2group_diff as ci2g\n",
    "\n",
    "        from string import Template\n",
    "        import warnings\n",
    "        \n",
    "        self.__effsizedf         = effectsizedataframe.results\n",
    "        self.__dabest_obj        = effectsizedataframe.dabest_obj\n",
    "        self.__ci                = ci\n",
    "        self.__resamples         = effectsizedataframe.resamples\n",
    "        self.__alpha             = ci2g._compute_alpha_from_ci(ci)\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__bootstraps        = np.array(self.__effsizedf[\"bootstraps\"])\n",
    "        self.__control           = np.array(self.__effsizedf[\"control\"])\n",
    "        self.__test              = np.array(self.__effsizedf[\"test\"])\n",
    "        self.__control_N         = np.array(self.__effsizedf[\"control_N\"])\n",
    "        self.__test_N            = np.array(self.__effsizedf[\"test_N\"])\n",
    "\n",
    "\n",
    "        idx  = self.__dabest_obj.idx\n",
    "        dat  = self.__dabest_obj._plot_data\n",
    "        xvar = self.__dabest_obj._xvar\n",
    "        yvar = self.__dabest_obj._yvar\n",
    "\n",
    "        # compute the variances of each control group and each test group\n",
    "        control_var=[]\n",
    "        test_var=[]\n",
    "        for j, current_tuple in enumerate(idx):\n",
    "            cname = current_tuple[0]\n",
    "            control = dat[dat[xvar] == cname][yvar].copy()\n",
    "            control_var.append(np.var(control, ddof=1))\n",
    "\n",
    "            tname = current_tuple[1]\n",
    "            test = dat[dat[xvar] == tname][yvar].copy()\n",
    "            test_var.append(np.var(test, ddof=1))\n",
    "        self.__control_var = np.array(control_var)\n",
    "        self.__test_var    = np.array(test_var)\n",
    "\n",
    "        # Compute pooled group variances for each pair of experiment groups\n",
    "        # based on the raw data\n",
    "        self.__group_var   = ci2g.calculate_group_var(self.__control_var, \n",
    "                                                 self.__control_N,\n",
    "                                                 self.__test_var, \n",
    "                                                 self.__test_N)\n",
    "\n",
    "        # Compute the weighted average mean differences of the bootstrap data\n",
    "        # using the pooled group variances of the raw data as the inverse of \n",
    "        # weights\n",
    "        self.__bootstraps_weighted_delta = ci2g.calculate_weighted_delta(\n",
    "                                                          self.__group_var, \n",
    "                                                          self.__bootstraps, \n",
    "                                                          self.__resamples)\n",
    "\n",
    "        # Compute the weighted average mean difference based on the raw data\n",
    "        self.__difference = es.weighted_delta(self.__effsizedf[\"difference\"],\n",
    "                                                   self.__group_var)\n",
    "\n",
    "        sorted_weighted_deltas = npsort(self.__bootstraps_weighted_delta)\n",
    "\n",
    "\n",
    "        self.__bias_correction = ci2g.compute_meandiff_bias_correction(\n",
    "                                    self.__bootstraps_weighted_delta, self.__difference)\n",
    "        \n",
    "        self.__jackknives = np.array(ci1g.compute_1group_jackknife(\n",
    "                                                self.__bootstraps_weighted_delta, \n",
    "                                                np.mean))\n",
    "\n",
    "        self.__acceleration_value = ci2g._calc_accel(self.__jackknives)\n",
    "\n",
    "        # Compute BCa intervals.\n",
    "        bca_idx_low, bca_idx_high = ci2g.compute_interval_limits(\n",
    "            self.__bias_correction, self.__acceleration_value,\n",
    "            self.__resamples, ci)\n",
    "        \n",
    "        self.__bca_interval_idx = (bca_idx_low, bca_idx_high)\n",
    "\n",
    "        if ~isnan(bca_idx_low) and ~isnan(bca_idx_high):\n",
    "            self.__bca_low  = sorted_weighted_deltas[bca_idx_low]\n",
    "            self.__bca_high = sorted_weighted_deltas[bca_idx_high]\n",
    "\n",
    "            err1 = \"The $lim_type limit of the interval\"\n",
    "            err2 = \"was in the $loc 10 values.\"\n",
    "            err3 = \"The result should be considered unstable.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if bca_idx_low <= 10:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\",\n",
    "                                                  loc=\"bottom\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "            if bca_idx_high >= self.__resamples-9:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\",\n",
    "                                                  loc=\"top\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "        else:\n",
    "            err1 = \"The $lim_type limit of the BCa interval cannot be computed.\"\n",
    "            err2 = \"It is set to the effect size itself.\"\n",
    "            err3 = \"All bootstrap values were likely all the same.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if isnan(bca_idx_low):\n",
    "                self.__bca_low  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "            if isnan(bca_idx_high):\n",
    "                self.__bca_high  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "        # Compute percentile intervals.\n",
    "        pct_idx_low  = int((self.__alpha/2)     * self.__resamples)\n",
    "        pct_idx_high = int((1-(self.__alpha/2)) * self.__resamples)\n",
    "\n",
    "        self.__pct_interval_idx = (pct_idx_low, pct_idx_high)\n",
    "        self.__pct_low          = sorted_weighted_deltas[pct_idx_low]\n",
    "        self.__pct_high         = sorted_weighted_deltas[pct_idx_high]\n",
    "        \n",
    "    \n",
    "\n",
    "    def __permutation_test(self):\n",
    "        \"\"\"\n",
    "        Perform a permutation test and obtain the permutation p-value\n",
    "        based on the permutation data.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        self.__permutations     = np.array(self.__effsizedf[\"permutations\"])\n",
    "        self.__permutations_var = np.array(self.__effsizedf[\"permutations_var\"])\n",
    "\n",
    "        THRESHOLD = np.abs(self.__difference)\n",
    "\n",
    "        all_num = []\n",
    "        all_denom = []\n",
    "\n",
    "        groups = len(self.__permutations)\n",
    "        for i in range(0, len(self.__permutations[0])):\n",
    "            weight = [1/self.__permutations_var[j][i] for j in range(0, groups)]\n",
    "            all_num.append(np.sum([weight[j]*self.__permutations[j][i] for j in range(0, groups)]))\n",
    "            all_denom.append(np.sum(weight))\n",
    "        \n",
    "        output=[]\n",
    "        for i in range(0, len(all_num)):\n",
    "            output.append(all_num[i]/all_denom[i])\n",
    "        \n",
    "        self.__permutations_weighted_delta = np.array(output)\n",
    "\n",
    "        count = sum(np.abs(self.__permutations_weighted_delta)>THRESHOLD)\n",
    "        self.__pvalue_permutation = count/self.__permutation_count\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self, header=True, sigfig=3):\n",
    "        from .__init__ import __version__\n",
    "        import datetime as dt\n",
    "        import numpy as np\n",
    "\n",
    "        from .misc_tools import print_greeting\n",
    "        \n",
    "        is_paired = self.__dabest_obj.is_paired\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'paired', \n",
    "                         'sequential' : 'paired',\n",
    "                         'None'       : 'unpaired'\n",
    "        }\n",
    "\n",
    "        first_line = {\"paired_status\": PAIRED_STATUS[str(is_paired)]}\n",
    "        \n",
    "\n",
    "        out1 = \"The weighted-average {paired_status} mean differences \".format(**first_line)\n",
    "        \n",
    "        base_string_fmt = \"{:.\" + str(sigfig) + \"}\"\n",
    "        if \".\" in str(self.__ci):\n",
    "            ci_width = base_string_fmt.format(self.__ci)\n",
    "        else:\n",
    "            ci_width = str(self.__ci)\n",
    "        \n",
    "        ci_out = {\"es\"       : base_string_fmt.format(self.__difference),\n",
    "                  \"ci\"       : ci_width,\n",
    "                  \"bca_low\"  : base_string_fmt.format(self.__bca_low),\n",
    "                  \"bca_high\" : base_string_fmt.format(self.__bca_high)}\n",
    "        \n",
    "        out2 = \"is {es} [{ci}%CI {bca_low}, {bca_high}].\".format(**ci_out)\n",
    "        out = out1 + out2\n",
    "\n",
    "        if header is True:\n",
    "            out = print_greeting() + \"\\n\" + \"\\n\" + out\n",
    "\n",
    "\n",
    "        pval_rounded = base_string_fmt.format(self.pvalue_permutation)\n",
    "\n",
    "        \n",
    "        p1 = \"The p-value of the two-sided permutation t-test is {}, \".format(pval_rounded)\n",
    "        p2 = \"calculated for legacy purposes only. \"\n",
    "        pvalue = p1 + p2\n",
    "\n",
    "\n",
    "        bs1 = \"{} bootstrap samples were taken; \".format(self.__resamples)\n",
    "        bs2 = \"the confidence interval is bias-corrected and accelerated.\"\n",
    "        bs = bs1 + bs2\n",
    "\n",
    "        pval_def1 = \"Any p-value reported is the probability of observing the\" + \\\n",
    "                    \"effect size (or greater),\\nassuming the null hypothesis of\" + \\\n",
    "                    \"zero difference is true.\"\n",
    "        pval_def2 = \"\\nFor each p-value, 5000 reshuffles of the \" + \\\n",
    "                    \"control and test labels were performed.\"\n",
    "        pval_def = pval_def1 + pval_def2\n",
    "\n",
    "\n",
    "        return \"{}\\n{}\\n\\n{}\\n{}\".format(out, pvalue, bs, pval_def)\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Returns all attributes of the `dabest.MiniMetaDelta` object as a\n",
    "        dictionary.\n",
    "        \"\"\"\n",
    "        # Only get public (user-facing) attributes.\n",
    "        attrs = [a for a in dir(self)\n",
    "                 if not a.startswith((\"_\", \"to_dict\"))]\n",
    "        out = {}\n",
    "        for a in attrs:\n",
    "            out[a] = getattr(self, a)\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        Returns the width of the confidence interval, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"\n",
    "        Returns the significance level of the statistical test as a float\n",
    "        between 0 and 1.\n",
    "        \"\"\"\n",
    "        return self.__alpha\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bias_correction(self):\n",
    "        return self.__bias_correction\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps(self):\n",
    "        '''\n",
    "        Return the bootstrapped differences from all the experiment groups.\n",
    "        '''\n",
    "        return self.__bootstraps\n",
    "\n",
    "\n",
    "    @property\n",
    "    def jackknives(self):\n",
    "        return self.__jackknives\n",
    "\n",
    "\n",
    "    @property\n",
    "    def acceleration_value(self):\n",
    "        return self.__acceleration_value\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_low(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_high(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval upper limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_interval_idx(self):\n",
    "        return self.__bca_interval_idx\n",
    "\n",
    "\n",
    "    @property\n",
    "    def control(self):\n",
    "        '''\n",
    "        Return the names of the control groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__control\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        '''\n",
    "        Return the names of the test groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__test\n",
    "    \n",
    "    @property\n",
    "    def control_N(self):\n",
    "        '''\n",
    "        Return the sizes of the control groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__control_N\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test_N(self):\n",
    "        '''\n",
    "        Return the sizes of the test groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__test_N\n",
    "\n",
    "\n",
    "    @property\n",
    "    def control_var(self):\n",
    "        '''\n",
    "        Return the estimated population variances of the control groups \n",
    "        from all the experiment groups in order. Here the population \n",
    "        variance is estimated from the sample variance. \n",
    "        '''\n",
    "        return self.__control_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test_var(self):\n",
    "        '''\n",
    "        Return the estimated population variances of the control groups \n",
    "        from all the experiment groups in order. Here the population \n",
    "        variance is estimated from the sample variance. \n",
    "        '''\n",
    "        return self.__test_var\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def group_var(self):\n",
    "        '''\n",
    "        Return the pooled group variances of all the experiment groups \n",
    "        in order. \n",
    "        '''\n",
    "        return self.__group_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps_weighted_delta(self):\n",
    "        '''\n",
    "        Return the weighted-average mean differences calculated from the bootstrapped \n",
    "        deltas and weights across the experiment groups, where the weights are \n",
    "        the inverse of the pooled group variances.\n",
    "        '''\n",
    "        return self.__bootstraps_weighted_delta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def difference(self):\n",
    "        '''\n",
    "        Return the weighted-average delta calculated from the raw data.\n",
    "        '''\n",
    "        return self.__difference\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_interval_idx (self):\n",
    "        return self.__pct_interval_idx \n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_low(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_high(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_permutation(self):\n",
    "        try:\n",
    "            return self.__pvalue_permutation\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__pvalue_permutation\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        \"\"\"\n",
    "        The number of permuations taken.\n",
    "        \"\"\"\n",
    "        return self.__permutation_count\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations(self):\n",
    "        '''\n",
    "        Return the mean differences of permutations obtained during\n",
    "        the permutation test for each experiment group.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        '''\n",
    "        Return the pooled group variances of permutations obtained during\n",
    "        the permutation test for each experiment group.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations_var\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations_var\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_weighted_delta(self):\n",
    "        '''\n",
    "        Return the weighted-average deltas of permutations obtained \n",
    "        during the permutation test.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations_weighted_delta\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations_weighted_delta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TwoGroupsEffectSize(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A class to compute and store the results of bootstrapped\n",
    "    mean differences between two groups.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, control, test, effect_size,\n",
    "                 proportional=False,\n",
    "                 is_paired=None, ci=95,\n",
    "                 resamples=5000, \n",
    "                 permutation_count=5000, \n",
    "                 random_seed=12345):\n",
    "\n",
    "        \"\"\"\n",
    "        Compute the effect size between two groups.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        control : array-like\n",
    "        test : array-like\n",
    "            These should be numerical iterables.\n",
    "        effect_size : string.\n",
    "            Any one of the following are accepted inputs:\n",
    "            'mean_diff', 'median_diff', 'cohens_d', 'hedges_g', or 'cliffs_delta'\n",
    "        is_paired : string, default None\n",
    "        resamples : int, default 5000\n",
    "            The number of bootstrap resamples to be taken for the calculation\n",
    "            of the confidence interval limits.\n",
    "        permutation_count : int, default 5000\n",
    "            The number of permutations (reshuffles) to perform for the \n",
    "            computation of the permutation p-value\n",
    "        ci : float, default 95\n",
    "            The confidence interval width. The default of 95 produces 95%\n",
    "            confidence intervals.\n",
    "        random_seed : int, default 12345\n",
    "            `random_seed` is used to seed the random number generator during\n",
    "            bootstrap resampling. This ensures that the confidence intervals\n",
    "            reported are replicable.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A :py:class:`TwoGroupEffectSize` object.\n",
    "        \n",
    "        difference : float\n",
    "            The effect size of the difference between the control and the test.\n",
    "        \n",
    "        effect_size : string\n",
    "            The type of effect size reported.\n",
    "        \n",
    "        is_paired : string\n",
    "            The type of repeated-measures experiment.\n",
    "            \n",
    "        ci : float\n",
    "            Returns the width of the confidence interval, in percent.\n",
    "            \n",
    "        alpha : float\n",
    "            Returns the significance level of the statistical test as a float\n",
    "            between 0 and 1.\n",
    "            \n",
    "        resamples : int\n",
    "            The number of resamples performed during the bootstrap procedure.\n",
    "\n",
    "        bootstraps : numpy ndarray\n",
    "            The generated bootstraps of the effect size.\n",
    "            \n",
    "        random_seed : int\n",
    "            The number used to initialise the numpy random seed generator, ie.\n",
    "            `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "            \n",
    "        bca_low, bca_high : float\n",
    "            The bias-corrected and accelerated confidence interval lower limit\n",
    "            and upper limits, respectively.\n",
    "            \n",
    "        pct_low, pct_high : float\n",
    "            The percentile confidence interval lower limit and upper limits, \n",
    "            respectively.\n",
    "            \n",
    "            \n",
    "        Examples\n",
    "        --------\n",
    "        >>> import numpy as np\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import dabest\n",
    "        >>> np.random.seed(12345)\n",
    "        >>> control = norm.rvs(loc=0, size=30)\n",
    "        >>> test = norm.rvs(loc=0.5, size=30)\n",
    "        >>> effsize = dabest.TwoGroupsEffectSize(control, test, \"mean_diff\")\n",
    "        >>> effsize\n",
    "        The unpaired mean difference is -0.253 [95%CI -0.78, 0.25].\n",
    "        The p-value of the two-sided permutation t-test is 0.348, calculated \n",
    "        for legacy purposes only. \n",
    "\n",
    "        5000 bootstrap samples were taken; the confidence interval is \n",
    "        bias-corrected and accelerated. The p-value(s) reported are the \n",
    "        likelihood(s) of observing the effect size(s), if the null hypothesis \n",
    "        of zero difference is true. For each p-value, 5000 reshuffles of the \n",
    "        control and test labels were performed.\n",
    "        >>> effsize.to_dict() \n",
    "        {'alpha': 0.05,\n",
    "         'bca_high': 0.24951887238295106,\n",
    "         'bca_interval_idx': (125, 4875),\n",
    "         'bca_low': -0.7801782111071534,\n",
    "         'bootstraps': array([-0.3649424 , -0.45018155, -0.56034412, ..., -0.49805581,\n",
    "                              -0.25334475, -0.55206229]),\n",
    "         'ci': 95,\n",
    "         'difference': -0.25315417702752846,\n",
    "         'effect_size': 'mean difference',\n",
    "         'is_paired': None,\n",
    "         'pct_high': 0.24951887238295106,\n",
    "         'pct_interval_idx': (125, 4875),\n",
    "         'pct_low': -0.7801782111071534,\n",
    "         'permutation_count': 5000,\n",
    "         'permutations': array([ 0.17221029,  0.03112419, -0.13911387, ..., -0.38007941,\n",
    "                                 0.30261507, -0.09073054]),\n",
    "         'permutations_var': array([0.07201642, 0.07251104, 0.07219407, ..., 0.07003705, 0.07094885,\n",
    "                                 0.07238581]),\n",
    "         'pvalue_brunner_munzel': nan,\n",
    "         'pvalue_kruskal': nan,\n",
    "         'pvalue_mann_whitney': 0.5201446121616038,\n",
    "         'pvalue_paired_students_t': nan,\n",
    "         'pvalue_permutation': 0.3484,\n",
    "         'pvalue_students_t': 0.34743913903372836,\n",
    "         'pvalue_welch': 0.3474493875548965,\n",
    "         'pvalue_wilcoxon': nan,\n",
    "         'random_seed': 12345,\n",
    "         'resamples': 5000,\n",
    "         'statistic_brunner_munzel': nan,\n",
    "         'statistic_kruskal': nan,\n",
    "         'statistic_mann_whitney': 494.0,\n",
    "         'statistic_paired_students_t': nan,\n",
    "         'statistic_students_t': 0.9472545159069105,\n",
    "         'statistic_welch': 0.9472545159069105,\n",
    "         'statistic_wilcoxon': nan}\n",
    "        \"\"\"\n",
    "        \n",
    "        import numpy as np\n",
    "        from numpy import array, isnan, isinf\n",
    "        from numpy import sort as npsort\n",
    "        from numpy.random import choice, seed\n",
    "\n",
    "        import scipy.stats as spstats\n",
    "\n",
    "        # import statsmodels.stats.power as power\n",
    "        import statsmodels\n",
    "\n",
    "        from string import Template\n",
    "        import warnings\n",
    "\n",
    "        from . import confint_2group_diff as ci2g\n",
    "        from . import effsize as es\n",
    "\n",
    "\n",
    "        self.__EFFECT_SIZE_DICT =  {\"mean_diff\" : \"mean difference\",\n",
    "                                    \"median_diff\" : \"median difference\",\n",
    "                                    \"cohens_d\" : \"Cohen's d\",\n",
    "                                    \"cohens_h\" : \"Cohen's h\",\n",
    "                                    \"hedges_g\" : \"Hedges' g\",\n",
    "                                    \"cliffs_delta\" : \"Cliff's delta\"}\n",
    "\n",
    "\n",
    "        kosher_es = [a for a in self.__EFFECT_SIZE_DICT.keys()]\n",
    "        if effect_size not in kosher_es:\n",
    "            err1 = \"The effect size '{}'\".format(effect_size)\n",
    "            err2 = \"is not one of {}\".format(kosher_es)\n",
    "            raise ValueError(\" \".join([err1, err2]))\n",
    "\n",
    "        if effect_size == \"cliffs_delta\" and is_paired:\n",
    "            err1 = \"`paired` is not None; therefore Cliff's delta is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        if proportional==True and effect_size not in ['mean_diff','cohens_h']:\n",
    "            err1 = \"`proportional` is True; therefore effect size other than mean_diff and cohens_h is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        if proportional==True and (np.isin(control, [0, 1]).all() == False or np.isin(test, [0, 1]).all() == False):\n",
    "            err1 = \"`proportional` is True; Only accept binary data consisting of 0 and 1.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        # Convert to numpy arrays for speed.\n",
    "        # NaNs are automatically dropped.\n",
    "        control = array(control)\n",
    "        test    = array(test)\n",
    "        control = control[~isnan(control)]\n",
    "        test    = test[~isnan(test)]\n",
    "\n",
    "        self.__effect_size       = effect_size\n",
    "        self.__control           = control\n",
    "        self.__test              = test\n",
    "        self.__is_paired         = is_paired\n",
    "        self.__resamples         = resamples\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__random_seed       = random_seed\n",
    "        self.__ci                = ci\n",
    "        self.__alpha             = ci2g._compute_alpha_from_ci(ci)\n",
    "\n",
    "        self.__difference = es.two_group_difference(\n",
    "                                control, test, is_paired, effect_size)\n",
    "        \n",
    "        self.__jackknives = ci2g.compute_meandiff_jackknife(\n",
    "                                control, test, is_paired, effect_size)\n",
    "\n",
    "        self.__acceleration_value = ci2g._calc_accel(self.__jackknives)\n",
    "\n",
    "        bootstraps = ci2g.compute_bootstrapped_diff(\n",
    "                            control, test, is_paired, effect_size,\n",
    "                            resamples, random_seed)\n",
    "        self.__bootstraps = bootstraps\n",
    "        \n",
    "        sorted_bootstraps = npsort(self.__bootstraps)\n",
    "        # Added in v0.2.6.\n",
    "        # Raises a UserWarning if there are any infiinities in the bootstraps.\n",
    "        num_infinities = len(self.__bootstraps[isinf(self.__bootstraps)])\n",
    "        \n",
    "        if num_infinities > 0:\n",
    "            warn_msg = \"There are {} bootstrap(s) that are not defined. \"\\\n",
    "            \"This is likely due to smaple sample sizes. \"\\\n",
    "            \"The values in a bootstrap for a group will be more likely \"\\\n",
    "            \"to be all equal, with a resulting variance of zero. \"\\\n",
    "            \"The computation of Cohen's d and Hedges' g thus \"\\\n",
    "            \"involved a division by zero. \"\n",
    "            warnings.warn(warn_msg.format(num_infinities), \n",
    "                          category=UserWarning)\n",
    "\n",
    "        self.__bias_correction = ci2g.compute_meandiff_bias_correction(\n",
    "                                    self.__bootstraps, self.__difference)\n",
    "\n",
    "        # Compute BCa intervals.\n",
    "        bca_idx_low, bca_idx_high = ci2g.compute_interval_limits(\n",
    "            self.__bias_correction, self.__acceleration_value,\n",
    "            self.__resamples, ci)\n",
    "\n",
    "        self.__bca_interval_idx = (bca_idx_low, bca_idx_high)\n",
    "\n",
    "        if ~isnan(bca_idx_low) and ~isnan(bca_idx_high):\n",
    "            self.__bca_low  = sorted_bootstraps[bca_idx_low]\n",
    "            self.__bca_high = sorted_bootstraps[bca_idx_high]\n",
    "\n",
    "            err1 = \"The $lim_type limit of the interval\"\n",
    "            err2 = \"was in the $loc 10 values.\"\n",
    "            err3 = \"The result should be considered unstable.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if bca_idx_low <= 10:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\",\n",
    "                                                  loc=\"bottom\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "            if bca_idx_high >= resamples-9:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\",\n",
    "                                                  loc=\"top\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "        else:\n",
    "            err1 = \"The $lim_type limit of the BCa interval cannot be computed.\"\n",
    "            err2 = \"It is set to the effect size itself.\"\n",
    "            err3 = \"All bootstrap values were likely all the same.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if isnan(bca_idx_low):\n",
    "                self.__bca_low  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "            if isnan(bca_idx_high):\n",
    "                self.__bca_high  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "        # Compute percentile intervals.\n",
    "        pct_idx_low  = int((self.__alpha/2)     * resamples)\n",
    "        pct_idx_high = int((1-(self.__alpha/2)) * resamples)\n",
    "\n",
    "        self.__pct_interval_idx = (pct_idx_low, pct_idx_high)\n",
    "        self.__pct_low  = sorted_bootstraps[pct_idx_low]\n",
    "        self.__pct_high = sorted_bootstraps[pct_idx_high]\n",
    "\n",
    "        # Perform statistical tests.\n",
    "                \n",
    "        self.__PermutationTest_result = PermutationTest(control, test, \n",
    "                                                        effect_size, \n",
    "                                                        is_paired,\n",
    "                                                        permutation_count)\n",
    "        \n",
    "        if is_paired and proportional is False:\n",
    "            # Wilcoxon, a non-parametric version of the paired T-test.\n",
    "            wilcoxon = spstats.wilcoxon(control, test)\n",
    "            self.__pvalue_wilcoxon = wilcoxon.pvalue\n",
    "            self.__statistic_wilcoxon = wilcoxon.statistic\n",
    "            \n",
    "            \n",
    "            # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#             lqrt_result = lqrt.lqrtest_rel(control, test, \n",
    "#                                     random_state=random_seed)\n",
    "#             self.__pvalue_paired_lqrt = lqrt_result.pvalue\n",
    "#             self.__statistic_paired_lqrt = lqrt_result.statistic\n",
    "\n",
    "            if effect_size != \"median_diff\":\n",
    "                # Paired Student's t-test.\n",
    "                paired_t = spstats.ttest_rel(control, test, nan_policy='omit')\n",
    "                self.__pvalue_paired_students_t = paired_t.pvalue\n",
    "                self.__statistic_paired_students_t = paired_t.statistic\n",
    "\n",
    "                standardized_es = es.cohens_d(control, test, is_paired)\n",
    "                # self.__power = power.tt_solve_power(standardized_es,\n",
    "                #                                     len(control),\n",
    "                #                                     alpha=self.__alpha)\n",
    "\n",
    "        elif is_paired and proportional is True:\n",
    "            # for binary paired data, use McNemar's test\n",
    "            # References:\n",
    "            # https://en.wikipedia.org/wiki/McNemar%27s_test\n",
    "            from statsmodels.stats.contingency_tables import mcnemar\n",
    "            import pandas as pd\n",
    "            df_temp = pd.DataFrame({'control': control, 'test': test})\n",
    "            x1 = len(df_temp[(df_temp['control'] == 0)&(df_temp['test'] == 0)])\n",
    "            x2 = len(df_temp[(df_temp['control'] == 0)&(df_temp['test'] == 1)])\n",
    "            x3 = len(df_temp[(df_temp['control'] == 1)&(df_temp['test'] == 0)])\n",
    "            x4 = len(df_temp[(df_temp['control'] == 1)&(df_temp['test'] == 1)])\n",
    "            table =  [[x1,x2],[x3,x4]]\n",
    "            _mcnemar = mcnemar(table, exact=True, correction=True)\n",
    "            self.__pvalue_mcnemar = _mcnemar.pvalue\n",
    "            self.__statistic_mcnemar = _mcnemar.statistic\n",
    "\n",
    "        elif effect_size == \"cliffs_delta\":\n",
    "            # Let's go with Brunner-Munzel!\n",
    "            brunner_munzel = spstats.brunnermunzel(control, test,\n",
    "                                                     nan_policy='omit')\n",
    "            self.__pvalue_brunner_munzel = brunner_munzel.pvalue\n",
    "            self.__statistic_brunner_munzel = brunner_munzel.statistic\n",
    "\n",
    "\n",
    "        elif effect_size == \"median_diff\":\n",
    "            # According to scipy's documentation of the function,\n",
    "            # \"The Kruskal-Wallis H-test tests the null hypothesis\n",
    "            # that the population median of all of the groups are equal.\"\n",
    "            kruskal = spstats.kruskal(control, test, nan_policy='omit')\n",
    "            self.__pvalue_kruskal = kruskal.pvalue\n",
    "            self.__statistic_kruskal = kruskal.statistic\n",
    "            # self.__power = np.nan\n",
    "\n",
    "        else: # for mean difference, Cohen's d, and Hedges' g.\n",
    "            # Welch's t-test, assumes normality of distributions,\n",
    "            # but does not assume equal variances.\n",
    "            welch = spstats.ttest_ind(control, test, equal_var=False,\n",
    "                                       nan_policy='omit')\n",
    "            self.__pvalue_welch = welch.pvalue\n",
    "            self.__statistic_welch = welch.statistic\n",
    "\n",
    "            # Student's t-test, assumes normality of distributions,\n",
    "            # as well as assumption of equal variances.\n",
    "            students_t = spstats.ttest_ind(control, test, equal_var=True,\n",
    "                                            nan_policy='omit')\n",
    "            self.__pvalue_students_t = students_t.pvalue\n",
    "            self.__statistic_students_t = students_t.statistic\n",
    "\n",
    "            # Mann-Whitney test: Non parametric,\n",
    "            # does not assume normality of distributions\n",
    "            try:\n",
    "                mann_whitney = spstats.mannwhitneyu(control, test, \n",
    "                                                    alternative='two-sided')\n",
    "                self.__pvalue_mann_whitney = mann_whitney.pvalue\n",
    "                self.__statistic_mann_whitney = mann_whitney.statistic\n",
    "            except ValueError:\n",
    "                # Occurs when the control and test are exactly identical\n",
    "                # in terms of rank (eg. all zeros.)\n",
    "                pass\n",
    "            \n",
    "            # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#             # Likelihood Q-Ratio test:\n",
    "#             lqrt_equal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "#                                         random_state=random_seed,\n",
    "#                                         equal_var=True)\n",
    "                            \n",
    "#             self.__pvalue_lqrt_equal_var = lqrt_equal_var_result.pvalue\n",
    "#             self.__statistic_lqrt_equal_var = lqrt_equal_var_result.statistic\n",
    "            \n",
    "#             lqrt_unequal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "#                                         random_state=random_seed,\n",
    "#                                         equal_var=False)\n",
    "                                        \n",
    "#             self.__pvalue_lqrt_unequal_var = lqrt_unequal_var_result.pvalue\n",
    "#             self.__statistic_lqrt_unequal_var = lqrt_unequal_var_result.statistic\n",
    "                    \n",
    "\n",
    "            standardized_es = es.cohens_d(control, test, is_paired = None)\n",
    "            \n",
    "            # The Cohen's h calculation is for binary categorical data\n",
    "            try:\n",
    "                self.__proportional_difference = es.cohens_h(control, test)\n",
    "            except ValueError:\n",
    "                # Occur only when the data consists not only 0's and 1's.\n",
    "                pass\n",
    "            # self.__power = power.tt_ind_solve_power(standardized_es,\n",
    "            #                                         len(control),\n",
    "            #                                         alpha=self.__alpha,\n",
    "            #                                         ratio=len(test)/len(control)\n",
    "            #                                         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self, show_resample_count=True, define_pval=True, sigfig=3):\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # UNPAIRED_ES_TO_TEST = {\"mean_diff\"    : \"Mann-Whitney\",\n",
    "        #                        \"median_diff\"  : \"Kruskal\",\n",
    "        #                        \"cohens_d\"     : \"Mann-Whitney\",\n",
    "        #                        \"hedges_g\"     : \"Mann-Whitney\",\n",
    "        #                        \"cliffs_delta\" : \"Brunner-Munzel\"}\n",
    "        # \n",
    "        # TEST_TO_PVAL_ATTR = {\"Mann-Whitney\"    : \"pvalue_mann_whitney\",\n",
    "        #                      \"Kruskal\"        :  \"pvalue_kruskal\",\n",
    "        #                      \"Brunner-Munzel\" :  \"pvalue_brunner_munzel\",\n",
    "        #                      \"Wilcoxon\"       :  \"pvalue_wilcoxon\"}\n",
    "        \n",
    "        RM_STATUS = {'baseline'  : 'for repeated measures against baseline \\n', \n",
    "                     'sequential': 'for the sequential design of repeated-measures experiment \\n',\n",
    "                     'None'      : ''\n",
    "                    }\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'paired', \n",
    "                         'sequential' : 'paired',\n",
    "                         'None'       : 'unpaired'\n",
    "        }\n",
    "\n",
    "        first_line = {\"rm_status\"    : RM_STATUS[str(self.__is_paired)],\n",
    "                      \"es\"           : self.__EFFECT_SIZE_DICT[self.__effect_size],\n",
    "                      \"paired_status\": PAIRED_STATUS[str(self.__is_paired)]}\n",
    "        \n",
    "\n",
    "        out1 = \"The {paired_status} {es} {rm_status}\".format(**first_line)\n",
    "        \n",
    "        base_string_fmt = \"{:.\" + str(sigfig) + \"}\"\n",
    "        if \".\" in str(self.__ci):\n",
    "            ci_width = base_string_fmt.format(self.__ci)\n",
    "        else:\n",
    "            ci_width = str(self.__ci)\n",
    "        \n",
    "        ci_out = {\"es\"       : base_string_fmt.format(self.__difference),\n",
    "                  \"ci\"       : ci_width,\n",
    "                  \"bca_low\"  : base_string_fmt.format(self.__bca_low),\n",
    "                  \"bca_high\" : base_string_fmt.format(self.__bca_high)}\n",
    "        \n",
    "        out2 = \"is {es} [{ci}%CI {bca_low}, {bca_high}].\".format(**ci_out)\n",
    "        out = out1 + out2\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # if self.__is_paired:\n",
    "        #     stats_test = \"Wilcoxon\"\n",
    "        # else:\n",
    "        #     stats_test = UNPAIRED_ES_TO_TEST[self.__effect_size]\n",
    "        \n",
    "        \n",
    "        # pval_rounded = base_string_fmt.format(getattr(self,\n",
    "        #                                              TEST_TO_PVAL_ATTR[stats_test])\n",
    "        #                                       )\n",
    "        \n",
    "        pval_rounded = base_string_fmt.format(self.pvalue_permutation)\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # pvalue = \"The two-sided p-value of the {} test is {}.\".format(stats_test,\n",
    "        #                                                         pval_rounded)\n",
    "        \n",
    "        # pvalue = \"The two-sided p-value of the {} test is {}.\".format(stats_test,\n",
    "        #                                                         pval_rounded)\n",
    "        \n",
    "        \n",
    "        p1 = \"The p-value of the two-sided permutation t-test is {}, \".format(pval_rounded)\n",
    "        p2 = \"calculated for legacy purposes only. \"\n",
    "        pvalue = p1 + p2\n",
    "                                                                \n",
    "        bs1 = \"{} bootstrap samples were taken; \".format(self.__resamples)\n",
    "        bs2 = \"the confidence interval is bias-corrected and accelerated.\"\n",
    "        bs = bs1 + bs2\n",
    "\n",
    "        pval_def1 = \"Any p-value reported is the probability of observing the\" + \\\n",
    "                    \"effect size (or greater),\\nassuming the null hypothesis of\" + \\\n",
    "                    \"zero difference is true.\"\n",
    "        pval_def2 = \"\\nFor each p-value, 5000 reshuffles of the \" + \\\n",
    "                    \"control and test labels were performed.\"\n",
    "        pval_def = pval_def1 + pval_def2\n",
    "\n",
    "        if show_resample_count and define_pval:\n",
    "            return \"{}\\n{}\\n\\n{}\\n{}\".format(out, pvalue, bs, pval_def)\n",
    "        elif show_resample_count is False and define_pval is True:\n",
    "            return \"{}\\n{}\\n\\n{}\".format(out, pvalue, pval_def)\n",
    "        elif show_resample_count is True and define_pval is False:\n",
    "            return \"{}\\n{}\\n\\n{}\".format(out, pvalue, bs)\n",
    "        else:\n",
    "            return \"{}\\n{}\".format(out, pvalue)\n",
    "\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Returns the attributes of the `dabest.TwoGroupEffectSize` object as a\n",
    "        dictionary.\n",
    "        \"\"\"\n",
    "        # Only get public (user-facing) attributes.\n",
    "        attrs = [a for a in dir(self)\n",
    "                 if not a.startswith((\"_\", \"to_dict\"))]\n",
    "        out = {}\n",
    "        for a in attrs:\n",
    "            out[a] = getattr(self, a)\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def difference(self):\n",
    "        \"\"\"\n",
    "        Returns the difference between the control and the test.\n",
    "        \"\"\"\n",
    "        return self.__difference\n",
    "\n",
    "    @property\n",
    "    def effect_size(self):\n",
    "        \"\"\"\n",
    "        Returns the type of effect size reported.\n",
    "        \"\"\"\n",
    "        return self.__EFFECT_SIZE_DICT[self.__effect_size]\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        return self.__is_paired\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        Returns the width of the confidence interval, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"\n",
    "        Returns the significance level of the statistical test as a float\n",
    "        between 0 and 1.\n",
    "        \"\"\"\n",
    "        return self.__alpha\n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples performed during the bootstrap procedure.\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "    @property\n",
    "    def bootstraps(self):\n",
    "        \"\"\"\n",
    "        The generated bootstraps of the effect size.\n",
    "        \"\"\"\n",
    "        return self.__bootstraps\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The number used to initialise the numpy random seed generator, ie.\n",
    "        `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "    @property\n",
    "    def bca_interval_idx(self):\n",
    "        return self.__bca_interval_idx\n",
    "\n",
    "    @property\n",
    "    def bca_low(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_low\n",
    "\n",
    "    @property\n",
    "    def bca_high(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval upper limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_high\n",
    "\n",
    "    @property\n",
    "    def pct_interval_idx(self):\n",
    "        return self.__pct_interval_idx\n",
    "\n",
    "    @property\n",
    "    def pct_low(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_low\n",
    "\n",
    "    @property\n",
    "    def pct_high(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_high\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_brunner_munzel(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_brunner_munzel\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_brunner_munzel(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_brunner_munzel\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_wilcoxon(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_wilcoxon\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_wilcoxon(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_wilcoxon\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def pvalue_mcnemar(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_mcnemar\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_mcnemar(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_mcnemar\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_paired_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_paired_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_paired_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_paired_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_kruskal(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_kruskal\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_kruskal(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_kruskal\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_welch(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_welch\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_welch(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_welch\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_mann_whitney(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_mann_whitney\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def statistic_mann_whitney(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_mann_whitney\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "            \n",
    "    # Introduced in v0.3.0.\n",
    "    @property\n",
    "    def pvalue_permutation(self):\n",
    "        return self.__PermutationTest_result.pvalue\n",
    "    \n",
    "    # \n",
    "    # \n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        \"\"\"\n",
    "        The number of permuations taken.\n",
    "        \"\"\"\n",
    "        return self.__PermutationTest_result.permutation_count\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations(self):\n",
    "        return self.__PermutationTest_result.permutations\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        return self.__PermutationTest_result.permutations_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def proportional_difference(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__proportional_difference\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#     @property\n",
    "#     def pvalue_lqrt_paired(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_paired_lqrt\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_paired(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_paired_lqrt\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "            \n",
    "    \n",
    "#     @property\n",
    "#     def pvalue_lqrt_unpaired_equal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_lqrt_equal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_unpaired_equal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_lqrt_equal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "            \n",
    "            \n",
    "#     @property\n",
    "#     def pvalue_lqrt_unpaired_unequal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_lqrt_unequal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_unpaired_unequal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_lqrt_unequal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "    \n",
    "    \n",
    "    \n",
    "    # @property\n",
    "    # def power(self):\n",
    "    #     from numpy import nan as npnan\n",
    "    #     try:\n",
    "    #         return self.__power\n",
    "    #     except AttributeError:\n",
    "    #         return npnan\n",
    "\n",
    "        \n",
    "        \n",
    "class EffectSizeDataFrame(object):\n",
    "    \"\"\"A class that generates and stores the results of bootstrapped effect\n",
    "    sizes for several comparisons.\"\"\"\n",
    "\n",
    "    def __init__(self, dabest, effect_size,\n",
    "                 is_paired, ci=95, proportional=False,\n",
    "                 resamples=5000, \n",
    "                 permutation_count=5000,\n",
    "                 random_seed=12345, \n",
    "                 x1_level=None, x2=None, \n",
    "                 delta2=False, experiment_label=None,\n",
    "                 mini_meta=False):\n",
    "        \"\"\"\n",
    "        Parses the data from a Dabest object, enabling plotting and printing\n",
    "        capability for the effect size of interest.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__dabest_obj        = dabest\n",
    "        self.__effect_size       = effect_size\n",
    "        self.__is_paired         = is_paired\n",
    "        self.__ci                = ci\n",
    "        self.__resamples         = resamples\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__random_seed       = random_seed\n",
    "        self.__proportional      = proportional\n",
    "        self.__x1_level          = x1_level\n",
    "        self.__experiment_label  = experiment_label \n",
    "        self.__x2                = x2\n",
    "        self.__delta2            = delta2 \n",
    "        self.__mini_meta         = mini_meta\n",
    "\n",
    "\n",
    "    def __pre_calc(self):\n",
    "        import pandas as pd\n",
    "        from .misc_tools import print_greeting, get_varname\n",
    "\n",
    "        idx  = self.__dabest_obj.idx\n",
    "        dat  = self.__dabest_obj._plot_data\n",
    "        xvar = self.__dabest_obj._xvar\n",
    "        yvar = self.__dabest_obj._yvar\n",
    "\n",
    "        out = []\n",
    "        reprs = []\n",
    "\n",
    "        for j, current_tuple in enumerate(idx):\n",
    "            if self.__is_paired!=\"sequential\":\n",
    "                cname = current_tuple[0]\n",
    "                control = dat[dat[xvar] == cname][yvar].copy()\n",
    "\n",
    "            for ix, tname in enumerate(current_tuple[1:]):\n",
    "                if self.__is_paired == \"sequential\":\n",
    "                    cname = current_tuple[ix]\n",
    "                    control = dat[dat[xvar] == cname][yvar].copy()\n",
    "                test = dat[dat[xvar] == tname][yvar].copy()\n",
    "\n",
    "                result = TwoGroupsEffectSize(control, test,\n",
    "                                             self.__effect_size,\n",
    "                                             self.__proportional,\n",
    "                                             self.__is_paired,\n",
    "                                             self.__ci,\n",
    "                                             self.__resamples,\n",
    "                                             self.__permutation_count,\n",
    "                                             self.__random_seed)\n",
    "                r_dict = result.to_dict()\n",
    "                r_dict[\"control\"]   = cname\n",
    "                r_dict[\"test\"]      = tname\n",
    "                r_dict[\"control_N\"] = int(len(control))\n",
    "                r_dict[\"test_N\"]    = int(len(test))\n",
    "                out.append(r_dict)\n",
    "                if j == len(idx)-1 and ix == len(current_tuple)-2:\n",
    "                    if self.__delta2 and self.__effect_size == \"mean_diff\":\n",
    "                        resamp_count = False\n",
    "                        def_pval     = False\n",
    "                    elif self.__mini_meta and self.__effect_size == \"mean_diff\":\n",
    "                        resamp_count = False\n",
    "                        def_pval     = False\n",
    "                    else:\n",
    "                        resamp_count = True\n",
    "                        def_pval     = True\n",
    "                else:\n",
    "                    resamp_count = False\n",
    "                    def_pval     = False\n",
    "\n",
    "                text_repr = result.__repr__(show_resample_count=resamp_count,\n",
    "                                            define_pval=def_pval)\n",
    "\n",
    "                to_replace = \"between {} and {} is\".format(cname, tname)\n",
    "                text_repr = text_repr.replace(\"is\", to_replace, 1)\n",
    "\n",
    "                reprs.append(text_repr)\n",
    "\n",
    "        varname = get_varname(self.__dabest_obj)\n",
    "        lastline = \"To get the results of all valid statistical tests, \" +\\\n",
    "        \"use `{}.{}.statistical_tests`\".format(varname, self.__effect_size)\n",
    "        reprs.append(lastline)\n",
    "\n",
    "        reprs.insert(0, print_greeting())\n",
    "\n",
    "        self.__for_print = \"\\n\\n\".join(reprs)\n",
    "\n",
    "        out_             = pd.DataFrame(out)\n",
    "\n",
    "        columns_in_order = ['control', 'test', 'control_N', 'test_N',\n",
    "                            'effect_size', 'is_paired',\n",
    "                            'difference', 'ci',\n",
    "\n",
    "                            'bca_low', 'bca_high', 'bca_interval_idx',\n",
    "                            'pct_low', 'pct_high', 'pct_interval_idx',\n",
    "                            \n",
    "                            'bootstraps', 'resamples', 'random_seed',\n",
    "                            \n",
    "                            'permutations', 'pvalue_permutation', 'permutation_count', 'permutations_var',\n",
    "                            \n",
    "                            'pvalue_welch',\n",
    "                            'statistic_welch',\n",
    "\n",
    "                            'pvalue_students_t',\n",
    "                            'statistic_students_t',\n",
    "\n",
    "                            'pvalue_mann_whitney',\n",
    "                            'statistic_mann_whitney',\n",
    "\n",
    "                            'pvalue_brunner_munzel',\n",
    "                            'statistic_brunner_munzel',\n",
    "\n",
    "                            'pvalue_wilcoxon',\n",
    "                            'statistic_wilcoxon',\n",
    "\n",
    "                            'pvalue_mcnemar',\n",
    "                            'statistic_mcnemar',\n",
    "\n",
    "                            'pvalue_paired_students_t',\n",
    "                            'statistic_paired_students_t',\n",
    "\n",
    "                            'pvalue_kruskal',\n",
    "                            'statistic_kruskal',\n",
    "                            'proportional_difference'\n",
    "                           ]\n",
    "        self.__results   = out_.reindex(columns=columns_in_order)\n",
    "        self.__results.dropna(axis=\"columns\", how=\"all\", inplace=True)\n",
    "        \n",
    "        # Add the is_paired column back when is_paired is None\n",
    "        if self.is_paired is None:\n",
    "            self.__results.insert(5, 'is_paired', self.__results.apply(lambda _: None, axis=1))\n",
    "        \n",
    "        # Create and compute the delta-delta statistics\n",
    "        if self.__delta2 is True and self.__effect_size == \"mean_diff\":\n",
    "            self.__delta_delta = DeltaDelta(self,\n",
    "                                            self.__permutation_count,\n",
    "                                            self.__ci)\n",
    "            reprs.append(self.__delta_delta.__repr__(header=False))\n",
    "        elif self.__delta2 is True and self.__effect_size != \"mean_diff\":\n",
    "            self.__delta_delta = \"Delta-delta is not supported for {}.\".format(self.__effect_size)\n",
    "        else:\n",
    "            self.__delta_delta = \"`delta2` is False; delta-delta is therefore not calculated.\"\n",
    "\n",
    "        # Create and compute the weighted average statistics\n",
    "        if self.__mini_meta is True and self.__effect_size == \"mean_diff\":\n",
    "            self.__mini_meta_delta = MiniMetaDelta(self,\n",
    "                                                     self.__permutation_count,\n",
    "                                                     self.__ci)\n",
    "            reprs.append(self.__mini_meta_delta.__repr__(header=False))\n",
    "        elif self.__mini_meta is True and self.__effect_size != \"mean_diff\":\n",
    "            self.__mini_meta_delta = \"Weighted delta is not supported for {}.\".format(self.__effect_size)\n",
    "        else:\n",
    "            self.__mini_meta_delta = \"`mini_meta` is False; weighted delta is therefore not calculated.\"\n",
    "        \n",
    "        \n",
    "        varname = get_varname(self.__dabest_obj)\n",
    "        lastline = \"To get the results of all valid statistical tests, \" +\\\n",
    "        \"use `{}.{}.statistical_tests`\".format(varname, self.__effect_size)\n",
    "        reprs.append(lastline)\n",
    "\n",
    "        reprs.insert(0, print_greeting())\n",
    "\n",
    "        self.__for_print = \"\\n\\n\".join(reprs)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            return self.__for_print\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__for_print\n",
    "            \n",
    "            \n",
    "            \n",
    "    def __calc_lqrt(self):\n",
    "        import lqrt\n",
    "        import pandas as pd\n",
    "        \n",
    "        rnd_seed = self.__random_seed\n",
    "        db_obj = self.__dabest_obj\n",
    "        dat  = db_obj._plot_data\n",
    "        xvar = db_obj._xvar\n",
    "        yvar = db_obj._yvar\n",
    "        delta2 = self.__delta2\n",
    "        \n",
    "\n",
    "        out = []\n",
    "\n",
    "        for j, current_tuple in enumerate(db_obj.idx):\n",
    "            if self.__is_paired != \"sequential\":\n",
    "                cname = current_tuple[0]\n",
    "                control = dat[dat[xvar] == cname][yvar].copy()\n",
    "\n",
    "            for ix, tname in enumerate(current_tuple[1:]):\n",
    "                if self.__is_paired == \"sequential\":\n",
    "                    cname = current_tuple[ix]\n",
    "                    control = dat[dat[xvar] == cname][yvar].copy()\n",
    "                test = dat[dat[xvar] == tname][yvar].copy()\n",
    "                \n",
    "                if self.__is_paired:                    \n",
    "                    # Refactored here in v0.3.0 for performance issues.\n",
    "                    lqrt_result = lqrt.lqrtest_rel(control, test, \n",
    "                                            random_state=rnd_seed)\n",
    "                    \n",
    "                    out.append({\"control\": cname, \"test\": tname, \n",
    "                                \"control_N\": int(len(control)), \n",
    "                                \"test_N\": int(len(test)),\n",
    "                                \"pvalue_paired_lqrt\": lqrt_result.pvalue,\n",
    "                                \"statistic_paired_lqrt\": lqrt_result.statistic\n",
    "                                })\n",
    "\n",
    "                else:\n",
    "                    # Likelihood Q-Ratio test:\n",
    "                    lqrt_equal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "                                                random_state=rnd_seed,\n",
    "                                                equal_var=True)\n",
    "                                                \n",
    "                                                \n",
    "                    lqrt_unequal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "                                                random_state=rnd_seed,\n",
    "                                                equal_var=False)\n",
    "                                                \n",
    "                    out.append({\"control\": cname, \"test\": tname, \n",
    "                                \"control_N\": int(len(control)), \n",
    "                                \"test_N\": int(len(test)),\n",
    "                                \n",
    "                                \"pvalue_lqrt_equal_var\"      : lqrt_equal_var_result.pvalue,\n",
    "                                \"statistic_lqrt_equal_var\"   : lqrt_equal_var_result.statistic,\n",
    "                                \"pvalue_lqrt_unequal_var\"    : lqrt_unequal_var_result.pvalue,\n",
    "                                \"statistic_lqrt_unequal_var\" : lqrt_unequal_var_result.statistic,\n",
    "                                })                     \n",
    "        self.__lqrt_results = pd.DataFrame(out)\n",
    "\n",
    "\n",
    "    def plot(self, color_col=None,\n",
    "\n",
    "            raw_marker_size=6, es_marker_size=9,\n",
    "\n",
    "            swarm_label=None, barchart_label=None, contrast_label=None, delta2_label=None,\n",
    "            swarm_ylim=None, barchart_ylim=None, contrast_ylim=None, delta2_ylim=None,\n",
    "\n",
    "            custom_palette=None, swarm_desat=0.5, halfviolin_desat=1,\n",
    "            halfviolin_alpha=0.8, \n",
    "\n",
    "            face_color = None,\n",
    "            #bar plot\n",
    "            bar_label=None, bar_desat=0.5, bar_width = 0.5,bar_ylim = None,\n",
    "            # error bar of proportion plot\n",
    "            ci=None, ci_type='bca', err_color=None,\n",
    "\n",
    "            float_contrast=True,\n",
    "            show_pairs=True,\n",
    "            show_delta2=True,\n",
    "            show_mini_meta=True,\n",
    "            group_summaries=None,\n",
    "            group_summaries_offset=0.1,\n",
    "\n",
    "            fig_size=None,\n",
    "            dpi=100,\n",
    "            ax=None,\n",
    "\n",
    "            swarmplot_kwargs=None,\n",
    "            barplot_kwargs=None,\n",
    "            violinplot_kwargs=None,\n",
    "            slopegraph_kwargs=None,\n",
    "            sankey_kwargs=None,\n",
    "            reflines_kwargs=None,\n",
    "            group_summary_kwargs=None,\n",
    "            legend_kwargs=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates an estimation plot for the effect size of interest.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        color_col : string, default None\n",
    "            Column to be used for colors.\n",
    "        raw_marker_size : float, default 6\n",
    "            The diameter (in points) of the marker dots plotted in the\n",
    "            swarmplot.\n",
    "        es_marker_size : float, default 9\n",
    "            The size (in points) of the effect size points on the difference\n",
    "            axes.\n",
    "        swarm_label, contrast_label, delta2_label : strings, default None\n",
    "            Set labels for the y-axis of the swarmplot and the contrast plot,\n",
    "            respectively. If `swarm_label` is not specified, it defaults to\n",
    "            \"value\", unless a column name was passed to `y`. If\n",
    "            `contrast_label` is not specified, it defaults to the effect size\n",
    "            being plotted. If `delta2_label` is not specifed, it defaults to \n",
    "            \"delta - delta\"\n",
    "        swarm_ylim, contrast_ylim, delta2_ylim : tuples, default None\n",
    "            The desired y-limits of the raw data (swarmplot) axes, the\n",
    "            difference axes and the delta-delta axes respectively, as a tuple. \n",
    "            These will be autoscaled to sensible values if they are not \n",
    "            specified. The delta2 axes and contrast axes should have the same \n",
    "            limits for y. When `show_delta2` is True, if both of the `contrast_ylim`\n",
    "            and `delta2_ylim` are not None, then they must be specified with the \n",
    "            same values; when `show_delta2` is True and only one of them is specified,\n",
    "            then the other will automatically be assigned with the same value.\n",
    "            Specifying `delta2_ylim` does not have any effect when `show_delta2` is\n",
    "            False. \n",
    "        custom_palette : dict, list, or matplotlib color palette, default None\n",
    "            This keyword accepts a dictionary with {'group':'color'} pairings,\n",
    "            a list of RGB colors, or a specified matplotlib palette. This\n",
    "            palette will be used to color the swarmplot. If `color_col` is not\n",
    "            specified, then each group will be colored in sequence according\n",
    "            to the default palette currently used by matplotlib.\n",
    "            Please take a look at the seaborn commands `color_palette`\n",
    "            and `cubehelix_palette` to generate a custom palette. Both\n",
    "            these functions generate a list of RGB colors.\n",
    "            See:\n",
    "            https://seaborn.pydata.org/generated/seaborn.color_palette.html\n",
    "            https://seaborn.pydata.org/generated/seaborn.cubehelix_palette.html\n",
    "            The named colors of matplotlib can be found here:\n",
    "            https://matplotlib.org/examples/color/named_colors.html\n",
    "        swarm_desat : float, default 1\n",
    "            Decreases the saturation of the colors in the swarmplot by the\n",
    "            desired proportion. Uses `seaborn.desaturate()` to acheive this.\n",
    "        halfviolin_desat : float, default 0.5\n",
    "            Decreases the saturation of the colors of the half-violin bootstrap\n",
    "            curves by the desired proportion. Uses `seaborn.desaturate()` to\n",
    "            acheive this.\n",
    "        halfviolin_alpha : float, default 0.8\n",
    "            The alpha (transparency) level of the half-violin bootstrap curves.            \n",
    "        float_contrast : boolean, default True\n",
    "            Whether or not to display the halfviolin bootstrapped difference\n",
    "            distribution alongside the raw data.\n",
    "        show_pairs : boolean, default True\n",
    "            If the data is paired, whether or not to show the raw data as a\n",
    "            swarmplot, or as slopegraph, with a line joining each pair of\n",
    "            observations.\n",
    "        show_delta2, show_mini_meta : boolean, default True\n",
    "            If delta-delta or mini-meta delta is calculated, whether or not to \n",
    "            show the delta-delta plot or mini-meta plot.\n",
    "        group_summaries : ['mean_sd', 'median_quartiles', 'None'], default None.\n",
    "            Plots the summary statistics for each group. If 'mean_sd', then\n",
    "            the mean and standard deviation of each group is plotted as a\n",
    "            notched line beside each group. If 'median_quantiles', then the\n",
    "            median and 25th and 75th percentiles of each group is plotted\n",
    "            instead. If 'None', the summaries are not shown.\n",
    "        group_summaries_offset : float, default 0.1\n",
    "            If group summaries are displayed, they will be offset from the raw\n",
    "            data swarmplot groups by this value. \n",
    "        fig_size : tuple, default None\n",
    "            The desired dimensions of the figure as a (length, width) tuple.\n",
    "        dpi : int, default 100\n",
    "            The dots per inch of the resulting figure.\n",
    "        ax : matplotlib.Axes, default None\n",
    "            Provide an existing Axes for the plots to be created. If no Axes is\n",
    "            specified, a new matplotlib Figure will be created.\n",
    "        swarmplot_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the seaborn `swarmplot`\n",
    "            command here, as a dict. If None, the following keywords are\n",
    "            passed to sns.swarmplot : {'size':`raw_marker_size`}.\n",
    "        violinplot_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib `\n",
    "            pyplot.violinplot` command here, as a dict. If None, the following\n",
    "            keywords are passed to violinplot : {'widths':0.5, 'vert':True,\n",
    "            'showextrema':False, 'showmedians':False}.\n",
    "        slopegraph_kwargs : dict, default None\n",
    "            This will change the appearance of the lines used to join each pair\n",
    "            of observations when `show_pairs=True`. Pass any keyword arguments\n",
    "            accepted by matplotlib `plot()` function here, as a dict.\n",
    "            If None, the following keywords are\n",
    "            passed to plot() : {'linewidth':1, 'alpha':0.5}.\n",
    "        sankey_kwargs: dict, default None\n",
    "            Whis will change the appearance of the sankey diagram used to depict\n",
    "            paired proportional data when `show_pairs=True` and `proportional=True`. \n",
    "            Pass any keyword arguments accepted by plot_tools.sankeydiag() function\n",
    "            here, as a dict. If None, the following keywords are passed to sankey diagram:\n",
    "            {\"width\": 0.5, \"align\": \"center\", \"alpha\": 0.4, \"bar_width\": 0.1, \"rightColor\": False}\n",
    "        reflines_kwargs : dict, default None\n",
    "            This will change the appearance of the zero reference lines. Pass\n",
    "            any keyword arguments accepted by the matplotlib Axes `hlines`\n",
    "            command here, as a dict. If None, the following keywords are\n",
    "            passed to Axes.hlines : {'linestyle':'solid', 'linewidth':0.75,\n",
    "            'zorder':2, 'color' : default y-tick color}.\n",
    "        group_summary_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib.lines.Line2D\n",
    "            command here, as a dict. This will change the appearance of the\n",
    "            vertical summary lines for each group, if `group_summaries` is not\n",
    "            'None'. If None, the following keywords are passed to\n",
    "            matplotlib.lines.Line2D : {'lw':2, 'alpha':1, 'zorder':3}.\n",
    "        legend_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib Axes\n",
    "            `legend` command here, as a dict. If None, the following keywords\n",
    "            are passed to matplotlib.Axes.legend : {'loc':'upper left',\n",
    "            'frameon':False}.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A :class:`matplotlib.figure.Figure` with 2 Axes, if ``ax = None``.\n",
    "        \n",
    "        The first axes (accessible with ``FigName.axes[0]``) contains the rawdata swarmplot; the second axes (accessible with ``FigName.axes[1]``) has the bootstrap distributions and effect sizes (with confidence intervals) plotted on it.\n",
    "        \n",
    "        If ``ax`` is specified, the rawdata swarmplot is accessed at ``ax`` \n",
    "        itself, while the effect size axes is accessed at ``ax.contrast_axes``.\n",
    "        See the last example below.\n",
    "        \n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Create a Gardner-Altman estimation plot for the mean difference.\n",
    "\n",
    "        >>> my_data = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\n",
    "        >>> fig1 = my_data.mean_diff.plot()\n",
    "\n",
    "        Create a Gardner-Altman plot for the Hedges' g effect size.\n",
    "\n",
    "        >>> fig2 = my_data.hedges_g.plot()\n",
    "\n",
    "        Create a Cumming estimation plot for the mean difference.\n",
    "\n",
    "        >>> fig3 = my_data.mean_diff.plot(float_contrast=True)\n",
    "\n",
    "        Create a paired Gardner-Altman plot.\n",
    "\n",
    "        >>> my_data_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"),\n",
    "        ...                id_col = \"ID\", paired='baseline')\n",
    "        >>> fig4 = my_data_paired.mean_diff.plot()\n",
    "\n",
    "        Create a multi-group Cumming plot.\n",
    "\n",
    "        >>> my_multi_groups = dabest.load(df, id_col = \"ID\", \n",
    "        ...                             idx=((\"Control 1\", \"Test 1\"),\n",
    "        ...                                 (\"Control 2\", \"Test 2\")))\n",
    "        >>> fig5 = my_multi_groups.mean_diff.plot()\n",
    "\n",
    "        Create a shared control Cumming plot.\n",
    "\n",
    "        >>> my_shared_control = dabest.load(df, id_col = \"ID\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig6 = my_shared_control.mean_diff.plot()\n",
    "        \n",
    "        Create a repeated meausures (against baseline) Slopeplot.\n",
    "\n",
    "        >>> my_rm_baseline = dabest.load(df, id_col = \"ID\", paired = \"baseline\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig7 = my_rm_baseline.mean_diff.plot()\n",
    "\n",
    "        Create a repeated meausures (sequential) Slopeplot.\n",
    "\n",
    "        >>> my_rm_sequential = dabest.load(df, id_col = \"ID\", paired = \"sequential\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig8 = my_rm_sequential.mean_diff.plot()\n",
    "\n",
    "        Creating estimation plots in individual panels of a figure.\n",
    "        \n",
    "        >>> f, axx = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))\n",
    "        >>> my_data.mean_diff.plot(ax=axx.flat[0])\n",
    "        >>> my_data_paired.mean_diff.plot(ax=axx.flat[1])\n",
    "        >>> my_shared_control.mean_diff.plot(ax=axx.flat[2])\n",
    "        >>> my_shared_control.mean_diff.plot(ax=axx.flat[3], float_contrast=False)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        from .plotter import EffectSizeDataFramePlotter\n",
    "\n",
    "        if hasattr(self, \"results\") is False:\n",
    "            self.__pre_calc()\n",
    "\n",
    "        if self.__delta2:\n",
    "            color_col = self.__x2\n",
    "\n",
    "        # if self.__proportional:\n",
    "        #     raw_marker_size = 0.01\n",
    "            \n",
    "        all_kwargs = locals()\n",
    "        del all_kwargs[\"self\"]\n",
    "\n",
    "        out = EffectSizeDataFramePlotter(self, **all_kwargs)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "\n",
    "    @property\n",
    "    def results(self):\n",
    "        \"\"\"Prints all pairwise comparisons nicely.\"\"\"\n",
    "        try:\n",
    "            return self.__results\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__results\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def statistical_tests(self):\n",
    "        results_df = self.results\n",
    "\n",
    "        # Select only the statistics and p-values.\n",
    "        stats_columns = [c for c in results_df.columns\n",
    "                         if c.startswith(\"statistic\") or c.startswith(\"pvalue\")]\n",
    "\n",
    "        default_cols = ['control', 'test', 'control_N', 'test_N',\n",
    "                        'effect_size', 'is_paired',\n",
    "                        'difference', 'ci', 'bca_low', 'bca_high']\n",
    "\n",
    "        cols_of_interest = default_cols + stats_columns\n",
    "\n",
    "        return results_df[cols_of_interest]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _for_print(self):\n",
    "        return self.__for_print\n",
    "\n",
    "    @property\n",
    "    def _plot_data(self):\n",
    "        return self.__dabest_obj._plot_data\n",
    "\n",
    "    @property\n",
    "    def idx(self):\n",
    "        return self.__dabest_obj.idx\n",
    "\n",
    "    @property\n",
    "    def xvar(self):\n",
    "        return self.__dabest_obj._xvar\n",
    "\n",
    "    @property\n",
    "    def yvar(self):\n",
    "        return self.__dabest_obj._yvar\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        return self.__is_paired\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        The width of the confidence interval being produced, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "    @property\n",
    "    def x1_level(self):\n",
    "        return self.__x1_level\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x2(self):\n",
    "        return self.__x2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def experiment_label(self):\n",
    "        return self.__experiment_label\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def delta2(self):\n",
    "        return self.__delta2\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples (with replacement) during bootstrap resampling.\"\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The seed used by `numpy.seed()` for bootstrap resampling.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "    @property\n",
    "    def effect_size(self):\n",
    "        \"\"\"The type of effect size being computed.\"\"\"\n",
    "        return self.__effect_size\n",
    "\n",
    "    @property\n",
    "    def dabest_obj(self):\n",
    "        \"\"\"\n",
    "        Returns the `dabest` object that invoked the current EffectSizeDataFrame\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__dabest_obj\n",
    "\n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "        \n",
    "    @property\n",
    "    def lqrt(self):\n",
    "        \"\"\"Returns all pairwise Lq-Likelihood Ratio Type test results \n",
    "        as a pandas DataFrame.\n",
    "        \n",
    "        For more information on LqRT tests, see https://arxiv.org/abs/1911.11922\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__lqrt_results\n",
    "        except AttributeError:\n",
    "            self.__calc_lqrt()\n",
    "            return self.__lqrt_results\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def mini_meta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta boolean parameter.\n",
    "        \"\"\"\n",
    "        return self.__mini_meta\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def mini_meta_delta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__mini_meta_delta\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__mini_meta_delta\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def delta_delta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__delta_delta\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__delta_delta\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "class PermutationTest:\n",
    "    \"\"\"\n",
    "    A class to compute and report permutation tests.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    control : array-like\n",
    "    test : array-like\n",
    "        These should be numerical iterables.\n",
    "    effect_size : string.\n",
    "        Any one of the following are accepted inputs:\n",
    "        'mean_diff', 'median_diff', 'cohens_d', 'hedges_g', or 'cliffs_delta'\n",
    "    is_paired : string, default None\n",
    "    permutation_count : int, default 10000\n",
    "        The number of permutations (reshuffles) to perform.\n",
    "    random_seed : int, default 12345\n",
    "        `random_seed` is used to seed the random number generator during\n",
    "        bootstrap resampling. This ensures that the generated permutations\n",
    "        are replicable.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A :py:class:`PermutationTest` object.\n",
    "    \n",
    "    difference : float\n",
    "        The effect size of the difference between the control and the test.\n",
    "    \n",
    "    effect_size : string\n",
    "        The type of effect size reported.\n",
    "        \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The basic concept of permutation tests is the same as that behind bootstrapping.\n",
    "    In an \"exact\" permutation test, all possible resuffles of the control and test \n",
    "    labels are performed, and the proportion of effect sizes that equal or exceed \n",
    "    the observed effect size is computed. This is the probability, under the null \n",
    "    hypothesis of zero difference between test and control groups, of observing the\n",
    "    effect size: the p-value of the Student's t-test.\n",
    "    \n",
    "    Exact permutation tests are impractical: computing the effect sizes for all reshuffles quickly exceeds trivial computational loads. A control group and a test group both with 10 observations each would have a total of  :math:`20!` or :math:`2.43 \\\\times {10}^{18}` reshuffles.\n",
    "    Therefore, in practice, \"approximate\" permutation tests are performed, where a sufficient number of reshuffles are performed (5,000 or 10,000), from which the p-value is computed.\n",
    "    \n",
    "    More information can be found `here <https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests>`_.\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> from scipy.stats import norm\n",
    "    >>> import dabest\n",
    "    >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "    >>> test = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "    >>> perm_test = dabest.PermutationTest(control, test, \n",
    "    ...                                    effect_size=\"mean_diff\", \n",
    "    ...                                    paired=None)\n",
    "    >>> perm_test\n",
    "    5000 permutations were taken. The pvalue is 0.0758.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, control, test, \n",
    "                 effect_size, is_paired,\n",
    "                 permutation_count=5000, \n",
    "                 random_seed=12345,\n",
    "                 **kwargs):\n",
    "    \n",
    "        import numpy as np\n",
    "        from numpy.random import PCG64, RandomState\n",
    "        from .effsize import two_group_difference\n",
    "        from .confint_2group_diff import calculate_group_var\n",
    "\n",
    "        self.__permutation_count = permutation_count\n",
    "\n",
    "        # Run Sanity Check.\n",
    "        if is_paired and len(control) != len(test):\n",
    "            raise ValueError(\"The two arrays do not have the same length.\")\n",
    "\n",
    "        # Initialise random number generator.\n",
    "        # rng = np.random.default_rng(seed=random_seed)\n",
    "        rng = RandomState(PCG64(random_seed))\n",
    "\n",
    "        # Set required constants and variables\n",
    "        control = np.array(control)\n",
    "        test = np.array(test)\n",
    "\n",
    "        control_sample = control.copy()\n",
    "        test_sample    = test.copy()\n",
    "\n",
    "        BAG = np.array([*control, *test])\n",
    "        CONTROL_LEN = int(len(control))\n",
    "        EXTREME_COUNT = 0.\n",
    "        THRESHOLD = np.abs(two_group_difference(control, test, \n",
    "                                                is_paired, effect_size))\n",
    "        self.__permutations = []\n",
    "        self.__permutations_var = []\n",
    "\n",
    "        for i in range(int(permutation_count)):\n",
    "            \n",
    "            if is_paired:\n",
    "                # Select which control-test pairs to swap.\n",
    "                random_idx = rng.choice(CONTROL_LEN,\n",
    "                                rng.randint(0, CONTROL_LEN+1),\n",
    "                                replace=False)\n",
    "\n",
    "                # Perform swap.\n",
    "                for i in random_idx:\n",
    "                    _placeholder      = control_sample[i]\n",
    "                    control_sample[i] = test_sample[i]\n",
    "                    test_sample[i]    = _placeholder\n",
    "                \n",
    "            else:\n",
    "                # Shuffle the bag and assign to control and test groups.\n",
    "                # NB. rng.shuffle didn't produce replicable results...\n",
    "                shuffled = rng.permutation(BAG) \n",
    "                control_sample = shuffled[:CONTROL_LEN]\n",
    "                test_sample    = shuffled[CONTROL_LEN:]\n",
    "\n",
    "\n",
    "            es = two_group_difference(control_sample, test_sample, \n",
    "                                    False, effect_size)\n",
    "            \n",
    "            var = calculate_group_var(np.var(control_sample, ddof=1), \n",
    "                                      CONTROL_LEN, \n",
    "                                      np.var(test_sample, ddof=1), \n",
    "                                      len(test_sample))\n",
    "            self.__permutations.append(es)\n",
    "            self.__permutations_var.append(var)\n",
    "\n",
    "            if np.abs(es) > THRESHOLD:\n",
    "                EXTREME_COUNT += 1.\n",
    "\n",
    "        self.__permutations = np.array(self.__permutations)\n",
    "        self.__permutations_var = np.array(self.__permutations_var)\n",
    "\n",
    "        self.pvalue = EXTREME_COUNT / permutation_count\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(\"{} permutations were taken. The p-value is {}.\".format(self.permutation_count, \n",
    "                                                                      self.pvalue))\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        \"\"\"\n",
    "        The number of permuations taken.\n",
    "        \"\"\"\n",
    "        return self.__permutation_count\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutations(self):\n",
    "        \"\"\"\n",
    "        The effect sizes of all the permutations in a list.\n",
    "        \"\"\"\n",
    "        return self.__permutations\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        \"\"\"\n",
    "        The experiment group variance of all the permutations in a list.\n",
    "        \"\"\"\n",
    "        return self.__permutations_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa405f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
